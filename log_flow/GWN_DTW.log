../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/flow_DTW.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302358 training started Mon May 30 23:58:15 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:58:15 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6792578620897078 validation loss: 0.6866970590097987
epoch 1 time used: 19  seconds  train loss: 0.6403205980193055 validation loss: 0.6663414497873676
epoch 2 time used: 19  seconds  train loss: 0.6282126156568189 validation loss: 0.6642350386920853
epoch 3 time used: 19  seconds  train loss: 0.6194927321897971 validation loss: 0.7035807928635707
epoch 4 time used: 19  seconds  train loss: 0.6149979180326502 validation loss: 0.6487807471360734
epoch 5 time used: 19  seconds  train loss: 0.609714638118554 validation loss: 0.6397297240015286
epoch 6 time used: 19  seconds  train loss: 0.6074011582314205 validation loss: 0.6671471400047416
epoch 7 time used: 19  seconds  train loss: 0.6046555703598608 validation loss: 0.6414992984254562
epoch 8 time used: 19  seconds  train loss: 0.6022839060379126 validation loss: 0.6444661583176893
epoch 9 time used: 19  seconds  train loss: 0.6011399497009103 validation loss: 0.6450461463548651
epoch 10 time used: 19  seconds  train loss: 0.5973782365556123 validation loss: 0.6297873753813369
epoch 11 time used: 19  seconds  train loss: 0.595031016327409 validation loss: 0.6315796995044347
epoch 12 time used: 19  seconds  train loss: 0.5938014894257568 validation loss: 0.6275772387115517
epoch 13 time used: 19  seconds  train loss: 0.5929275057563402 validation loss: 0.628803383948198
epoch 14 time used: 19  seconds  train loss: 0.5917996732812179 validation loss: 0.6534453138190123
epoch 15 time used: 19  seconds  train loss: 0.593907361688519 validation loss: 0.6286969680098159
epoch 16 time used: 19  seconds  train loss: 0.590494616018081 validation loss: 0.6298100593967817
epoch 17 time used: 19  seconds  train loss: 0.5868686964128638 validation loss: 0.629863631517733
epoch 18 time used: 19  seconds  train loss: 0.5855137365810562 validation loss: 0.6341838697295877
epoch 19 time used: 19  seconds  train loss: 0.5839605300897894 validation loss: 0.6267842349424884
epoch 20 time used: 19  seconds  train loss: 0.5848051041661422 validation loss: 0.6430458728946856
epoch 21 time used: 19  seconds  train loss: 0.5820007012629747 validation loss: 0.631294089318508
epoch 22 time used: 19  seconds  train loss: 0.5814798234367099 validation loss: 0.6265193108302444
epoch 23 time used: 19  seconds  train loss: 0.5798150330654758 validation loss: 0.6362622246813419
epoch 24 time used: 19  seconds  train loss: 0.5786130987054763 validation loss: 0.6409379309089622
epoch 25 time used: 19  seconds  train loss: 0.5772498374643231 validation loss: 0.6224430390258333
epoch 26 time used: 19  seconds  train loss: 0.5771080747267939 validation loss: 0.6248793299518415
epoch 27 time used: 19  seconds  train loss: 0.5747678558823055 validation loss: 0.6235674145209849
epoch 28 time used: 19  seconds  train loss: 0.5738557604688669 validation loss: 0.6232919823470994
epoch 29 time used: 19  seconds  train loss: 0.5732470821181198 validation loss: 0.6210362662130328
epoch 30 time used: 19  seconds  train loss: 0.5732411046116315 validation loss: 0.6321013578728064
epoch 31 time used: 19  seconds  train loss: 0.5724587803375331 validation loss: 0.6370547950564333
epoch 32 time used: 19  seconds  train loss: 0.5713560518465544 validation loss: 0.6280507237757024
epoch 33 time used: 19  seconds  train loss: 0.5695578952771672 validation loss: 0.6329560202745655
epoch 34 time used: 19  seconds  train loss: 0.5691598473198892 validation loss: 0.6339570060001677
epoch 35 time used: 19  seconds  train loss: 0.5699266100336783 validation loss: 0.6315517223889555
epoch 36 time used: 19  seconds  train loss: 0.5698162809883378 validation loss: 0.6263455348228341
epoch 37 time used: 19  seconds  train loss: 0.5666402705533067 validation loss: 0.6310780463527091
epoch 38 time used: 19  seconds  train loss: 0.5651173360995514 validation loss: 0.6286186480996621
epoch 39 time used: 19  seconds  train loss: 0.5656016432967668 validation loss: 0.6205797145022681
epoch 40 time used: 19  seconds  train loss: 0.5666844420039637 validation loss: 0.6281132448965044
epoch 41 time used: 19  seconds  train loss: 0.5653166358026638 validation loss: 0.6194674887170839
epoch 42 time used: 19  seconds  train loss: 0.5629429541644806 validation loss: 0.6224292386230544
epoch 43 time used: 19  seconds  train loss: 0.5634449968806032 validation loss: 0.6369950169354529
epoch 44 time used: 19  seconds  train loss: 0.562134319314916 validation loss: 0.6254018162613484
epoch 45 time used: 19  seconds  train loss: 0.5629902686367333 validation loss: 0.6196001255097081
epoch 46 time used: 19  seconds  train loss: 0.5600625965876735 validation loss: 0.6224431686140411
epoch 47 time used: 19  seconds  train loss: 0.5590456628358551 validation loss: 0.6173434654871622
epoch 48 time used: 19  seconds  train loss: 0.5584836480118981 validation loss: 0.6174639241019292
epoch 49 time used: 19  seconds  train loss: 0.557004287605774 validation loss: 0.6173035324509464
epoch 50 time used: 19  seconds  train loss: 0.5562883364526849 validation loss: 0.6219082400573427
epoch 51 time used: 19  seconds  train loss: 0.5600939482916809 validation loss: 0.6248670069139395
epoch 52 time used: 19  seconds  train loss: 0.5570628956744546 validation loss: 0.6251920018326583
epoch 53 time used: 19  seconds  train loss: 0.5572922285725688 validation loss: 0.6316268236482915
epoch 54 time used: 19  seconds  train loss: 0.5564986252004697 validation loss: 0.6191510774602937
epoch 55 time used: 19  seconds  train loss: 0.5540692926640192 validation loss: 0.6218746713737944
epoch 56 time used: 19  seconds  train loss: 0.5533445888698355 validation loss: 0.622213657222577
epoch 57 time used: 19  seconds  train loss: 0.552721155910709 validation loss: 0.6334747716562071
epoch 58 time used: 19  seconds  train loss: 0.5517661039893692 validation loss: 0.6196150566214946
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4952929132e-01, 0.5495292913
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.9536068142, 4.6854676196, 3.5565450595, 31.6836357117
Model Training Ended ... Tue May 31 00:18:45 2022
pred_SZTAXI_GraphWaveNet_2205302358 testing started Tue May 31 00:18:45 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:18:45 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.5316096109e-01, 0.5531609611
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.1858007251, 5.1172063399, 3.8321763099, 35.4441136122
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.2936360920, 4.2771060417, 3.3276528177, 31.7130982876
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5325727815, 4.4195670355, 3.4148760680, 32.3798745871
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.2597696659, 4.6108317759, 3.5391929585, 33.2991063595
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8531299270, 4.7804947366, 3.6470939388, 34.0898036957
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2603820080, 4.9254829213, 3.7321487999, 34.7662687302
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.6099443769, 5.0606268759, 3.8162286319, 35.4083836079
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.1966470039, 5.2150404604, 3.9083564895, 36.0375553370
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 28.7894948441, 5.3655842966, 3.9935576664, 36.6398781538
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 30.3189823999, 5.5062675561, 4.0856381306, 37.3361289501
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 31.3217715406, 5.5965857039, 4.1344914141, 37.5892311335
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 32.1395755612, 5.6691776795, 4.1746411836, 37.8573685884
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 32.7603912351, 5.7236693856, 4.2186563584, 38.2598757744
Model Testing Ended ... Tue May 31 00:18:51 2022
