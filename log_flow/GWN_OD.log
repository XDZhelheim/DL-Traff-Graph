../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/OD_matrix.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302301 training started Mon May 30 23:01:02 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:01:02 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6943020072380136 validation loss: 0.712101910689577
epoch 1 time used: 19  seconds  train loss: 0.6604052771036519 validation loss: 0.6921369875248392
epoch 2 time used: 19  seconds  train loss: 0.6486998981296762 validation loss: 0.6808776784299025
epoch 3 time used: 19  seconds  train loss: 0.6408665501545706 validation loss: 0.7094376529034098
epoch 4 time used: 19  seconds  train loss: 0.6334409952841985 validation loss: 0.6633758020045152
epoch 5 time used: 19  seconds  train loss: 0.6274226912394018 validation loss: 0.6521154431561332
epoch 6 time used: 19  seconds  train loss: 0.6244967603581728 validation loss: 0.6748156286590729
epoch 7 time used: 19  seconds  train loss: 0.6182953466053199 validation loss: 0.6490638653437296
epoch 8 time used: 19  seconds  train loss: 0.6159883001620535 validation loss: 0.6529281948929402
epoch 9 time used: 19  seconds  train loss: 0.6116386620621932 validation loss: 0.6541908267718642
epoch 10 time used: 19  seconds  train loss: 0.610237417485602 validation loss: 0.6385065870202002
epoch 11 time used: 19  seconds  train loss: 0.6062488637302882 validation loss: 0.6396820820979218
epoch 12 time used: 19  seconds  train loss: 0.6041679331452545 validation loss: 0.6365320466051054
epoch 13 time used: 19  seconds  train loss: 0.6011926225289851 validation loss: 0.6402903857515819
epoch 14 time used: 19  seconds  train loss: 0.5994743920152591 validation loss: 0.6342553090100265
epoch 15 time used: 19  seconds  train loss: 0.6005308422051996 validation loss: 0.6408489106306389
epoch 16 time used: 19  seconds  train loss: 0.5970593231331404 validation loss: 0.6283965625276613
epoch 17 time used: 19  seconds  train loss: 0.5943108561367941 validation loss: 0.6521172320368278
epoch 18 time used: 19  seconds  train loss: 0.5934980128855997 validation loss: 0.6330808813299112
epoch 19 time used: 19  seconds  train loss: 0.5911918372382141 validation loss: 0.6314945861474791
epoch 20 time used: 19  seconds  train loss: 0.5925351254970556 validation loss: 0.6440275252161928
epoch 21 time used: 19  seconds  train loss: 0.5885447455758221 validation loss: 0.6386646834475485
epoch 22 time used: 19  seconds  train loss: 0.5881953125827513 validation loss: 0.637007885014833
epoch 23 time used: 19  seconds  train loss: 0.5874707520771162 validation loss: 0.6273287315273759
epoch 24 time used: 19  seconds  train loss: 0.5853765778148158 validation loss: 0.6299697463192157
epoch 25 time used: 19  seconds  train loss: 0.584446376070359 validation loss: 0.6220253124758972
epoch 26 time used: 19  seconds  train loss: 0.5801691390033467 validation loss: 0.6243617792627705
epoch 27 time used: 19  seconds  train loss: 0.5821200131013418 validation loss: 0.6256521172191373
epoch 28 time used: 19  seconds  train loss: 0.5786350750990986 validation loss: 0.6202507161382419
epoch 29 time used: 19  seconds  train loss: 0.5819971233309587 validation loss: 0.6194083732158984
epoch 30 time used: 19  seconds  train loss: 0.5780346059527879 validation loss: 0.6200789041187039
epoch 31 time used: 19  seconds  train loss: 0.5763382168955687 validation loss: 0.6209036307548409
epoch 32 time used: 19  seconds  train loss: 0.5755411262702128 validation loss: 0.6208502026043128
epoch 33 time used: 19  seconds  train loss: 0.574306596266596 validation loss: 0.6194318482531836
epoch 34 time used: 19  seconds  train loss: 0.5740842492787291 validation loss: 0.6362996141412365
epoch 35 time used: 19  seconds  train loss: 0.5727428737100463 validation loss: 0.6205048647092942
epoch 36 time used: 19  seconds  train loss: 0.5727464144633471 validation loss: 0.6127336855551496
epoch 37 time used: 19  seconds  train loss: 0.5719013933097655 validation loss: 0.628360951569543
epoch 38 time used: 19  seconds  train loss: 0.5698755210527824 validation loss: 0.6187592934613204
epoch 39 time used: 19  seconds  train loss: 0.5709975982882389 validation loss: 0.6211130414436112
epoch 40 time used: 20  seconds  train loss: 0.5703370282015794 validation loss: 0.6195979459368768
epoch 41 time used: 19  seconds  train loss: 0.5712344728696397 validation loss: 0.6145159219627949
epoch 42 time used: 19  seconds  train loss: 0.5668428723367824 validation loss: 0.6108378165989966
epoch 43 time used: 19  seconds  train loss: 0.56580655749458 validation loss: 0.6132045269605533
epoch 44 time used: 19  seconds  train loss: 0.5645590614458575 validation loss: 0.6131572283025998
epoch 45 time used: 19  seconds  train loss: 0.5652781872457664 validation loss: 0.6095354064780089
epoch 46 time used: 19  seconds  train loss: 0.5620178135580901 validation loss: 0.6096735730100034
epoch 47 time used: 19  seconds  train loss: 0.5657365650235335 validation loss: 0.6029398180359039
epoch 48 time used: 19  seconds  train loss: 0.5613429799018849 validation loss: 0.6097175323251468
epoch 49 time used: 19  seconds  train loss: 0.558938283584535 validation loss: 0.6037832409588259
epoch 50 time used: 19  seconds  train loss: 0.5599322182525103 validation loss: 0.6041711076575133
epoch 51 time used: 19  seconds  train loss: 0.5582298246420294 validation loss: 0.6227340905820552
epoch 52 time used: 19  seconds  train loss: 0.559186273499539 validation loss: 0.6097868468927506
epoch 53 time used: 19  seconds  train loss: 0.5567321745125023 validation loss: 0.6182418388513783
epoch 54 time used: 19  seconds  train loss: 0.5567444587499963 validation loss: 0.6151911880246442
epoch 55 time used: 19  seconds  train loss: 0.557083274443153 validation loss: 0.605088995167272
epoch 56 time used: 19  seconds  train loss: 0.5536036017439613 validation loss: 0.6109016276710663
Early stopping at epoch: 57
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.5106288254e-01, 0.5510628825
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.5135013256, 4.6382649046, 3.5411636727, 31.6432297230
Model Training Ended ... Mon May 30 23:20:26 2022
pred_SZTAXI_GraphWaveNet_2205302301 testing started Mon May 30 23:20:26 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 23:20:26 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.4058397691e-01, 0.5405839769
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.8709673933, 4.8857924018, 3.7123880187, 34.4235479832
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0100721813, 4.2438275391, 3.3036113984, 31.3778340816
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.2867300157, 4.3916659727, 3.4030428534, 32.1338593960
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.3190745453, 4.5076684156, 3.4773466656, 32.7569216490
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.2669761383, 4.6116131818, 3.5471156804, 33.2885831594
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0778920513, 4.6987117438, 3.6079494648, 33.7591469288
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8116654819, 4.7761559315, 3.6521132047, 34.0378075838
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2191224529, 4.9212927624, 3.7532987466, 34.7851961851
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.4215108097, 5.0419748918, 3.8273073627, 35.3107392788
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.6047415455, 5.1579784359, 3.9003962433, 35.7950568199
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.7751258771, 5.2702111796, 3.9741007170, 36.3177716732
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 29.0473204980, 5.3895566142, 4.0420999901, 36.7468178272
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 29.6946056168, 5.4492756965, 4.0657186675, 36.8115305901
Model Testing Ended ... Mon May 30 23:20:31 2022
