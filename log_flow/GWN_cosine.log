../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/flow_cosine.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302340 training started Mon May 30 23:40:53 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:40:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6742751056574826 validation loss: 0.680592818788035
epoch 1 time used: 19  seconds  train loss: 0.6398888305783441 validation loss: 0.6724464946718358
epoch 2 time used: 19  seconds  train loss: 0.6264712799494161 validation loss: 0.6571467305297283
epoch 3 time used: 19  seconds  train loss: 0.6139306842348144 validation loss: 0.6513907159145792
epoch 4 time used: 19  seconds  train loss: 0.6067170806833215 validation loss: 0.6403908928235372
epoch 5 time used: 19  seconds  train loss: 0.6024023461477516 validation loss: 0.6358831026660863
epoch 6 time used: 19  seconds  train loss: 0.5972389878962152 validation loss: 0.6576098483889851
epoch 7 time used: 19  seconds  train loss: 0.5945182663956883 validation loss: 0.6242116829797403
epoch 8 time used: 19  seconds  train loss: 0.5915029962914088 validation loss: 0.6345268871950273
epoch 9 time used: 19  seconds  train loss: 0.5903156310701438 validation loss: 0.6315828837565521
epoch 10 time used: 19  seconds  train loss: 0.5871263500806447 validation loss: 0.625326414309924
epoch 11 time used: 19  seconds  train loss: 0.5847246565486425 validation loss: 0.6264094312985738
epoch 12 time used: 19  seconds  train loss: 0.5836895409213699 validation loss: 0.6230242427308761
epoch 13 time used: 19  seconds  train loss: 0.582090442245071 validation loss: 0.629927912161718
epoch 14 time used: 19  seconds  train loss: 0.579849376023918 validation loss: 0.6265465335466376
epoch 15 time used: 19  seconds  train loss: 0.5802997554179445 validation loss: 0.6227840300816209
epoch 16 time used: 19  seconds  train loss: 0.5792599588335832 validation loss: 0.6156611924444265
epoch 17 time used: 19  seconds  train loss: 0.5768052201352452 validation loss: 0.6199543587307432
epoch 18 time used: 19  seconds  train loss: 0.5747463572160957 validation loss: 0.6185984071807482
epoch 19 time used: 19  seconds  train loss: 0.5738929845021765 validation loss: 0.611683722307433
epoch 20 time used: 19  seconds  train loss: 0.574477029389372 validation loss: 0.628593553061509
epoch 21 time used: 19  seconds  train loss: 0.5706774572474859 validation loss: 0.6090887896160582
epoch 22 time used: 19  seconds  train loss: 0.5721347289607671 validation loss: 0.626240436413988
epoch 23 time used: 19  seconds  train loss: 0.5700585762433612 validation loss: 0.6101214998397068
epoch 24 time used: 19  seconds  train loss: 0.5697869811085176 validation loss: 0.6110117429524512
epoch 25 time used: 19  seconds  train loss: 0.5678224289315523 validation loss: 0.613646052963105
epoch 26 time used: 19  seconds  train loss: 0.5661564593973065 validation loss: 0.6048747437510325
epoch 27 time used: 19  seconds  train loss: 0.5665151035124343 validation loss: 0.6054085759974238
epoch 28 time used: 19  seconds  train loss: 0.5641856017611274 validation loss: 0.6028370821653907
epoch 29 time used: 19  seconds  train loss: 0.563599320427961 validation loss: 0.6040420828767084
epoch 30 time used: 19  seconds  train loss: 0.5624202663664458 validation loss: 0.6053298622814577
epoch 31 time used: 19  seconds  train loss: 0.563212859427098 validation loss: 0.6050913677879827
epoch 32 time used: 19  seconds  train loss: 0.5614767314529691 validation loss: 0.6061984001107477
epoch 33 time used: 19  seconds  train loss: 0.5608213176344061 validation loss: 0.6097008360559074
epoch 34 time used: 19  seconds  train loss: 0.5602482154986598 validation loss: 0.6078294781013508
epoch 35 time used: 19  seconds  train loss: 0.559438596239809 validation loss: 0.6085977038340782
epoch 36 time used: 19  seconds  train loss: 0.5582568108357203 validation loss: 0.6007933840526277
epoch 37 time used: 19  seconds  train loss: 0.5581606842715234 validation loss: 0.6034618507866836
epoch 38 time used: 19  seconds  train loss: 0.5575753268103512 validation loss: 0.601119742761204
epoch 39 time used: 19  seconds  train loss: 0.5574219995847298 validation loss: 0.606692723670409
epoch 40 time used: 19  seconds  train loss: 0.5569383355326537 validation loss: 0.5987343562776176
epoch 41 time used: 19  seconds  train loss: 0.554657845120681 validation loss: 0.6034445928696969
epoch 42 time used: 19  seconds  train loss: 0.5554000246066966 validation loss: 0.6036987494473434
epoch 43 time used: 19  seconds  train loss: 0.5560429526935431 validation loss: 0.6052132051679032
epoch 44 time used: 19  seconds  train loss: 0.5536593197928383 validation loss: 0.608505566766606
epoch 45 time used: 19  seconds  train loss: 0.5552395781022557 validation loss: 0.600846919254284
epoch 46 time used: 19  seconds  train loss: 0.5530604804477854 validation loss: 0.6106972632123463
epoch 47 time used: 19  seconds  train loss: 0.5542402599817658 validation loss: 0.6044164937527026
epoch 48 time used: 19  seconds  train loss: 0.5498521612853787 validation loss: 0.6011203988571072
epoch 49 time used: 19  seconds  train loss: 0.5501524351569023 validation loss: 0.6042874298285489
Early stopping at epoch: 50
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.5135472079e-01, 0.5513547208
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.1046931838, 4.7015628448, 3.5616024349, 31.4547538757
Model Training Ended ... Mon May 30 23:58:04 2022
pred_SZTAXI_GraphWaveNet_2205302340 testing started Mon May 30 23:58:04 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 23:58:04 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3895137823e-01, 0.5389513782
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.1613458448, 4.9154191932, 3.7346287862, 34.9978446960
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.7355830749, 4.2113635648, 3.2867271915, 31.6810905933
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.9920048838, 4.3579817443, 3.3915059344, 32.5235247612
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.0797696639, 4.4810455994, 3.4722373421, 33.1231594086
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3680581495, 4.6225596967, 3.5636021245, 33.8655680418
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.6134521898, 4.7553603638, 3.6505615469, 34.5109820366
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.6236754795, 4.8604192699, 3.7175837041, 34.9420756102
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.8993942333, 4.9899292814, 3.7850261257, 35.3536695242
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.9932866260, 5.0983611706, 3.8502815858, 35.7854694128
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.1267382630, 5.2083335399, 3.9167537432, 36.2245887518
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 28.3382669284, 5.3233698846, 4.0016039858, 36.8727385998
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 29.2632921070, 5.4095556294, 4.0664633840, 37.3502761126
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 29.9905628096, 5.4763640136, 4.1189620743, 37.7822816372
Model Testing Ended ... Mon May 30 23:58:10 2022
