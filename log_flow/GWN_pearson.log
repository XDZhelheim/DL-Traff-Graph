../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/flow_pearson.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302320 training started Mon May 30 23:20:36 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:20:36 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6619603669066857 validation loss: 0.6547204218990174
epoch 1 time used: 19  seconds  train loss: 0.6174592508869524 validation loss: 0.6491716343965104
epoch 2 time used: 19  seconds  train loss: 0.6051237669642247 validation loss: 0.6440513194793492
epoch 3 time used: 19  seconds  train loss: 0.5968999669782468 validation loss: 0.6466086050171164
epoch 4 time used: 19  seconds  train loss: 0.5909077255518983 validation loss: 0.624560108825342
epoch 5 time used: 19  seconds  train loss: 0.5871648883412607 validation loss: 0.6177527005992719
epoch 6 time used: 19  seconds  train loss: 0.5840561968164457 validation loss: 0.6319931404507575
epoch 7 time used: 19  seconds  train loss: 0.5812525732249318 validation loss: 0.6070185057559416
epoch 8 time used: 19  seconds  train loss: 0.5770252911668075 validation loss: 0.6123782500105711
epoch 9 time used: 19  seconds  train loss: 0.577155536472543 validation loss: 0.6124032365148934
epoch 10 time used: 19  seconds  train loss: 0.5729353895058503 validation loss: 0.6076271238908246
epoch 11 time used: 19  seconds  train loss: 0.5718132756003954 validation loss: 0.6119363625251238
epoch 12 time used: 19  seconds  train loss: 0.5702642414342628 validation loss: 0.6043394172369544
epoch 13 time used: 19  seconds  train loss: 0.567924846541322 validation loss: 0.6113508871538722
epoch 14 time used: 19  seconds  train loss: 0.5656960290322772 validation loss: 0.6033346605538136
epoch 15 time used: 19  seconds  train loss: 0.5658171830611413 validation loss: 0.601116502462928
epoch 16 time used: 19  seconds  train loss: 0.5646364996646919 validation loss: 0.6004978870574514
epoch 17 time used: 19  seconds  train loss: 0.5625498919704052 validation loss: 0.6010720679415992
epoch 18 time used: 19  seconds  train loss: 0.5606548558512588 validation loss: 0.5988383939610192
epoch 19 time used: 19  seconds  train loss: 0.559215969584914 validation loss: 0.5948071954262197
epoch 20 time used: 19  seconds  train loss: 0.5587637989992438 validation loss: 0.5948870902630821
epoch 21 time used: 19  seconds  train loss: 0.5561957036702765 validation loss: 0.595695293216563
epoch 22 time used: 19  seconds  train loss: 0.5552623568693571 validation loss: 0.6052287653904056
epoch 23 time used: 19  seconds  train loss: 0.5550886638473141 validation loss: 0.600283702214559
epoch 24 time used: 19  seconds  train loss: 0.5542985304321029 validation loss: 0.5959374477614218
epoch 25 time used: 19  seconds  train loss: 0.551469915918741 validation loss: 0.5902064226160002
epoch 26 time used: 19  seconds  train loss: 0.5514289627373642 validation loss: 0.5936302673164292
epoch 27 time used: 19  seconds  train loss: 0.5499983080589924 validation loss: 0.5958344553833577
epoch 28 time used: 19  seconds  train loss: 0.5481871670035177 validation loss: 0.5931595394860453
epoch 29 time used: 19  seconds  train loss: 0.5471819495917384 validation loss: 0.5881290720469916
epoch 30 time used: 19  seconds  train loss: 0.5461586092308609 validation loss: 0.5877546976454815
epoch 31 time used: 19  seconds  train loss: 0.5459761512737356 validation loss: 0.5914980517097966
epoch 32 time used: 19  seconds  train loss: 0.5506839391856241 validation loss: 0.5890966627135206
epoch 33 time used: 19  seconds  train loss: 0.5446373390863155 validation loss: 0.5903959265395776
epoch 34 time used: 19  seconds  train loss: 0.5428464037086682 validation loss: 0.5912439157417164
epoch 35 time used: 19  seconds  train loss: 0.5452170882421741 validation loss: 0.5909396854799185
epoch 36 time used: 19  seconds  train loss: 0.543389803824011 validation loss: 0.5935346675452902
epoch 37 time used: 19  seconds  train loss: 0.5405326957044696 validation loss: 0.5899942483178419
epoch 38 time used: 19  seconds  train loss: 0.5389842962472571 validation loss: 0.5909489808390983
epoch 39 time used: 19  seconds  train loss: 0.5401111451185614 validation loss: 0.5896566658470761
epoch 40 time used: 19  seconds  train loss: 0.5372558174228261 validation loss: 0.5843382955190555
epoch 41 time used: 19  seconds  train loss: 0.5366523908517439 validation loss: 0.5879315060762623
epoch 42 time used: 19  seconds  train loss: 0.5370859717407064 validation loss: 0.5882844767760281
epoch 43 time used: 19  seconds  train loss: 0.5362979795990425 validation loss: 0.5879609866521844
epoch 44 time used: 19  seconds  train loss: 0.5352588101776362 validation loss: 0.5896560557149536
epoch 45 time used: 19  seconds  train loss: 0.5382666487781964 validation loss: 0.5865618619159679
epoch 46 time used: 19  seconds  train loss: 0.5338543024799054 validation loss: 0.5861876710730406
epoch 47 time used: 19  seconds  train loss: 0.536618375718848 validation loss: 0.5845969304516541
epoch 48 time used: 19  seconds  train loss: 0.5315191468507433 validation loss: 0.5862660805384318
epoch 49 time used: 19  seconds  train loss: 0.5316308251824522 validation loss: 0.583754495601749
epoch 50 time used: 19  seconds  train loss: 0.5314987802912466 validation loss: 0.5837549582049621
epoch 51 time used: 19  seconds  train loss: 0.5307124213846784 validation loss: 0.5865612504494131
epoch 52 time used: 19  seconds  train loss: 0.5304642986946052 validation loss: 0.585996210130293
epoch 53 time used: 19  seconds  train loss: 0.5298296637928502 validation loss: 0.5850528256217046
epoch 54 time used: 19  seconds  train loss: 0.5286069874403996 validation loss: 0.5876742272234675
epoch 55 time used: 19  seconds  train loss: 0.5283198593181703 validation loss: 0.5872716242401161
epoch 56 time used: 19  seconds  train loss: 0.527548853652406 validation loss: 0.586863057826882
epoch 57 time used: 19  seconds  train loss: 0.5282420780546804 validation loss: 0.5958019846410894
epoch 58 time used: 19  seconds  train loss: 0.5282708086380749 validation loss: 0.5846591741587985
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.2206218963e-01, 0.5220621896
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 19.8488389070, 4.4552035764, 3.3945423114, 30.2978545427
Model Training Ended ... Mon May 30 23:40:42 2022
pred_SZTAXI_GraphWaveNet_2205302320 testing started Mon May 30 23:40:42 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 23:40:42 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.1195155618e-01, 0.5119515562
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9686589978, 4.5791548344, 3.5033528867, 33.2868546247
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.0553770675, 4.1298156215, 3.2182387259, 31.0116887093
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.9211140053, 4.2333336752, 3.2847561986, 31.5889328718
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.6178164169, 4.3148367775, 3.3422165216, 32.0020467043
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.4083293215, 4.4054885452, 3.4023851439, 32.5138896704
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.2110454379, 4.4956696318, 3.4546158136, 32.9734444618
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9463623239, 4.5767196029, 3.5076563774, 33.4446847439
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.4702170802, 4.6335965599, 3.5439165226, 33.6802154779
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.1026742213, 4.7013481281, 3.5843410730, 33.9516878128
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.7282868175, 4.7674193037, 3.6330753297, 34.3132078648
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.1991727611, 4.8165519577, 3.6579950404, 34.4167202711
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7153965049, 4.8698456346, 3.6883486044, 34.6415072680
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2984269885, 4.9293434642, 3.7261854452, 34.9312782288
Model Testing Ended ... Mon May 30 23:40:47 2022
