../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_10.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310256 training started Tue May 31 02:56:08 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:56:08 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6852645723951999 validation loss: 0.690724641677752
epoch 1 time used: 19  seconds  train loss: 0.6510947474290433 validation loss: 0.6900723280005194
epoch 2 time used: 19  seconds  train loss: 0.6401343803487156 validation loss: 0.6721241107924067
epoch 3 time used: 19  seconds  train loss: 0.6322002431237341 validation loss: 0.6935573733268092
epoch 4 time used: 19  seconds  train loss: 0.6274918338991331 validation loss: 0.663281618066095
epoch 5 time used: 19  seconds  train loss: 0.6235470425014306 validation loss: 0.6742578733026685
epoch 6 time used: 19  seconds  train loss: 0.6189560231833505 validation loss: 0.6745789862094234
epoch 7 time used: 19  seconds  train loss: 0.6170284092680658 validation loss: 0.6564148682266918
epoch 8 time used: 19  seconds  train loss: 0.6140021818291242 validation loss: 0.6534816573804884
epoch 9 time used: 19  seconds  train loss: 0.6125084562796786 validation loss: 0.666948105565351
epoch 10 time used: 19  seconds  train loss: 0.6105627978000668 validation loss: 0.6470921696418553
epoch 11 time used: 19  seconds  train loss: 0.6067267555430808 validation loss: 0.6590519749110018
epoch 12 time used: 19  seconds  train loss: 0.6055533704513506 validation loss: 0.6402439006525485
epoch 13 time used: 19  seconds  train loss: 0.6037381545747835 validation loss: 0.647761394431935
epoch 14 time used: 19  seconds  train loss: 0.6026503809146149 validation loss: 0.6623519392155889
epoch 15 time used: 19  seconds  train loss: 0.6020407704676198 validation loss: 0.6466147552675275
epoch 16 time used: 19  seconds  train loss: 0.6020839321579398 validation loss: 0.6423977324322089
epoch 17 time used: 19  seconds  train loss: 0.5989033511997456 validation loss: 0.6389351202480829
epoch 18 time used: 19  seconds  train loss: 0.596877564407175 validation loss: 0.6425347102815239
epoch 19 time used: 19  seconds  train loss: 0.594839414102085 validation loss: 0.6329104510409322
epoch 20 time used: 19  seconds  train loss: 0.5955685043063645 validation loss: 0.6501712440258235
epoch 21 time used: 19  seconds  train loss: 0.5917140957641059 validation loss: 0.6478360072890325
epoch 22 time used: 19  seconds  train loss: 0.5923148362260116 validation loss: 0.6337098956701175
epoch 23 time used: 19  seconds  train loss: 0.5894097116051155 validation loss: 0.6415936312272181
epoch 24 time used: 19  seconds  train loss: 0.5866552111434394 validation loss: 0.6367499949920237
epoch 25 time used: 19  seconds  train loss: 0.5855274126675526 validation loss: 0.6360979166196946
epoch 26 time used: 19  seconds  train loss: 0.5832242687599757 validation loss: 0.6311672522653988
epoch 27 time used: 19  seconds  train loss: 0.5807820579744505 validation loss: 0.6243167116274289
epoch 28 time used: 19  seconds  train loss: 0.5785341647322453 validation loss: 0.6329431219480524
epoch 29 time used: 19  seconds  train loss: 0.5775783558827885 validation loss: 0.629177186026502
epoch 30 time used: 19  seconds  train loss: 0.5759404593307637 validation loss: 0.6340336099785951
epoch 31 time used: 19  seconds  train loss: 0.5741337541156948 validation loss: 0.641672788567804
epoch 32 time used: 19  seconds  train loss: 0.5737001573717272 validation loss: 0.622501758645423
epoch 33 time used: 19  seconds  train loss: 0.5702575511308348 validation loss: 0.6222356723908761
epoch 34 time used: 19  seconds  train loss: 0.5680736455096629 validation loss: 0.6308952750851266
epoch 35 time used: 19  seconds  train loss: 0.5688117344043672 validation loss: 0.6269977697685584
epoch 36 time used: 19  seconds  train loss: 0.5647987093389628 validation loss: 0.6189118036583289
epoch 37 time used: 19  seconds  train loss: 0.5634820994577909 validation loss: 0.6170726207951408
epoch 38 time used: 19  seconds  train loss: 0.561297069996553 validation loss: 0.6274723200062614
epoch 39 time used: 19  seconds  train loss: 0.5602738580018664 validation loss: 0.6174993639561668
epoch 40 time used: 19  seconds  train loss: 0.5591137028520511 validation loss: 0.6187697598590186
epoch 41 time used: 19  seconds  train loss: 0.5568080391856719 validation loss: 0.6131453907015312
epoch 42 time used: 19  seconds  train loss: 0.5546283038547674 validation loss: 0.6146814182623109
epoch 43 time used: 19  seconds  train loss: 0.5536723375150863 validation loss: 0.627096024318714
epoch 44 time used: 19  seconds  train loss: 0.553252553617632 validation loss: 0.6189890883455229
epoch 45 time used: 19  seconds  train loss: 0.5534117052683959 validation loss: 0.6109513717504284
epoch 46 time used: 19  seconds  train loss: 0.549739490532095 validation loss: 0.6120300794122231
epoch 47 time used: 19  seconds  train loss: 0.5478854057714238 validation loss: 0.6113658176725777
epoch 48 time used: 19  seconds  train loss: 0.5468415806168004 validation loss: 0.6118647129974555
epoch 49 time used: 19  seconds  train loss: 0.5464554950488919 validation loss: 0.6089623825467048
epoch 50 time used: 19  seconds  train loss: 0.5452136744137001 validation loss: 0.6134533117066568
epoch 51 time used: 19  seconds  train loss: 0.5444475703185178 validation loss: 0.6165290003392234
epoch 52 time used: 19  seconds  train loss: 0.5429198964052485 validation loss: 0.6158619798831085
epoch 53 time used: 19  seconds  train loss: 0.5422791321450582 validation loss: 0.608877273044776
epoch 54 time used: 19  seconds  train loss: 0.5407511829312461 validation loss: 0.6142891360752618
epoch 55 time used: 19  seconds  train loss: 0.540397763676189 validation loss: 0.6134809062848636
epoch 56 time used: 19  seconds  train loss: 0.5390711369928222 validation loss: 0.6180686431737682
epoch 57 time used: 19  seconds  train loss: 0.5379710552702588 validation loss: 0.618650266780189
epoch 58 time used: 19  seconds  train loss: 0.5381111424644166 validation loss: 0.6139552078733397
epoch 59 time used: 19  seconds  train loss: 0.536973039422232 validation loss: 0.6139177573260977
epoch 60 time used: 19  seconds  train loss: 0.5348306996045716 validation loss: 0.6152669419696675
epoch 61 time used: 19  seconds  train loss: 0.5348885780038739 validation loss: 0.6117170169875397
epoch 62 time used: 19  seconds  train loss: 0.5336466460445018 validation loss: 0.61131482456454
epoch 63 time used: 19  seconds  train loss: 0.5334016289853439 validation loss: 0.6087400741245023
epoch 64 time used: 19  seconds  train loss: 0.5321313540847339 validation loss: 0.6166833339638971
epoch 65 time used: 19  seconds  train loss: 0.5320333568842958 validation loss: 0.6103479276545605
epoch 66 time used: 19  seconds  train loss: 0.5306101391359549 validation loss: 0.6151445011297861
epoch 67 time used: 19  seconds  train loss: 0.5295752065619228 validation loss: 0.615313714416466
epoch 68 time used: 19  seconds  train loss: 0.5289837974064041 validation loss: 0.6123816833567264
epoch 69 time used: 19  seconds  train loss: 0.5284825297202359 validation loss: 0.6065460305605361
epoch 70 time used: 19  seconds  train loss: 0.5282105134527171 validation loss: 0.6065779111871672
epoch 71 time used: 19  seconds  train loss: 0.5267987820620558 validation loss: 0.6094589716759488
epoch 72 time used: 19  seconds  train loss: 0.5263779191340017 validation loss: 0.6118880808353424
epoch 73 time used: 19  seconds  train loss: 0.5261562502655501 validation loss: 0.6149741621752877
epoch 74 time used: 19  seconds  train loss: 0.5260999780969633 validation loss: 0.617588786343437
epoch 75 time used: 19  seconds  train loss: 0.5251661861265028 validation loss: 0.6092434658933041
epoch 76 time used: 19  seconds  train loss: 0.524374119502891 validation loss: 0.6135829865042843
epoch 77 time used: 19  seconds  train loss: 0.5235034953564363 validation loss: 0.6160783485986701
epoch 78 time used: 19  seconds  train loss: 0.5238224508328254 validation loss: 0.6114483490512146
Early stopping at epoch: 79
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.1926543851e-01, 0.5192654385
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 20.2561928195, 4.5006880385, 3.4151867852, 30.4954677820
Model Training Ended ... Tue May 31 03:22:41 2022
pred_SZTAXI_GraphWaveNet_2205310256 testing started Tue May 31 03:22:41 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 03:22:41 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2177411325e-01, 0.5217741133
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.5645842335, 4.6437683226, 3.5579666267, 33.5603952408
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0256278386, 4.2456598826, 3.3005557357, 31.6568017006
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.7146371753, 4.3260417445, 3.3538858108, 31.9703459740
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.4074054114, 4.4053836849, 3.4005135458, 32.3482096195
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.0241858935, 4.4748392031, 3.4469951299, 32.7125698328
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.6261971267, 4.5416073285, 3.4901841434, 33.0213785172
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.2280226824, 4.6073878372, 3.5378600692, 33.3998382092
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.9671232874, 4.6869097802, 3.5949723864, 33.8724911213
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.6161372736, 4.7556426772, 3.6426215066, 34.2323809862
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.1157921590, 4.8078885344, 3.6737445182, 34.4404786825
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.6987936912, 4.8681406811, 3.7128020474, 34.7137570381
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3759042657, 4.9371959922, 3.7532993294, 35.0501805544
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0239414040, 5.0023935675, 3.7916319438, 35.3330463171
Model Testing Ended ... Tue May 31 03:22:46 2022
