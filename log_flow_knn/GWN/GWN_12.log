../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_12.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310347 training started Tue May 31 03:47:38 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 03:47:38 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6839381265606345 validation loss: 0.6880563783704938
epoch 1 time used: 19  seconds  train loss: 0.6499019573372424 validation loss: 0.6859537520218845
epoch 2 time used: 19  seconds  train loss: 0.6398880669097303 validation loss: 0.6702634951665034
epoch 3 time used: 19  seconds  train loss: 0.6312298059124356 validation loss: 0.6981388621069305
epoch 4 time used: 19  seconds  train loss: 0.6271524888862078 validation loss: 0.6672858658121593
epoch 5 time used: 19  seconds  train loss: 0.6218213997728286 validation loss: 0.6619627010169907
epoch 6 time used: 19  seconds  train loss: 0.618054935085994 validation loss: 0.6750468451585343
epoch 7 time used: 19  seconds  train loss: 0.6173456808920436 validation loss: 0.6543420194393367
epoch 8 time used: 19  seconds  train loss: 0.6135378435020935 validation loss: 0.6515717715469759
epoch 9 time used: 19  seconds  train loss: 0.611924861182868 validation loss: 0.66526912338105
epoch 10 time used: 19  seconds  train loss: 0.609306167996625 validation loss: 0.6513492847556499
epoch 11 time used: 19  seconds  train loss: 0.6060865702873274 validation loss: 0.6537345905802143
epoch 12 time used: 19  seconds  train loss: 0.6059218406846818 validation loss: 0.6410082338461235
epoch 13 time used: 19  seconds  train loss: 0.6035104635599498 validation loss: 0.6547748867552079
epoch 14 time used: 19  seconds  train loss: 0.6025060036273973 validation loss: 0.6514529333778875
epoch 15 time used: 19  seconds  train loss: 0.6015529871665227 validation loss: 0.6465689483566663
epoch 16 time used: 19  seconds  train loss: 0.600500258324326 validation loss: 0.6377950198021695
epoch 17 time used: 19  seconds  train loss: 0.5981213847230882 validation loss: 0.6389716181589004
epoch 18 time used: 19  seconds  train loss: 0.5967445972125188 validation loss: 0.6405701115356749
epoch 19 time used: 19  seconds  train loss: 0.5948864247008713 validation loss: 0.6332886204197632
epoch 20 time used: 19  seconds  train loss: 0.5960362802867699 validation loss: 0.6540728650282864
epoch 21 time used: 19  seconds  train loss: 0.5921624925194221 validation loss: 0.6346907178264353
epoch 22 time used: 19  seconds  train loss: 0.5930745964538661 validation loss: 0.6365691610236666
epoch 23 time used: 19  seconds  train loss: 0.5900858689846727 validation loss: 0.6435676309006724
epoch 24 time used: 19  seconds  train loss: 0.5872271845215246 validation loss: 0.6375596413564919
epoch 25 time used: 19  seconds  train loss: 0.5870161887846495 validation loss: 0.6340044787274072
epoch 26 time used: 19  seconds  train loss: 0.58392565603107 validation loss: 0.6368103733110191
epoch 27 time used: 19  seconds  train loss: 0.5824269625235079 validation loss: 0.6259677244063041
epoch 28 time used: 19  seconds  train loss: 0.5806340040217762 validation loss: 0.6356045535547816
epoch 29 time used: 19  seconds  train loss: 0.5796136870492743 validation loss: 0.6375229305295802
epoch 30 time used: 19  seconds  train loss: 0.5778089709166613 validation loss: 0.6305207817708675
epoch 31 time used: 19  seconds  train loss: 0.5753912919785186 validation loss: 0.6383094790563062
epoch 32 time used: 19  seconds  train loss: 0.5765580423017315 validation loss: 0.6223434309164683
epoch 33 time used: 19  seconds  train loss: 0.5720828908944706 validation loss: 0.6243520874289138
epoch 34 time used: 19  seconds  train loss: 0.5706811044497646 validation loss: 0.6231930177306655
epoch 35 time used: 19  seconds  train loss: 0.5696670985323606 validation loss: 0.6287828992255291
epoch 36 time used: 19  seconds  train loss: 0.5671984622013857 validation loss: 0.6234165137976556
epoch 37 time used: 19  seconds  train loss: 0.565855212944161 validation loss: 0.6171807943291925
epoch 38 time used: 19  seconds  train loss: 0.5634846886564284 validation loss: 0.6221682705096344
epoch 39 time used: 19  seconds  train loss: 0.562293980063958 validation loss: 0.623006235900803
epoch 40 time used: 19  seconds  train loss: 0.5623088226379406 validation loss: 0.6231701824795547
epoch 41 time used: 19  seconds  train loss: 0.5603623381719142 validation loss: 0.6266914625369494
epoch 42 time used: 19  seconds  train loss: 0.558260726555652 validation loss: 0.6125998550386571
epoch 43 time used: 19  seconds  train loss: 0.5565800295445862 validation loss: 0.6208474354364386
epoch 44 time used: 19  seconds  train loss: 0.5557238118746881 validation loss: 0.6220214002168001
epoch 45 time used: 19  seconds  train loss: 0.5573871799163086 validation loss: 0.6141494094435849
epoch 46 time used: 19  seconds  train loss: 0.5523037217334866 validation loss: 0.6101365317752705
epoch 47 time used: 19  seconds  train loss: 0.5511558441230616 validation loss: 0.6157468889483172
epoch 48 time used: 19  seconds  train loss: 0.5500016861077223 validation loss: 0.614224621164265
epoch 49 time used: 19  seconds  train loss: 0.5493147580925465 validation loss: 0.6125787822761346
epoch 50 time used: 19  seconds  train loss: 0.548087051125034 validation loss: 0.616485811288084
epoch 51 time used: 19  seconds  train loss: 0.5477056921291487 validation loss: 0.6224341143423052
epoch 52 time used: 19  seconds  train loss: 0.546036503308189 validation loss: 0.6117131416477374
epoch 53 time used: 19  seconds  train loss: 0.5453096848633008 validation loss: 0.6102077984691259
epoch 54 time used: 19  seconds  train loss: 0.5441302016144287 validation loss: 0.6156891809767159
epoch 55 time used: 19  seconds  train loss: 0.5425094433902508 validation loss: 0.6139945625072688
Early stopping at epoch: 56
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4686526426e-01, 0.5468652643
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.9486223251, 4.7904720357, 3.6309180248, 31.3960134983
Model Training Ended ... Tue May 31 04:06:39 2022
pred_SZTAXI_GraphWaveNet_2205310347 testing started Tue May 31 04:06:39 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:06:39 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3119868208e-01, 0.5311986821
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0386796644, 4.6945372151, 3.5734118849, 33.5952430964
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.6809754933, 4.2048752054, 3.2650407431, 31.2129259109
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.5186153827, 4.3033260837, 3.3315137619, 31.7083746195
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.3469950858, 4.3985219206, 3.3900687824, 32.1419268847
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.0920376133, 4.4824142617, 3.4416468695, 32.5994223356
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.8398801152, 4.5650717536, 3.4971427443, 33.0315589905
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.5138199620, 4.6382992532, 3.5414442242, 33.3608567715
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2961595244, 4.7218809308, 3.5925297191, 33.7336272001
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.2195732420, 4.8186692397, 3.6579998791, 34.2619508505
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.8787159219, 4.8865853028, 3.6997152979, 34.5590531826
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.7741988169, 4.9773686639, 3.7566450618, 34.9993348122
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.8063457430, 5.0799946597, 3.8297465547, 35.5838179588
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.5587110925, 5.1535144409, 3.8816909464, 35.9830200672
Model Testing Ended ... Tue May 31 04:06:44 2022
