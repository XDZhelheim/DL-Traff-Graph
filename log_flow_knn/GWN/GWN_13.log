../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_13.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310406 training started Tue May 31 04:06:49 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 04:06:49 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6837749840694335 validation loss: 0.6863028671017927
epoch 1 time used: 19  seconds  train loss: 0.6504817671999653 validation loss: 0.6878835523306434
epoch 2 time used: 19  seconds  train loss: 0.6397898588885963 validation loss: 0.6717985288717261
epoch 3 time used: 19  seconds  train loss: 0.631386867034147 validation loss: 0.6993804167752242
epoch 4 time used: 19  seconds  train loss: 0.6268727211321401 validation loss: 0.6688002063267267
epoch 5 time used: 19  seconds  train loss: 0.6214665535673138 validation loss: 0.6599695688456445
epoch 6 time used: 19  seconds  train loss: 0.6178038318669304 validation loss: 0.6747736302181263
epoch 7 time used: 19  seconds  train loss: 0.617380476693171 validation loss: 0.6543769873493347
epoch 8 time used: 19  seconds  train loss: 0.6138134981117411 validation loss: 0.6539399829966512
epoch 9 time used: 19  seconds  train loss: 0.6122874790540291 validation loss: 0.6652773912273237
epoch 10 time used: 19  seconds  train loss: 0.609327670181459 validation loss: 0.6515947500271584
epoch 11 time used: 19  seconds  train loss: 0.6061102778440179 validation loss: 0.6529169631241566
epoch 12 time used: 19  seconds  train loss: 0.6062342656794856 validation loss: 0.6394042408288415
epoch 13 time used: 19  seconds  train loss: 0.6038025711288154 validation loss: 0.6534463508212152
epoch 14 time used: 19  seconds  train loss: 0.6025667344862502 validation loss: 0.6534649548838981
epoch 15 time used: 19  seconds  train loss: 0.6021232601589024 validation loss: 0.6444875749189463
epoch 16 time used: 19  seconds  train loss: 0.6025451595125293 validation loss: 0.6395033096792686
epoch 17 time used: 19  seconds  train loss: 0.6002651525934255 validation loss: 0.64043477785528
epoch 18 time used: 19  seconds  train loss: 0.5974701132577649 validation loss: 0.6404504099888588
epoch 19 time used: 19  seconds  train loss: 0.5956226031098563 validation loss: 0.6341816753297302
epoch 20 time used: 19  seconds  train loss: 0.5962349596098171 validation loss: 0.6503041460739439
epoch 21 time used: 19  seconds  train loss: 0.592688396467084 validation loss: 0.6386062717852901
epoch 22 time used: 19  seconds  train loss: 0.5936847153632434 validation loss: 0.6355472690430447
epoch 23 time used: 19  seconds  train loss: 0.5911480577538057 validation loss: 0.6379407994189665
epoch 24 time used: 19  seconds  train loss: 0.5883671862641575 validation loss: 0.6369532311140601
epoch 25 time used: 19  seconds  train loss: 0.5886555159753282 validation loss: 0.6357430255235131
epoch 26 time used: 19  seconds  train loss: 0.5855114041148005 validation loss: 0.6319790414316737
epoch 27 time used: 19  seconds  train loss: 0.5840579152615956 validation loss: 0.6267466485796876
epoch 28 time used: 19  seconds  train loss: 0.5822265594561782 validation loss: 0.6347149376252398
epoch 29 time used: 19  seconds  train loss: 0.5812936809290185 validation loss: 0.6371477403450961
epoch 30 time used: 19  seconds  train loss: 0.5801706540465864 validation loss: 0.634198387167347
epoch 31 time used: 19  seconds  train loss: 0.578302190025704 validation loss: 0.6402817659117096
epoch 32 time used: 19  seconds  train loss: 0.5778524098152117 validation loss: 0.6316964798305759
epoch 33 time used: 19  seconds  train loss: 0.5743955484409929 validation loss: 0.6300252800557151
epoch 34 time used: 19  seconds  train loss: 0.5732979069478481 validation loss: 0.6245191214393028
epoch 35 time used: 19  seconds  train loss: 0.5727618616471759 validation loss: 0.6276173799192134
epoch 36 time used: 19  seconds  train loss: 0.5701832185005226 validation loss: 0.625340140281032
epoch 37 time used: 19  seconds  train loss: 0.5690848626418948 validation loss: 0.6224708136041366
epoch 38 time used: 19  seconds  train loss: 0.5676803610911579 validation loss: 0.6268448817789258
epoch 39 time used: 19  seconds  train loss: 0.5655761032999833 validation loss: 0.6232175239876135
epoch 40 time used: 19  seconds  train loss: 0.5646806396596971 validation loss: 0.6242311795552572
epoch 41 time used: 19  seconds  train loss: 0.5631910180129842 validation loss: 0.6239434212297943
epoch 42 time used: 19  seconds  train loss: 0.5608722000339122 validation loss: 0.6163448219868675
epoch 43 time used: 19  seconds  train loss: 0.560061407207934 validation loss: 0.6218409351448515
epoch 44 time used: 19  seconds  train loss: 0.5590474498729787 validation loss: 0.630187183322005
epoch 45 time used: 19  seconds  train loss: 0.5613363146527564 validation loss: 0.6143848747756351
epoch 46 time used: 19  seconds  train loss: 0.5555346872270701 validation loss: 0.6135366093460007
epoch 47 time used: 19  seconds  train loss: 0.5542974295690761 validation loss: 0.6144188909388301
epoch 48 time used: 19  seconds  train loss: 0.553100103080527 validation loss: 0.620756246409013
epoch 49 time used: 19  seconds  train loss: 0.552118423992336 validation loss: 0.6182146985732501
epoch 50 time used: 19  seconds  train loss: 0.5502584480798431 validation loss: 0.6238347211880471
epoch 51 time used: 19  seconds  train loss: 0.550059022808482 validation loss: 0.6175967460841089
epoch 52 time used: 19  seconds  train loss: 0.5489058959195827 validation loss: 0.615394407243871
epoch 53 time used: 19  seconds  train loss: 0.547574870447346 validation loss: 0.6129778330005816
epoch 54 time used: 19  seconds  train loss: 0.5467460910083559 validation loss: 0.6181502193953861
epoch 55 time used: 19  seconds  train loss: 0.5456370428140946 validation loss: 0.6200031756761655
epoch 56 time used: 19  seconds  train loss: 0.5445857447377309 validation loss: 0.6244313417382501
epoch 57 time used: 19  seconds  train loss: 0.5431539362897914 validation loss: 0.6259552753386806
epoch 58 time used: 19  seconds  train loss: 0.5436828030461438 validation loss: 0.6105230203018853
epoch 59 time used: 19  seconds  train loss: 0.542378184127265 validation loss: 0.6171260163262116
epoch 60 time used: 19  seconds  train loss: 0.5399108151792632 validation loss: 0.6196197464098385
epoch 61 time used: 19  seconds  train loss: 0.540535707901077 validation loss: 0.6079412188696031
epoch 62 time used: 19  seconds  train loss: 0.5378575249128627 validation loss: 0.614551124288075
epoch 63 time used: 19  seconds  train loss: 0.5370952035929706 validation loss: 0.6113727712512609
epoch 64 time used: 19  seconds  train loss: 0.5359770453417114 validation loss: 0.6068242124064052
epoch 65 time used: 19  seconds  train loss: 0.5367911412230936 validation loss: 0.6114983082707248
epoch 66 time used: 19  seconds  train loss: 0.5355631105421617 validation loss: 0.607923503835403
epoch 67 time used: 19  seconds  train loss: 0.5335864584951279 validation loss: 0.6080143908363077
epoch 68 time used: 19  seconds  train loss: 0.5347461294313922 validation loss: 0.6078653486806955
epoch 69 time used: 19  seconds  train loss: 0.5320148516345669 validation loss: 0.6161143696723292
epoch 70 time used: 19  seconds  train loss: 0.5320578076761444 validation loss: 0.605448360763379
epoch 71 time used: 19  seconds  train loss: 0.533439459197043 validation loss: 0.6135781054473042
epoch 72 time used: 19  seconds  train loss: 0.5300338565031462 validation loss: 0.6087040692123015
epoch 73 time used: 19  seconds  train loss: 0.5291874068729568 validation loss: 0.6107120273718193
epoch 74 time used: 19  seconds  train loss: 0.5298006582904506 validation loss: 0.6126291152849719
epoch 75 time used: 19  seconds  train loss: 0.528892481564458 validation loss: 0.6123208750539751
epoch 76 time used: 19  seconds  train loss: 0.5279011348233285 validation loss: 0.612407936978696
epoch 77 time used: 19  seconds  train loss: 0.5277566081005682 validation loss: 0.6085806800358331
epoch 78 time used: 19  seconds  train loss: 0.5272367182022138 validation loss: 0.6108330930050333
epoch 79 time used: 19  seconds  train loss: 0.5267995558626113 validation loss: 0.607484500206525
Early stopping at epoch: 80
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.2398624936e-01, 0.5239862494
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 20.7756999771, 4.5580368556, 3.4676853572, 30.8185994625
Model Training Ended ... Tue May 31 04:33:42 2022
pred_SZTAXI_GraphWaveNet_2205310406 testing started Tue May 31 04:33:42 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:33:42 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2536005221e-01, 0.5253600522
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.7865678571, 4.6676083659, 3.5754793168, 33.6627602577
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0852290506, 4.2526731653, 3.3133873656, 31.7864000797
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8742147917, 4.3444464310, 3.3757496130, 32.2194963694
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5084203938, 4.4168337521, 3.4203374799, 32.4999064207
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.0390925783, 4.4765045044, 3.4527852891, 32.7195018530
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.7521205422, 4.5554495434, 3.5076052264, 33.1886649132
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.4190536917, 4.6280723516, 3.5588452524, 33.5613369942
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0732093491, 4.6982134210, 3.6024096671, 33.8774770498
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.7311126233, 4.7677156609, 3.6404787845, 34.1510444880
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.3469693874, 4.8318701749, 3.6827845969, 34.4583243132
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3426183343, 4.9338239059, 3.7529691402, 34.9887460470
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.8212379792, 4.9820917273, 3.7796832377, 35.1115077734
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.4975937232, 5.0495142067, 3.8222759888, 35.4166150093
Model Testing Ended ... Tue May 31 04:33:48 2022
