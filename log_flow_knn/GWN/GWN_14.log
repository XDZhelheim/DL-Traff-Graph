../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_14.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310433 training started Tue May 31 04:33:53 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 04:33:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.683422829187442 validation loss: 0.6863710362816331
epoch 1 time used: 19  seconds  train loss: 0.6501141584360413 validation loss: 0.6869679719061401
epoch 2 time used: 19  seconds  train loss: 0.6397674780651651 validation loss: 0.6726780043016025
epoch 3 time used: 19  seconds  train loss: 0.6312690414541307 validation loss: 0.6918318325014257
epoch 4 time used: 19  seconds  train loss: 0.6267798526019155 validation loss: 0.6685075383281234
epoch 5 time used: 19  seconds  train loss: 0.6213578390193358 validation loss: 0.6552081840548349
epoch 6 time used: 19  seconds  train loss: 0.6179766436643994 validation loss: 0.6717652761521031
epoch 7 time used: 19  seconds  train loss: 0.6181790553997794 validation loss: 0.6527532433989036
epoch 8 time used: 19  seconds  train loss: 0.6135381427971093 validation loss: 0.653393621764966
epoch 9 time used: 19  seconds  train loss: 0.6123950209251339 validation loss: 0.6601408909802413
epoch 10 time used: 19  seconds  train loss: 0.6097001570726017 validation loss: 0.6516088096063528
epoch 11 time used: 19  seconds  train loss: 0.6062354301321049 validation loss: 0.6488781592146081
epoch 12 time used: 19  seconds  train loss: 0.6067519048030142 validation loss: 0.6391565153254798
epoch 13 time used: 19  seconds  train loss: 0.6039685274594878 validation loss: 0.6517165190544888
epoch 14 time used: 19  seconds  train loss: 0.6031309297549436 validation loss: 0.6703341535074794
epoch 15 time used: 19  seconds  train loss: 0.604840658297749 validation loss: 0.6447882251953011
epoch 16 time used: 19  seconds  train loss: 0.6021837099517562 validation loss: 0.6373154197759296
epoch 17 time used: 19  seconds  train loss: 0.5994020498663738 validation loss: 0.6415163973967234
epoch 18 time used: 19  seconds  train loss: 0.5976036331731598 validation loss: 0.6402117360883685
epoch 19 time used: 19  seconds  train loss: 0.5962748776798058 validation loss: 0.6349730657700875
epoch 20 time used: 19  seconds  train loss: 0.5968147553556504 validation loss: 0.6533253584335099
epoch 21 time used: 19  seconds  train loss: 0.5934860607977442 validation loss: 0.6422178699305995
epoch 22 time used: 19  seconds  train loss: 0.594822736586819 validation loss: 0.6352371187945504
epoch 23 time used: 19  seconds  train loss: 0.5918869111649852 validation loss: 0.642235348473734
epoch 24 time used: 19  seconds  train loss: 0.5888644733266166 validation loss: 0.640530346341394
epoch 25 time used: 19  seconds  train loss: 0.5888995305233625 validation loss: 0.6358273948603008
epoch 26 time used: 19  seconds  train loss: 0.5861073207549995 validation loss: 0.6325896957620459
epoch 27 time used: 19  seconds  train loss: 0.584140604708985 validation loss: 0.6299758277722259
epoch 28 time used: 19  seconds  train loss: 0.5826775317595659 validation loss: 0.633033679492438
epoch 29 time used: 19  seconds  train loss: 0.5824422840543018 validation loss: 0.6350341744683868
epoch 30 time used: 19  seconds  train loss: 0.5810491139146037 validation loss: 0.631736347627877
epoch 31 time used: 19  seconds  train loss: 0.5789248556704134 validation loss: 0.6362216010022519
epoch 32 time used: 19  seconds  train loss: 0.5783542094495184 validation loss: 0.6287516229484805
epoch 33 time used: 19  seconds  train loss: 0.5761444462651379 validation loss: 0.6325353321744435
epoch 34 time used: 19  seconds  train loss: 0.5738705356378813 validation loss: 0.6244955695980224
epoch 35 time used: 19  seconds  train loss: 0.5740833354538908 validation loss: 0.6260296435498479
epoch 36 time used: 19  seconds  train loss: 0.5710835955814481 validation loss: 0.6257285303737393
epoch 37 time used: 19  seconds  train loss: 0.5700740722639971 validation loss: 0.6215172796996672
epoch 38 time used: 19  seconds  train loss: 0.5683625672823335 validation loss: 0.6281141018986109
epoch 39 time used: 19  seconds  train loss: 0.5667723988740576 validation loss: 0.6238046241043812
epoch 40 time used: 19  seconds  train loss: 0.5658106349440422 validation loss: 0.6267431283471596
epoch 41 time used: 19  seconds  train loss: 0.5648037839580227 validation loss: 0.6224211654556331
epoch 42 time used: 19  seconds  train loss: 0.5626429109112128 validation loss: 0.6188100348064556
epoch 43 time used: 19  seconds  train loss: 0.5613554567734513 validation loss: 0.6283465638682617
epoch 44 time used: 19  seconds  train loss: 0.5605299257452084 validation loss: 0.6313947193065093
epoch 45 time used: 19  seconds  train loss: 0.5631912669026495 validation loss: 0.6164200448278171
epoch 46 time used: 19  seconds  train loss: 0.557085855035999 validation loss: 0.6147644469394019
epoch 47 time used: 19  seconds  train loss: 0.5556506879129586 validation loss: 0.6160169217123914
epoch 48 time used: 19  seconds  train loss: 0.5556287096540415 validation loss: 0.6178143771726694
epoch 49 time used: 19  seconds  train loss: 0.5535453235780871 validation loss: 0.6120112917909575
epoch 50 time used: 19  seconds  train loss: 0.5517810321125503 validation loss: 0.6197458197228352
epoch 51 time used: 19  seconds  train loss: 0.5519066508938884 validation loss: 0.6216822580911627
epoch 52 time used: 19  seconds  train loss: 0.551246168264115 validation loss: 0.6164739948896626
epoch 53 time used: 19  seconds  train loss: 0.5486492155117128 validation loss: 0.6146994405124911
epoch 54 time used: 19  seconds  train loss: 0.5487106023608027 validation loss: 0.625514218759774
epoch 55 time used: 19  seconds  train loss: 0.5489974032933818 validation loss: 0.6255885472345115
epoch 56 time used: 19  seconds  train loss: 0.5475546793103387 validation loss: 0.6200225839567421
epoch 57 time used: 19  seconds  train loss: 0.5451007205595502 validation loss: 0.62515752291798
epoch 58 time used: 19  seconds  train loss: 0.5448592012671285 validation loss: 0.6152650063014149
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4033222485e-01, 0.5403322249
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.4164732740, 4.6277935643, 3.5119064230, 31.2826871872
Model Training Ended ... Tue May 31 04:53:58 2022
pred_SZTAXI_GraphWaveNet_2205310433 testing started Tue May 31 04:53:58 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:53:58 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3135451310e-01, 0.5313545131
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.4701470552, 4.7402686691, 3.6267769821, 34.0669661760
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.2878430502, 4.2764287730, 3.3283109893, 31.6514521837
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.9885509269, 4.3575854469, 3.3791334969, 32.1038007736
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.9124532006, 4.4623371904, 3.4507060241, 32.6310098171
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.8052550691, 4.5612777891, 3.5120254924, 33.0959767103
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.4235449580, 4.6285575461, 3.5545317213, 33.4932148457
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2124592441, 4.7130095739, 3.6125637831, 34.0009748936
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8341939906, 4.7785137847, 3.6586266491, 34.3668162823
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.5590292086, 4.8537644369, 3.7075167964, 34.7596883774
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2904377871, 4.9285330259, 3.7611676721, 35.1659625769
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.9406790871, 4.9940643856, 3.8029733521, 35.4494601488
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.7648441218, 5.0759082066, 3.8501214331, 35.8248084784
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.6800996323, 5.1652782725, 3.9076514168, 36.2926989794
Model Testing Ended ... Tue May 31 04:54:03 2022
