../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_15.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310454 training started Tue May 31 04:54:08 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 04:54:08 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6831351250282901 validation loss: 0.6858539885252862
epoch 1 time used: 19  seconds  train loss: 0.6499208457354632 validation loss: 0.6857181508742755
epoch 2 time used: 19  seconds  train loss: 0.639645805314798 validation loss: 0.6721582260001359
epoch 3 time used: 19  seconds  train loss: 0.6309901754852718 validation loss: 0.6903464548030303
epoch 4 time used: 19  seconds  train loss: 0.626479091125396 validation loss: 0.6668351556531232
epoch 5 time used: 19  seconds  train loss: 0.6210350351008039 validation loss: 0.6533223191897074
epoch 6 time used: 19  seconds  train loss: 0.6177500641532507 validation loss: 0.6701370783113129
epoch 7 time used: 19  seconds  train loss: 0.6175582695482127 validation loss: 0.6542287144198347
epoch 8 time used: 19  seconds  train loss: 0.6154415911834575 validation loss: 0.6566614833340716
epoch 9 time used: 19  seconds  train loss: 0.6123215785067248 validation loss: 0.6571843665630663
epoch 10 time used: 19  seconds  train loss: 0.6095318693355002 validation loss: 0.6533684905488693
epoch 11 time used: 19  seconds  train loss: 0.6062504621182871 validation loss: 0.6497618579745885
epoch 12 time used: 19  seconds  train loss: 0.6063547524415582 validation loss: 0.6396851480303712
epoch 13 time used: 19  seconds  train loss: 0.6040902821980364 validation loss: 0.6523919399104902
epoch 14 time used: 19  seconds  train loss: 0.602900788081998 validation loss: 0.6727600168825975
epoch 15 time used: 19  seconds  train loss: 0.6041968235080984 validation loss: 0.6437474139294221
epoch 16 time used: 19  seconds  train loss: 0.6019076613409929 validation loss: 0.6388778956375312
epoch 17 time used: 19  seconds  train loss: 0.5997712473102857 validation loss: 0.6410714481303941
epoch 18 time used: 19  seconds  train loss: 0.597918014014259 validation loss: 0.6401243862228014
epoch 19 time used: 19  seconds  train loss: 0.5965532373907216 validation loss: 0.6344689416944684
epoch 20 time used: 19  seconds  train loss: 0.597644864919345 validation loss: 0.6592889537858726
epoch 21 time used: 19  seconds  train loss: 0.5948563242704736 validation loss: 0.6395681820698639
epoch 22 time used: 19  seconds  train loss: 0.5949780410248389 validation loss: 0.6352422848269714
epoch 23 time used: 19  seconds  train loss: 0.5919861993613318 validation loss: 0.6430622748474577
epoch 24 time used: 19  seconds  train loss: 0.5899990674102967 validation loss: 0.6400516958379033
epoch 25 time used: 19  seconds  train loss: 0.5902714096804601 validation loss: 0.6328009998620446
epoch 26 time used: 19  seconds  train loss: 0.5872712295560715 validation loss: 0.6321355851728525
epoch 27 time used: 19  seconds  train loss: 0.5854833838271553 validation loss: 0.6324715709211814
epoch 28 time used: 19  seconds  train loss: 0.584249170287744 validation loss: 0.6370264422241135
epoch 29 time used: 19  seconds  train loss: 0.5839341632163372 validation loss: 0.6352286006680768
epoch 30 time used: 19  seconds  train loss: 0.5829797808510141 validation loss: 0.6327915013726078
epoch 31 time used: 19  seconds  train loss: 0.5804389710955395 validation loss: 0.6368003546895079
epoch 32 time used: 19  seconds  train loss: 0.5801378712376015 validation loss: 0.631914178975186
epoch 33 time used: 19  seconds  train loss: 0.5774635709027308 validation loss: 0.6337959834592259
epoch 34 time used: 19  seconds  train loss: 0.5769021617060535 validation loss: 0.6293922336540412
epoch 35 time used: 19  seconds  train loss: 0.5756320021569644 validation loss: 0.6256908540108904
epoch 36 time used: 19  seconds  train loss: 0.5732853897604799 validation loss: 0.6262341527203422
epoch 37 time used: 19  seconds  train loss: 0.5724043738451995 validation loss: 0.6242486767804445
epoch 38 time used: 19  seconds  train loss: 0.5715257399960568 validation loss: 0.62547621531273
epoch 39 time used: 19  seconds  train loss: 0.5690875227217315 validation loss: 0.6262452205022176
epoch 40 time used: 19  seconds  train loss: 0.5678778016041556 validation loss: 0.6279760237356916
epoch 41 time used: 19  seconds  train loss: 0.5663030652029925 validation loss: 0.6222551657785824
epoch 42 time used: 19  seconds  train loss: 0.5647604078859896 validation loss: 0.6230298778904018
epoch 43 time used: 19  seconds  train loss: 0.563686415192752 validation loss: 0.6336196953087897
epoch 44 time used: 19  seconds  train loss: 0.5624364702664263 validation loss: 0.6322435776689159
epoch 45 time used: 19  seconds  train loss: 0.5656627856650699 validation loss: 0.614263165056409
epoch 46 time used: 19  seconds  train loss: 0.558986617525136 validation loss: 0.6167816498979407
epoch 47 time used: 19  seconds  train loss: 0.5575711549939336 validation loss: 0.6146527463523903
epoch 48 time used: 19  seconds  train loss: 0.5560292583780302 validation loss: 0.6201072212178909
epoch 49 time used: 19  seconds  train loss: 0.5553967351594656 validation loss: 0.6119485550851964
epoch 50 time used: 19  seconds  train loss: 0.5537265741808146 validation loss: 0.6145914185106458
epoch 51 time used: 19  seconds  train loss: 0.5528492211956387 validation loss: 0.6227018142220986
epoch 52 time used: 19  seconds  train loss: 0.5530500562058743 validation loss: 0.617750297731428
epoch 53 time used: 19  seconds  train loss: 0.5512839771944971 validation loss: 0.6147198932087836
epoch 54 time used: 19  seconds  train loss: 0.5505096665656414 validation loss: 0.6269174464306428
epoch 55 time used: 19  seconds  train loss: 0.5496068156799924 validation loss: 0.6178210689060724
epoch 56 time used: 19  seconds  train loss: 0.5473682455623133 validation loss: 0.6255353689193726
epoch 57 time used: 19  seconds  train loss: 0.5463955431201549 validation loss: 0.6287287982245583
epoch 58 time used: 19  seconds  train loss: 0.5486113251018659 validation loss: 0.6169931563868452
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4203056653e-01, 0.5420305665
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.4071061732, 4.6267814054, 3.5105765466, 31.2029600143
Model Training Ended ... Tue May 31 05:14:06 2022
pred_SZTAXI_GraphWaveNet_2205310454 testing started Tue May 31 05:14:06 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 05:14:06 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3077056104e-01, 0.5307705610
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.5762090054, 4.7514428341, 3.6339606139, 34.0072393417
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.1329862942, 4.2582844309, 3.3136139516, 31.5327256918
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.9018565090, 4.3476265374, 3.3704794976, 32.0114642382
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.7843549339, 4.4479607613, 3.4397781574, 32.4750602245
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.6499691862, 4.5442237166, 3.5014249112, 32.9426079988
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3779529155, 4.6236298420, 3.5544685431, 33.4174573421
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2119801965, 4.7129587518, 3.6154238181, 33.9189350605
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.0233050524, 4.7982606278, 3.6738207990, 34.3786835670
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7367708276, 4.8720396989, 3.7211267472, 34.7360998392
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.5640208062, 4.9562103271, 3.7828426265, 35.1955264807
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.3725086975, 5.0371131313, 3.8296579015, 35.4734033346
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.1520376929, 5.1139063047, 3.8741389082, 35.7751607895
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.0690881290, 5.2027961837, 3.9350919254, 36.2628906965
Model Testing Ended ... Tue May 31 05:14:12 2022
