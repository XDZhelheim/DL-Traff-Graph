../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_16.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310514 training started Tue May 31 05:14:17 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 05:14:17 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6827890694056602 validation loss: 0.6855181680982979
epoch 1 time used: 19  seconds  train loss: 0.6494220480386428 validation loss: 0.6847569797169509
epoch 2 time used: 19  seconds  train loss: 0.6394650516435398 validation loss: 0.6726391250221291
epoch 3 time used: 19  seconds  train loss: 0.6307676091980968 validation loss: 0.6902465876655199
epoch 4 time used: 19  seconds  train loss: 0.6265763303802837 validation loss: 0.6693520240522736
epoch 5 time used: 19  seconds  train loss: 0.6212585009687486 validation loss: 0.6546165762256034
epoch 6 time used: 19  seconds  train loss: 0.6179109178430495 validation loss: 0.6713833426361653
epoch 7 time used: 19  seconds  train loss: 0.6175107821970542 validation loss: 0.6556763985560308
epoch 8 time used: 19  seconds  train loss: 0.6141826162806276 validation loss: 0.6511850407467553
epoch 9 time used: 19  seconds  train loss: 0.6125481438161977 validation loss: 0.6595800406304165
epoch 10 time used: 19  seconds  train loss: 0.6096875492912607 validation loss: 0.6533351496084413
epoch 11 time used: 19  seconds  train loss: 0.6064623094893791 validation loss: 0.6491258455746209
epoch 12 time used: 19  seconds  train loss: 0.606560518104016 validation loss: 0.63865851199449
epoch 13 time used: 19  seconds  train loss: 0.6043123263298702 validation loss: 0.655479873887342
epoch 14 time used: 19  seconds  train loss: 0.6032601171842171 validation loss: 0.6586142902943626
epoch 15 time used: 19  seconds  train loss: 0.6033488388251445 validation loss: 0.6445659692607709
epoch 16 time used: 19  seconds  train loss: 0.6022987187247867 validation loss: 0.6376548296776577
epoch 17 time used: 19  seconds  train loss: 0.5996704310984224 validation loss: 0.6383164195872065
epoch 18 time used: 19  seconds  train loss: 0.5979084494612464 validation loss: 0.6404582422171066
epoch 19 time used: 19  seconds  train loss: 0.5965997440207903 validation loss: 0.6358082365633836
epoch 20 time used: 19  seconds  train loss: 0.5977814997073427 validation loss: 0.6616418678962176
epoch 21 time used: 19  seconds  train loss: 0.5940955439383749 validation loss: 0.6397166379648654
epoch 22 time used: 19  seconds  train loss: 0.5947628791946097 validation loss: 0.6347010467776019
epoch 23 time used: 19  seconds  train loss: 0.5921608035798432 validation loss: 0.6412482552267426
epoch 24 time used: 19  seconds  train loss: 0.5903297408376615 validation loss: 0.6384976995525076
epoch 25 time used: 19  seconds  train loss: 0.591161757792382 validation loss: 0.6351633356578315
epoch 26 time used: 19  seconds  train loss: 0.5877882052281842 validation loss: 0.6335752941482696
epoch 27 time used: 19  seconds  train loss: 0.5855091071739306 validation loss: 0.6338238131940661
epoch 28 time used: 19  seconds  train loss: 0.5842808105189294 validation loss: 0.6391676100925426
epoch 29 time used: 19  seconds  train loss: 0.583793169828092 validation loss: 0.6392740236586006
epoch 30 time used: 19  seconds  train loss: 0.5827817034246572 validation loss: 0.6282313540207213
epoch 31 time used: 19  seconds  train loss: 0.5802001949733555 validation loss: 0.6449974760487305
epoch 32 time used: 19  seconds  train loss: 0.580632938514563 validation loss: 0.6311090487745864
epoch 33 time used: 19  seconds  train loss: 0.5774978100829579 validation loss: 0.6372319827625408
epoch 34 time used: 19  seconds  train loss: 0.5761554849944787 validation loss: 0.626650899945207
epoch 35 time used: 19  seconds  train loss: 0.5755093543661777 validation loss: 0.6264278746362942
epoch 36 time used: 19  seconds  train loss: 0.5728834880619266 validation loss: 0.6264540305481622
epoch 37 time used: 19  seconds  train loss: 0.5719117395908361 validation loss: 0.6245911821204039
epoch 38 time used: 19  seconds  train loss: 0.5702154410004107 validation loss: 0.6256567554094306
epoch 39 time used: 19  seconds  train loss: 0.568123522260959 validation loss: 0.6318374898896288
epoch 40 time used: 19  seconds  train loss: 0.5685711163036514 validation loss: 0.630402684804812
epoch 41 time used: 19  seconds  train loss: 0.5661545560336215 validation loss: 0.620641886743147
epoch 42 time used: 19  seconds  train loss: 0.5635471546632975 validation loss: 0.621669972713907
epoch 43 time used: 19  seconds  train loss: 0.5637138401122385 validation loss: 0.626429906531946
epoch 44 time used: 19  seconds  train loss: 0.5622379833230932 validation loss: 0.626194232583639
epoch 45 time used: 19  seconds  train loss: 0.5622742581757508 validation loss: 0.6190285400964728
epoch 46 time used: 19  seconds  train loss: 0.5582720814948401 validation loss: 0.6151269997530315
epoch 47 time used: 19  seconds  train loss: 0.5576317184849789 validation loss: 0.6151845591578318
epoch 48 time used: 19  seconds  train loss: 0.556646074797656 validation loss: 0.6174288295691286
epoch 49 time used: 19  seconds  train loss: 0.5552910116963502 validation loss: 0.6169775831165598
epoch 50 time used: 19  seconds  train loss: 0.5533995190012675 validation loss: 0.6144635650649
epoch 51 time used: 19  seconds  train loss: 0.553237455837418 validation loss: 0.6249511028403667
epoch 52 time used: 19  seconds  train loss: 0.5520483584356511 validation loss: 0.6244337435682021
epoch 53 time used: 19  seconds  train loss: 0.5512807347187786 validation loss: 0.61464508908305
epoch 54 time used: 19  seconds  train loss: 0.5516744395916696 validation loss: 0.6377077081903296
epoch 55 time used: 19  seconds  train loss: 0.5499395380488161 validation loss: 0.6155458303233284
epoch 56 time used: 19  seconds  train loss: 0.5469692542746261 validation loss: 0.622890070006622
epoch 57 time used: 19  seconds  train loss: 0.5464714513733919 validation loss: 0.6224214479104796
epoch 58 time used: 19  seconds  train loss: 0.5480405303356827 validation loss: 0.621550443605404
epoch 59 time used: 19  seconds  train loss: 0.547437444180886 validation loss: 0.6154257352672406
Early stopping at epoch: 60
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4901508154e-01, 0.5490150815
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.1054450534, 4.7016428037, 3.5381732392, 31.0489207506
Model Training Ended ... Tue May 31 05:34:45 2022
pred_SZTAXI_GraphWaveNet_2205310514 testing started Tue May 31 05:34:45 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 05:34:45 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2906279684e-01, 0.5290627968
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2492409729, 4.7169101086, 3.6049314773, 33.9345544577
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.1763544900, 4.2633736043, 3.3232634980, 31.8652212620
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.0656937575, 4.3664280319, 3.3900621995, 32.3740422726
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.6736420045, 4.4354979432, 3.4310801082, 32.6177537441
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.2536452251, 4.5004050068, 3.4654439086, 32.8466951847
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9667118718, 4.5789422219, 3.5169180406, 33.2254648209
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.7809164284, 4.6670029385, 3.5790396148, 33.7098032236
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.4814074991, 4.7414562635, 3.6244133875, 34.0304464102
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.2813818821, 4.8250784327, 3.6754884558, 34.4451963902
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.9070496765, 4.8894835797, 3.7211306804, 34.7577273846
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0372174271, 5.0037203586, 3.7989507308, 35.4450821877
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.8077181020, 5.0801297328, 3.8446367133, 35.7937008142
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.6181028999, 5.1592734857, 3.8927480661, 36.1336261034
Model Testing Ended ... Tue May 31 05:34:51 2022
