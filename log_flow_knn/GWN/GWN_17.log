../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_17.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310534 training started Tue May 31 05:34:56 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 05:34:56 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6825256458302141 validation loss: 0.6853941317221418
epoch 1 time used: 19  seconds  train loss: 0.6490980649994922 validation loss: 0.6834358878396637
epoch 2 time used: 19  seconds  train loss: 0.6394425090481852 validation loss: 0.6708490498623445
epoch 3 time used: 19  seconds  train loss: 0.6304161918282 validation loss: 0.687245425003678
epoch 4 time used: 19  seconds  train loss: 0.626528078343078 validation loss: 0.668394030030094
epoch 5 time used: 19  seconds  train loss: 0.6212328579144322 validation loss: 0.6554107754977782
epoch 6 time used: 19  seconds  train loss: 0.6178164290923991 validation loss: 0.6681302628706937
epoch 7 time used: 19  seconds  train loss: 0.6173065057180684 validation loss: 0.6534365833695255
epoch 8 time used: 19  seconds  train loss: 0.6132911118979475 validation loss: 0.6513781741780428
epoch 9 time used: 19  seconds  train loss: 0.6124778096570738 validation loss: 0.6615915485282442
epoch 10 time used: 19  seconds  train loss: 0.6100637839834178 validation loss: 0.6529841526823851
epoch 11 time used: 19  seconds  train loss: 0.6065044114803352 validation loss: 0.6491813152583678
epoch 12 time used: 19  seconds  train loss: 0.6063819333465815 validation loss: 0.6394274264425781
epoch 13 time used: 19  seconds  train loss: 0.6043490666159526 validation loss: 0.6536338258145461
epoch 14 time used: 19  seconds  train loss: 0.6034072254324705 validation loss: 0.6530020835980848
epoch 15 time used: 19  seconds  train loss: 0.6029791837057382 validation loss: 0.6473971676470628
epoch 16 time used: 19  seconds  train loss: 0.603275418832665 validation loss: 0.6379020258561888
epoch 17 time used: 19  seconds  train loss: 0.6003851812560731 validation loss: 0.6383949527099951
epoch 18 time used: 19  seconds  train loss: 0.5982681060074743 validation loss: 0.6418977184082145
epoch 19 time used: 19  seconds  train loss: 0.5966770620129017 validation loss: 0.6353679629997234
epoch 20 time used: 19  seconds  train loss: 0.5983962448867591 validation loss: 0.6476505834664872
epoch 21 time used: 19  seconds  train loss: 0.5942100993176104 validation loss: 0.6403634358401322
epoch 22 time used: 19  seconds  train loss: 0.595042251760556 validation loss: 0.6401800379824283
epoch 23 time used: 19  seconds  train loss: 0.5931126227758687 validation loss: 0.6452131567902826
epoch 24 time used: 19  seconds  train loss: 0.5912043255559072 validation loss: 0.6402302497061924
epoch 25 time used: 19  seconds  train loss: 0.5919355530911794 validation loss: 0.6336909808329682
epoch 26 time used: 19  seconds  train loss: 0.5883727975793787 validation loss: 0.6330928669047
epoch 27 time used: 19  seconds  train loss: 0.587298198326214 validation loss: 0.6357195101567169
epoch 28 time used: 19  seconds  train loss: 0.5854266098518969 validation loss: 0.636745796274783
epoch 29 time used: 19  seconds  train loss: 0.584958707201023 validation loss: 0.6413096420800508
epoch 30 time used: 19  seconds  train loss: 0.5847257106097291 validation loss: 0.6357907160597654
epoch 31 time used: 19  seconds  train loss: 0.5821779647558546 validation loss: 0.6341750663311327
epoch 32 time used: 19  seconds  train loss: 0.5822494229246169 validation loss: 0.634863194245011
epoch 33 time used: 19  seconds  train loss: 0.5789939449996732 validation loss: 0.6373551057938912
epoch 34 time used: 19  seconds  train loss: 0.5792190067968193 validation loss: 0.6261280918892344
epoch 35 time used: 19  seconds  train loss: 0.5772908316397904 validation loss: 0.6267652149817243
epoch 36 time used: 19  seconds  train loss: 0.5755317022925929 validation loss: 0.6266869813648622
epoch 37 time used: 19  seconds  train loss: 0.5753309464725966 validation loss: 0.6238307036570648
epoch 38 time used: 19  seconds  train loss: 0.5736126341826546 validation loss: 0.6302919642842231
epoch 39 time used: 19  seconds  train loss: 0.5712697495776593 validation loss: 0.6288430314158919
epoch 40 time used: 19  seconds  train loss: 0.570030086918881 validation loss: 0.6292708791903595
epoch 41 time used: 19  seconds  train loss: 0.5688722147202254 validation loss: 0.6248590234500259
epoch 42 time used: 19  seconds  train loss: 0.5666195980006906 validation loss: 0.6227418299931199
epoch 43 time used: 19  seconds  train loss: 0.5659202005751272 validation loss: 0.6292333496150686
epoch 44 time used: 19  seconds  train loss: 0.5651448243542722 validation loss: 0.6390236890434626
epoch 45 time used: 19  seconds  train loss: 0.5670693504013343 validation loss: 0.6158637528988853
epoch 46 time used: 19  seconds  train loss: 0.5611975539374996 validation loss: 0.6164510786829897
epoch 47 time used: 19  seconds  train loss: 0.559786301164505 validation loss: 0.6142438531515018
epoch 48 time used: 19  seconds  train loss: 0.5582188929975627 validation loss: 0.6209485360342472
epoch 49 time used: 19  seconds  train loss: 0.5585003011935467 validation loss: 0.6213067624699417
epoch 50 time used: 19  seconds  train loss: 0.5569551338681455 validation loss: 0.6148189430806175
epoch 51 time used: 19  seconds  train loss: 0.5551999865012353 validation loss: 0.6328982117757276
epoch 52 time used: 19  seconds  train loss: 0.5591062836423198 validation loss: 0.6243645777156697
epoch 53 time used: 19  seconds  train loss: 0.5548527111878266 validation loss: 0.6196363378520036
epoch 54 time used: 19  seconds  train loss: 0.5521262550082688 validation loss: 0.6232895352947179
epoch 55 time used: 19  seconds  train loss: 0.5510197852448074 validation loss: 0.614517958010014
epoch 56 time used: 19  seconds  train loss: 0.5495196826766598 validation loss: 0.6249368588129679
Early stopping at epoch: 57
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4649461681e-01, 0.5464946168
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.2181655914, 4.7136149176, 3.5820902780, 31.8119466305
Model Training Ended ... Tue May 31 05:54:20 2022
pred_SZTAXI_GraphWaveNet_2205310534 testing started Tue May 31 05:54:20 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 05:54:20 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2817882387e-01, 0.5281788239
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.1002295461, 4.7010881236, 3.5876631011, 33.7268799543
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0140162476, 4.2442921963, 3.3043011663, 31.6940993071
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8060756631, 4.3365972447, 3.3639354083, 32.0839434862
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.7158347080, 4.4402516492, 3.4252840890, 32.5962483883
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.3814402495, 4.5145808498, 3.4726434001, 32.9019963741
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.0849553141, 4.5918357238, 3.5243616452, 33.3145529032
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.6279480526, 4.6505857752, 3.5562207932, 33.4915816784
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.4798668558, 4.7412937956, 3.6216937565, 33.9802712202
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.1159269554, 4.8079025526, 3.6596722870, 34.2592597008
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7486348538, 4.8732571093, 3.7007014965, 34.5254361629
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.6416030007, 4.9640309226, 3.7625661962, 34.9774241447
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.4658134881, 5.0463663648, 3.8122979627, 35.3309750557
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.1769762804, 5.1163440346, 3.8520736968, 35.5939090252
Model Testing Ended ... Tue May 31 05:54:25 2022
