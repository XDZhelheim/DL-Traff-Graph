../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_18.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310554 training started Tue May 31 05:54:30 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 05:54:31 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6824403233497615 validation loss: 0.6853603114239613
epoch 1 time used: 19  seconds  train loss: 0.6489347241935486 validation loss: 0.6836433443263988
epoch 2 time used: 19  seconds  train loss: 0.6393733296760624 validation loss: 0.6717275782900664
epoch 3 time used: 19  seconds  train loss: 0.6304303181290117 validation loss: 0.6893130531951562
epoch 4 time used: 19  seconds  train loss: 0.6265629303574053 validation loss: 0.6669052723628371
epoch 5 time used: 19  seconds  train loss: 0.621254208925608 validation loss: 0.6549800515767947
epoch 6 time used: 19  seconds  train loss: 0.6179679335859388 validation loss: 0.670313648026974
epoch 7 time used: 19  seconds  train loss: 0.6173554636845379 validation loss: 0.6540009785647416
epoch 8 time used: 19  seconds  train loss: 0.6127930377659044 validation loss: 0.6504425296736001
epoch 9 time used: 19  seconds  train loss: 0.6128041596704323 validation loss: 0.6629206090424191
epoch 10 time used: 19  seconds  train loss: 0.6101105804124564 validation loss: 0.6523655338666925
epoch 11 time used: 19  seconds  train loss: 0.6063406516613695 validation loss: 0.6468406017146894
epoch 12 time used: 19  seconds  train loss: 0.6066077433812669 validation loss: 0.6409400766761741
epoch 13 time used: 19  seconds  train loss: 0.6044623759359249 validation loss: 0.6523214451116116
epoch 14 time used: 19  seconds  train loss: 0.6033945268451913 validation loss: 0.65164457921365
epoch 15 time used: 19  seconds  train loss: 0.603140875336795 validation loss: 0.6474611480437701
epoch 16 time used: 19  seconds  train loss: 0.603809960366652 validation loss: 0.6388117451572892
epoch 17 time used: 19  seconds  train loss: 0.6002825291702791 validation loss: 0.6402704969270906
epoch 18 time used: 19  seconds  train loss: 0.5984915001039655 validation loss: 0.641726366323025
epoch 19 time used: 19  seconds  train loss: 0.5969347553605884 validation loss: 0.6360333717581051
epoch 20 time used: 19  seconds  train loss: 0.598090222092136 validation loss: 0.6476488267604391
epoch 21 time used: 19  seconds  train loss: 0.5945233550892446 validation loss: 0.6406746248700725
epoch 22 time used: 19  seconds  train loss: 0.5952345800094551 validation loss: 0.6388050335556713
epoch 23 time used: 19  seconds  train loss: 0.5931722810902602 validation loss: 0.6497508352668724
epoch 24 time used: 19  seconds  train loss: 0.5919894185208664 validation loss: 0.6395648403547296
epoch 25 time used: 19  seconds  train loss: 0.5922169661623655 validation loss: 0.6355005639109446
epoch 26 time used: 19  seconds  train loss: 0.5886384523440561 validation loss: 0.6332347541306149
epoch 27 time used: 19  seconds  train loss: 0.5870853422546115 validation loss: 0.6379217564763121
epoch 28 time used: 19  seconds  train loss: 0.5858025220176404 validation loss: 0.6359761727983085
epoch 29 time used: 19  seconds  train loss: 0.5856385775344979 validation loss: 0.6388360024684697
epoch 30 time used: 19  seconds  train loss: 0.5851984258905414 validation loss: 0.6423425757469823
epoch 31 time used: 19  seconds  train loss: 0.58290325357429 validation loss: 0.6357882464703043
epoch 32 time used: 19  seconds  train loss: 0.5826144488912558 validation loss: 0.6310086494951106
epoch 33 time used: 19  seconds  train loss: 0.5794177843021974 validation loss: 0.6347777772305617
epoch 34 time used: 19  seconds  train loss: 0.5789983338685667 validation loss: 0.6282856041815743
epoch 35 time used: 19  seconds  train loss: 0.5780016922340284 validation loss: 0.6287698799104833
epoch 36 time used: 19  seconds  train loss: 0.5757971995246529 validation loss: 0.6255147993861147
epoch 37 time used: 19  seconds  train loss: 0.5754746352117058 validation loss: 0.6244361679352338
epoch 38 time used: 19  seconds  train loss: 0.5744666640314235 validation loss: 0.6280400109528309
epoch 39 time used: 19  seconds  train loss: 0.5723326374931661 validation loss: 0.6283104209164482
epoch 40 time used: 19  seconds  train loss: 0.5709636001125677 validation loss: 0.6271846071997685
epoch 41 time used: 19  seconds  train loss: 0.569477638343659 validation loss: 0.6261661570167067
epoch 42 time used: 19  seconds  train loss: 0.5675962026393939 validation loss: 0.6198755662832687
epoch 43 time used: 19  seconds  train loss: 0.5671250251245024 validation loss: 0.6214162406340167
epoch 44 time used: 19  seconds  train loss: 0.5655617928437114 validation loss: 0.627802207695311
epoch 45 time used: 19  seconds  train loss: 0.567563083229499 validation loss: 0.622088233333322
epoch 46 time used: 19  seconds  train loss: 0.5626652222524158 validation loss: 0.6190134088198344
epoch 47 time used: 19  seconds  train loss: 0.5604411915559349 validation loss: 0.6145086246936475
epoch 48 time used: 19  seconds  train loss: 0.5599955317814692 validation loss: 0.6189964705735297
epoch 49 time used: 19  seconds  train loss: 0.5587664016788748 validation loss: 0.6133891928255262
epoch 50 time used: 19  seconds  train loss: 0.5567373356134081 validation loss: 0.615934801338917
epoch 51 time used: 19  seconds  train loss: 0.5559921234973294 validation loss: 0.6243283472844025
epoch 52 time used: 19  seconds  train loss: 0.5553711112668132 validation loss: 0.6181007768977341
epoch 53 time used: 19  seconds  train loss: 0.553870739078793 validation loss: 0.6179169199953032
epoch 54 time used: 19  seconds  train loss: 0.5533529798133275 validation loss: 0.6374782495830783
epoch 55 time used: 19  seconds  train loss: 0.5531674895652836 validation loss: 0.6171207490252025
epoch 56 time used: 19  seconds  train loss: 0.5505071261190249 validation loss: 0.622993884988092
epoch 57 time used: 19  seconds  train loss: 0.5495755061146884 validation loss: 0.6239837511854979
epoch 58 time used: 19  seconds  train loss: 0.5525924943249731 validation loss: 0.6272748554523905
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4372977498e-01, 0.5437297750
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.6383383948, 4.6517027415, 3.5285112229, 31.3048720360
Model Training Ended ... Tue May 31 06:14:30 2022
pred_SZTAXI_GraphWaveNet_2205310554 testing started Tue May 31 06:14:30 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 06:14:30 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3722390551e-01, 0.5372239055
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.3534909369, 4.7279478568, 3.6085010905, 34.0921014547
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.9014969512, 4.2310160661, 3.2879534847, 31.4173609018
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.7366630127, 4.3285867223, 3.3504551499, 31.9738835096
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5307304586, 4.4193586026, 3.4108055670, 32.4115246534
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.3628387120, 4.5125202173, 3.4707952288, 32.8929781914
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.2232014939, 4.6068646056, 3.5335994280, 33.5044741631
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0855086891, 4.6995221767, 3.5966467459, 34.0614497662
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.9316839320, 4.7887037841, 3.6561805565, 34.5642834902
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7475103035, 4.8731417282, 3.7113120782, 35.0294470787
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3918875171, 4.9388143838, 3.7568831401, 35.3620290756
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0856721475, 5.0085598876, 3.7985397271, 35.6235235929
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.7437165461, 5.0738266177, 3.8402655449, 35.9435260296
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.5620202195, 5.1538354863, 3.8928394572, 36.3556116819
Model Testing Ended ... Tue May 31 06:14:35 2022
