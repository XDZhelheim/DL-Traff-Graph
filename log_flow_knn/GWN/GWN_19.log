../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_19.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310614 training started Tue May 31 06:14:40 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 06:14:40 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6822735539625583 validation loss: 0.685611088477557
epoch 1 time used: 19  seconds  train loss: 0.6486504171176113 validation loss: 0.6829176180398286
epoch 2 time used: 19  seconds  train loss: 0.6390561796353857 validation loss: 0.6730595269606481
epoch 3 time used: 19  seconds  train loss: 0.6300926694320581 validation loss: 0.692018664891447
epoch 4 time used: 19  seconds  train loss: 0.6264059367254482 validation loss: 0.666619925949704
epoch 5 time used: 19  seconds  train loss: 0.6213121377726537 validation loss: 0.6545207541973437
epoch 6 time used: 19  seconds  train loss: 0.6177772827033129 validation loss: 0.6691026791411253
epoch 7 time used: 19  seconds  train loss: 0.6173581870996088 validation loss: 0.6590105388591538
epoch 8 time used: 19  seconds  train loss: 0.6132575094615074 validation loss: 0.6501258971975811
epoch 9 time used: 19  seconds  train loss: 0.6121932830274699 validation loss: 0.6612208693181697
epoch 10 time used: 19  seconds  train loss: 0.6098026762985403 validation loss: 0.6546702773416814
epoch 11 time used: 19  seconds  train loss: 0.606395195337651 validation loss: 0.6476714406440507
epoch 12 time used: 19  seconds  train loss: 0.606228145138807 validation loss: 0.6399810477275754
epoch 13 time used: 19  seconds  train loss: 0.6043544093711278 validation loss: 0.6558311884082965
epoch 14 time used: 19  seconds  train loss: 0.6033186887948645 validation loss: 0.6547436186330235
epoch 15 time used: 19  seconds  train loss: 0.6031922236784424 validation loss: 0.6459242677807215
epoch 16 time used: 19  seconds  train loss: 0.6036261431183958 validation loss: 0.6564727576810923
epoch 17 time used: 19  seconds  train loss: 0.6026956792576385 validation loss: 0.6398130750181663
epoch 18 time used: 19  seconds  train loss: 0.5991580173012881 validation loss: 0.6410540514324435
epoch 19 time used: 19  seconds  train loss: 0.59701535822148 validation loss: 0.6353769935482177
epoch 20 time used: 19  seconds  train loss: 0.5985942581300207 validation loss: 0.6462171531435269
epoch 21 time used: 19  seconds  train loss: 0.5945417437580537 validation loss: 0.6397094849626817
epoch 22 time used: 19  seconds  train loss: 0.5957418831110339 validation loss: 0.6413007873800857
epoch 23 time used: 19  seconds  train loss: 0.5931153177875882 validation loss: 0.6500360295547182
epoch 24 time used: 19  seconds  train loss: 0.5920149338024948 validation loss: 0.6407139965550817
epoch 25 time used: 19  seconds  train loss: 0.5917866814611308 validation loss: 0.6346071739101884
epoch 26 time used: 19  seconds  train loss: 0.5889697998211021 validation loss: 0.6334208078052274
epoch 27 time used: 19  seconds  train loss: 0.5875597567341236 validation loss: 0.6369394253735519
epoch 28 time used: 19  seconds  train loss: 0.585946843049265 validation loss: 0.6360132323568733
epoch 29 time used: 19  seconds  train loss: 0.5862966650410703 validation loss: 0.6429059155544832
epoch 30 time used: 19  seconds  train loss: 0.5854165500631373 validation loss: 0.6361907925178756
epoch 31 time used: 19  seconds  train loss: 0.5828028185608377 validation loss: 0.6390313070211837
epoch 32 time used: 19  seconds  train loss: 0.5826058438628021 validation loss: 0.629859247759207
epoch 33 time used: 19  seconds  train loss: 0.5798581677938084 validation loss: 0.6349293189262276
epoch 34 time used: 19  seconds  train loss: 0.5796986360468532 validation loss: 0.6279361262843384
epoch 35 time used: 19  seconds  train loss: 0.5785964476434808 validation loss: 0.6309242645899454
epoch 36 time used: 19  seconds  train loss: 0.5762884886471679 validation loss: 0.6288862392973544
epoch 37 time used: 19  seconds  train loss: 0.5755370912138124 validation loss: 0.6285330627984669
epoch 38 time used: 19  seconds  train loss: 0.5749729314705047 validation loss: 0.6329610279543483
epoch 39 time used: 19  seconds  train loss: 0.5722922804006303 validation loss: 0.628337388014912
epoch 40 time used: 19  seconds  train loss: 0.5708394025162308 validation loss: 0.6303718979678937
epoch 41 time used: 19  seconds  train loss: 0.5699215274447228 validation loss: 0.6303833420596906
epoch 42 time used: 19  seconds  train loss: 0.5680866535662926 validation loss: 0.623554709242351
epoch 43 time used: 19  seconds  train loss: 0.5668731888870088 validation loss: 0.6227529538211538
epoch 44 time used: 19  seconds  train loss: 0.5654515810575798 validation loss: 0.6249010703753476
epoch 45 time used: 19  seconds  train loss: 0.5676596388114804 validation loss: 0.6215752748707634
epoch 46 time used: 19  seconds  train loss: 0.5621804074406793 validation loss: 0.6223589709742152
epoch 47 time used: 19  seconds  train loss: 0.5611473740758123 validation loss: 0.614464353566146
epoch 48 time used: 19  seconds  train loss: 0.5600855466651374 validation loss: 0.6175139589392724
epoch 49 time used: 19  seconds  train loss: 0.5587363392326604 validation loss: 0.6165805224755511
epoch 50 time used: 19  seconds  train loss: 0.5570602678981309 validation loss: 0.6202128846847003
epoch 51 time used: 19  seconds  train loss: 0.5563861605622521 validation loss: 0.62294893092777
epoch 52 time used: 19  seconds  train loss: 0.5562749796707295 validation loss: 0.6213193956892289
epoch 53 time used: 19  seconds  train loss: 0.5547783222171355 validation loss: 0.6222383374005408
epoch 54 time used: 19  seconds  train loss: 0.5530360631888486 validation loss: 0.6312854592479876
epoch 55 time used: 19  seconds  train loss: 0.5526906602074039 validation loss: 0.6210983244340811
epoch 56 time used: 19  seconds  train loss: 0.5510834443620055 validation loss: 0.6231372783433146
Early stopping at epoch: 57
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4520195248e-01, 0.5452019525
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.1551641857, 4.7069272552, 3.5691147146, 31.5983623266
Model Training Ended ... Tue May 31 06:34:01 2022
pred_SZTAXI_GraphWaveNet_2205310614 testing started Tue May 31 06:34:01 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 06:34:01 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2920286240e-01, 0.5292028624
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.9168838690, 4.6815471662, 3.5737355590, 33.5743844509
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 17.9837850765, 4.2407293095, 3.3032671171, 31.5426558256
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8081022778, 4.3368309026, 3.3641903168, 31.9424957037
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5307184759, 4.4193572469, 3.4103656580, 32.3528945446
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.2306852845, 4.4978534085, 3.4593974293, 32.7066600323
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.8816414764, 4.5696434737, 3.5054690800, 33.0596774817
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3843428023, 4.6243207936, 3.5362483283, 33.2871943712
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2840548718, 4.7205989950, 3.6034987837, 33.8037341833
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.9186645935, 4.7873442109, 3.6426340631, 34.1061383486
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.5468191169, 4.8525064778, 3.6867649136, 34.4365090132
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.4163344241, 4.9412887412, 3.7463066294, 34.8779886961
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.1604612620, 5.0160204607, 3.7929806665, 35.2316558361
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.9117984716, 5.0903632947, 3.8374147506, 35.5731964111
Model Testing Ended ... Tue May 31 06:34:06 2022
