../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_2.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310018 training started Tue May 31 00:18:56 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:18:56 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.7048010251684853 validation loss: 0.7275319154286266
epoch 1 time used: 19  seconds  train loss: 0.6852964716903854 validation loss: 0.7324468199886492
epoch 2 time used: 19  seconds  train loss: 0.6755933558957845 validation loss: 0.7231198122252279
epoch 3 time used: 19  seconds  train loss: 0.6702526614472673 validation loss: 0.7367331949039478
epoch 4 time used: 19  seconds  train loss: 0.6641993722739294 validation loss: 0.7020383993191506
epoch 5 time used: 19  seconds  train loss: 0.6606338180145871 validation loss: 0.6954955790766436
epoch 6 time used: 19  seconds  train loss: 0.6580314455636026 validation loss: 0.7072997010169337
epoch 7 time used: 19  seconds  train loss: 0.6561788358695138 validation loss: 0.6889888752455735
epoch 8 time used: 19  seconds  train loss: 0.6539115965112006 validation loss: 0.6959685033826686
epoch 9 time used: 19  seconds  train loss: 0.6520186515993956 validation loss: 0.6972987462039018
epoch 10 time used: 19  seconds  train loss: 0.6515254705593223 validation loss: 0.686675078833281
epoch 11 time used: 19  seconds  train loss: 0.6461687301673726 validation loss: 0.6900683807496407
epoch 12 time used: 19  seconds  train loss: 0.6446944229294193 validation loss: 0.6821403713961739
epoch 13 time used: 21  seconds  train loss: 0.6425464079525868 validation loss: 0.6854069401968771
epoch 14 time used: 31  seconds  train loss: 0.6420585332520486 validation loss: 0.6885604105185513
epoch 15 time used: 44  seconds  train loss: 0.6401968618714453 validation loss: 0.6846942207706508
epoch 16 time used: 19  seconds  train loss: 0.6386106031632864 validation loss: 0.6858405135757294
epoch 17 time used: 20  seconds  train loss: 0.6360202775910433 validation loss: 0.6770608328764711
epoch 18 time used: 19  seconds  train loss: 0.6344453133695664 validation loss: 0.6766468686843986
epoch 19 time used: 20  seconds  train loss: 0.6323218838249467 validation loss: 0.6745250708428189
epoch 20 time used: 19  seconds  train loss: 0.6323778570800553 validation loss: 0.6765739722038383
epoch 21 time used: 19  seconds  train loss: 0.6285875600737494 validation loss: 0.6826072234419448
epoch 22 time used: 19  seconds  train loss: 0.6285262749680075 validation loss: 0.6737454317102385
epoch 23 time used: 19  seconds  train loss: 0.6260575077272581 validation loss: 0.6759179083269033
epoch 24 time used: 19  seconds  train loss: 0.6236526314937543 validation loss: 0.6771817720351527
epoch 25 time used: 19  seconds  train loss: 0.6217490922590747 validation loss: 0.6677078554286292
epoch 26 time used: 19  seconds  train loss: 0.6194976015416521 validation loss: 0.670337270741439
epoch 27 time used: 19  seconds  train loss: 0.6180241949019019 validation loss: 0.665457888029108
epoch 28 time used: 19  seconds  train loss: 0.6156252943095917 validation loss: 0.6689297236613373
epoch 29 time used: 19  seconds  train loss: 0.6136744322512262 validation loss: 0.6632427754093758
epoch 30 time used: 19  seconds  train loss: 0.6135141153423749 validation loss: 0.6646824891294413
epoch 31 time used: 19  seconds  train loss: 0.6117338090499129 validation loss: 0.6743147901041591
epoch 32 time used: 19  seconds  train loss: 0.6111547381406488 validation loss: 0.6674335610807238
epoch 33 time used: 19  seconds  train loss: 0.608893731155911 validation loss: 0.6651193710108895
epoch 34 time used: 19  seconds  train loss: 0.6074114625857531 validation loss: 0.6614154961275224
epoch 35 time used: 19  seconds  train loss: 0.606254534480582 validation loss: 0.6643653150221601
epoch 36 time used: 19  seconds  train loss: 0.6049900167697185 validation loss: 0.6599044802770093
epoch 37 time used: 19  seconds  train loss: 0.6032079327666064 validation loss: 0.6618279485560176
epoch 38 time used: 19  seconds  train loss: 0.602483339024811 validation loss: 0.6636497117393646
epoch 39 time used: 19  seconds  train loss: 0.6015806879800549 validation loss: 0.6599411587810042
epoch 40 time used: 20  seconds  train loss: 0.5997665020005293 validation loss: 0.6577266300495584
epoch 41 time used: 19  seconds  train loss: 0.5991087704261031 validation loss: 0.6611597742607345
epoch 42 time used: 19  seconds  train loss: 0.5968732727031789 validation loss: 0.6600988575475133
epoch 43 time used: 19  seconds  train loss: 0.5971074390038318 validation loss: 0.6636355325060698
epoch 44 time used: 19  seconds  train loss: 0.5957942989099755 validation loss: 0.656895507775729
epoch 45 time used: 19  seconds  train loss: 0.5949893053700541 validation loss: 0.6591854658885975
epoch 46 time used: 19  seconds  train loss: 0.5939011133751523 validation loss: 0.66084505580551
epoch 47 time used: 19  seconds  train loss: 0.5940513253042403 validation loss: 0.6580931387137418
epoch 48 time used: 19  seconds  train loss: 0.5919352034755995 validation loss: 0.6611920676717711
epoch 49 time used: 19  seconds  train loss: 0.5915621221489452 validation loss: 0.6586952648352628
epoch 50 time used: 19  seconds  train loss: 0.589579502854544 validation loss: 0.6570092955631996
epoch 51 time used: 19  seconds  train loss: 0.5898351590460429 validation loss: 0.6610929900733986
epoch 52 time used: 19  seconds  train loss: 0.5876366621569583 validation loss: 0.6606147034251275
epoch 53 time used: 19  seconds  train loss: 0.5877119324794026 validation loss: 0.6584206196799207
Early stopping at epoch: 54
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.8556305803e-01, 0.5855630580
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 24.3498085009, 4.9345525127, 3.7076449161, 32.5967103243
Model Training Ended ... Tue May 31 00:37:57 2022
pred_SZTAXI_GraphWaveNet_2205310018 testing started Tue May 31 00:37:57 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:37:57 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.5379198810e-01, 0.5537919881
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.9428764629, 4.8931458657, 3.7239080423, 34.6865057945
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.7770380468, 4.3332479789, 3.3708550432, 32.0816248655
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.7771346372, 4.4471490460, 3.4419286067, 32.6100200415
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.5431486192, 4.5324550322, 3.4969231027, 32.9809814692
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3535490338, 4.6209900491, 3.5556263074, 33.4228545427
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.3970067389, 4.7325475950, 3.6307345080, 34.0078115463
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.1942591937, 4.8160418596, 3.6844625385, 34.3631267548
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2716807295, 4.9266297536, 3.7561703269, 34.9302113056
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.2938357155, 5.0292977358, 3.8178766779, 35.3644132614
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.4281390395, 5.1408305788, 3.8956497230, 35.9665274620
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.4289106737, 5.2372617534, 3.9572285910, 36.4156097174
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 28.4239149960, 5.3314083501, 4.0096406763, 36.8139535189
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 29.5017190415, 5.4315484939, 4.0747882765, 37.3178869486
Model Testing Ended ... Tue May 31 00:38:02 2022
