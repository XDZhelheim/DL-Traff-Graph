../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_20.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310634 training started Tue May 31 06:34:12 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 06:34:12 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6822139264255296 validation loss: 0.6862520720828232
epoch 1 time used: 19  seconds  train loss: 0.6487619712800423 validation loss: 0.6833645763681896
epoch 2 time used: 19  seconds  train loss: 0.6391949743498779 validation loss: 0.6748816323517567
epoch 3 time used: 19  seconds  train loss: 0.6302449105474383 validation loss: 0.6954941094218202
epoch 4 time used: 19  seconds  train loss: 0.6264394937165262 validation loss: 0.6662497096393832
epoch 5 time used: 19  seconds  train loss: 0.6209721075182788 validation loss: 0.6539190619146052
epoch 6 time used: 19  seconds  train loss: 0.6176208864743815 validation loss: 0.6694657538660723
epoch 7 time used: 19  seconds  train loss: 0.6175095242253408 validation loss: 0.6538111951517228
epoch 8 time used: 19  seconds  train loss: 0.6126604184487127 validation loss: 0.6506742394682187
epoch 9 time used: 19  seconds  train loss: 0.6126423559521205 validation loss: 0.6618667526624689
epoch 10 time used: 19  seconds  train loss: 0.6096876641764579 validation loss: 0.6530980435176869
epoch 11 time used: 19  seconds  train loss: 0.6061875899011007 validation loss: 0.648971606842914
epoch 12 time used: 19  seconds  train loss: 0.6064863288894317 validation loss: 0.6408310796490949
epoch 13 time used: 19  seconds  train loss: 0.6042373310960034 validation loss: 0.6536016227000981
epoch 14 time used: 19  seconds  train loss: 0.6031733808951562 validation loss: 0.6527690068999333
epoch 15 time used: 19  seconds  train loss: 0.603110635348438 validation loss: 0.6453739861350748
epoch 16 time used: 19  seconds  train loss: 0.6029538387594318 validation loss: 0.63864591702893
epoch 17 time used: 19  seconds  train loss: 0.5998619816042112 validation loss: 0.6392404459305664
epoch 18 time used: 19  seconds  train loss: 0.5990362938912122 validation loss: 0.6415318336652879
epoch 19 time used: 19  seconds  train loss: 0.5969176822332705 validation loss: 0.6359786161439336
epoch 20 time used: 19  seconds  train loss: 0.598081173717043 validation loss: 0.6465492402736227
epoch 21 time used: 19  seconds  train loss: 0.5954151080224457 validation loss: 0.638419135144694
epoch 22 time used: 19  seconds  train loss: 0.5954771134286991 validation loss: 0.6397328717791619
epoch 23 time used: 19  seconds  train loss: 0.5930471671255011 validation loss: 0.6470202432936104
epoch 24 time used: 19  seconds  train loss: 0.5914733503994188 validation loss: 0.6476706207095094
epoch 25 time used: 19  seconds  train loss: 0.5938150956484874 validation loss: 0.6360419947116529
epoch 26 time used: 19  seconds  train loss: 0.5887341521373005 validation loss: 0.6316926449685547
epoch 27 time used: 19  seconds  train loss: 0.5878140650806183 validation loss: 0.6329648011359409
epoch 28 time used: 19  seconds  train loss: 0.5863085233554731 validation loss: 0.6354249279890487
epoch 29 time used: 19  seconds  train loss: 0.5858844733170391 validation loss: 0.6360758080411313
epoch 30 time used: 19  seconds  train loss: 0.5855125630563218 validation loss: 0.6333408753077189
epoch 31 time used: 19  seconds  train loss: 0.5831023405490187 validation loss: 0.6360539129717433
epoch 32 time used: 19  seconds  train loss: 0.5828220574648927 validation loss: 0.6339331835656616
epoch 33 time used: 19  seconds  train loss: 0.5803012411251854 validation loss: 0.6368547357730011
epoch 34 time used: 19  seconds  train loss: 0.5805685749094652 validation loss: 0.6287270997887227
epoch 35 time used: 19  seconds  train loss: 0.5790674989118345 validation loss: 0.6251015547496169
epoch 36 time used: 19  seconds  train loss: 0.5770953860594911 validation loss: 0.6281078844817717
epoch 37 time used: 19  seconds  train loss: 0.5758486173061355 validation loss: 0.6247318115696978
epoch 38 time used: 19  seconds  train loss: 0.5755612431345759 validation loss: 0.6262223032576528
epoch 39 time used: 19  seconds  train loss: 0.5730819056926039 validation loss: 0.6270521742787527
epoch 40 time used: 19  seconds  train loss: 0.5712929514699098 validation loss: 0.630535085402911
epoch 41 time used: 19  seconds  train loss: 0.5710668450229368 validation loss: 0.6249909352010755
epoch 42 time used: 19  seconds  train loss: 0.5685703069353172 validation loss: 0.6214251690243014
epoch 43 time used: 19  seconds  train loss: 0.5685863611877897 validation loss: 0.6371207757672267
epoch 44 time used: 19  seconds  train loss: 0.5672703360765112 validation loss: 0.6269230105687137
epoch 45 time used: 19  seconds  train loss: 0.5684005443012053 validation loss: 0.624178166116648
epoch 46 time used: 19  seconds  train loss: 0.5641740066652448 validation loss: 0.6217076834754565
epoch 47 time used: 19  seconds  train loss: 0.5623593902689634 validation loss: 0.6162519294824174
epoch 48 time used: 19  seconds  train loss: 0.5610003005050833 validation loss: 0.6175832727655249
epoch 49 time used: 19  seconds  train loss: 0.5605092686236668 validation loss: 0.6185433256685438
epoch 50 time used: 19  seconds  train loss: 0.5587959358227541 validation loss: 0.6224386463710918
epoch 51 time used: 19  seconds  train loss: 0.5580471338622092 validation loss: 0.6268517460989121
epoch 52 time used: 19  seconds  train loss: 0.5567964540097656 validation loss: 0.6203775795834574
epoch 53 time used: 19  seconds  train loss: 0.5566361538037806 validation loss: 0.6197614162715513
epoch 54 time used: 19  seconds  train loss: 0.5551490353825761 validation loss: 0.6206453967450271
epoch 55 time used: 19  seconds  train loss: 0.5540327428075701 validation loss: 0.6199961983742406
epoch 56 time used: 19  seconds  train loss: 0.5519958183402527 validation loss: 0.6312135493577417
Early stopping at epoch: 57
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4742497350e-01, 0.5474249735
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.3267281607, 4.7251167351, 3.5932928069, 31.8634808064
Model Training Ended ... Tue May 31 06:53:31 2022
pred_SZTAXI_GraphWaveNet_2205310634 testing started Tue May 31 06:53:31 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 06:53:31 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2884359016e-01, 0.5288435902
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.8854445632, 4.6781881710, 3.5752900833, 33.6326718330
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0599173435, 4.2496961472, 3.3120390871, 31.6770970821
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8875654990, 4.3459826851, 3.3720903175, 32.0767343044
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5600138266, 4.4226704407, 3.4179115917, 32.4861437082
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.2434954362, 4.4992772126, 3.4649285842, 32.8002154827
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9050979354, 4.5722093057, 3.5113766099, 33.1582903862
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3856987334, 4.6244674000, 3.5402753324, 33.3643853664
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2187985967, 4.7136820636, 3.6046651141, 33.8734924793
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8476906815, 4.7799258029, 3.6422640173, 34.1395348310
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.4686580418, 4.8444461027, 3.6835598212, 34.4318002462
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3350621062, 4.9330580887, 3.7446594455, 34.8929226398
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0307570433, 5.0030747589, 3.7850978824, 35.1959377527
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.7356837887, 5.0730349682, 3.8281953541, 35.5222463608
Model Testing Ended ... Tue May 31 06:53:36 2022
