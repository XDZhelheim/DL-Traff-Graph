../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_3.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310038 training started Tue May 31 00:38:08 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:38:08 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6992142532831574 validation loss: 0.7155387604711068
epoch 1 time used: 19  seconds  train loss: 0.6704087984850193 validation loss: 0.6990589004250901
epoch 2 time used: 19  seconds  train loss: 0.657340606618911 validation loss: 0.6915339348624595
epoch 3 time used: 19  seconds  train loss: 0.6504787678908488 validation loss: 0.7367822349961124
epoch 4 time used: 19  seconds  train loss: 0.6401352358407011 validation loss: 0.6805208954051952
epoch 5 time used: 19  seconds  train loss: 0.6353154184129804 validation loss: 0.6679355831288579
epoch 6 time used: 19  seconds  train loss: 0.6306594423684762 validation loss: 0.6722458322249835
epoch 7 time used: 19  seconds  train loss: 0.6292105038169438 validation loss: 0.6637440746399894
epoch 8 time used: 19  seconds  train loss: 0.6267834417680928 validation loss: 0.6618134843472817
epoch 9 time used: 19  seconds  train loss: 0.6218625374912029 validation loss: 0.6702031979513405
epoch 10 time used: 19  seconds  train loss: 0.6216983421259211 validation loss: 0.6523218607131521
epoch 11 time used: 19  seconds  train loss: 0.616160428795333 validation loss: 0.6740284677761704
epoch 12 time used: 19  seconds  train loss: 0.6140534288513542 validation loss: 0.655583186529169
epoch 13 time used: 19  seconds  train loss: 0.6123892088787654 validation loss: 0.6479539370062339
epoch 14 time used: 19  seconds  train loss: 0.6122076206153012 validation loss: 0.6519207468080284
epoch 15 time used: 19  seconds  train loss: 0.6095102784643811 validation loss: 0.6580766202205449
epoch 16 time used: 19  seconds  train loss: 0.6077432934284889 validation loss: 0.6436634062238
epoch 17 time used: 19  seconds  train loss: 0.6032551588917185 validation loss: 0.6453127617859722
epoch 18 time used: 19  seconds  train loss: 0.6014539414584891 validation loss: 0.6453699514047423
epoch 19 time used: 19  seconds  train loss: 0.5989689753201405 validation loss: 0.6374854684172578
epoch 20 time used: 19  seconds  train loss: 0.5993545330944305 validation loss: 0.6369456147673118
epoch 21 time used: 19  seconds  train loss: 0.5948646405173909 validation loss: 0.6534775006237314
epoch 22 time used: 19  seconds  train loss: 0.5948172404959395 validation loss: 0.6325838257424274
epoch 23 time used: 19  seconds  train loss: 0.5904967640745182 validation loss: 0.6382608384042237
epoch 24 time used: 19  seconds  train loss: 0.5878255498697544 validation loss: 0.6376922157273364
epoch 25 time used: 19  seconds  train loss: 0.5877790541347027 validation loss: 0.641080150260261
epoch 26 time used: 19  seconds  train loss: 0.5840175465533608 validation loss: 0.6320067620396022
epoch 27 time used: 19  seconds  train loss: 0.5832367665737147 validation loss: 0.641482935022952
epoch 28 time used: 19  seconds  train loss: 0.5807336381031134 validation loss: 0.6355608977488617
epoch 29 time used: 19  seconds  train loss: 0.577549259828809 validation loss: 0.6281657266379589
epoch 30 time used: 19  seconds  train loss: 0.5776147153943905 validation loss: 0.626214254851365
epoch 31 time used: 19  seconds  train loss: 0.5747461137527422 validation loss: 0.6526290756552967
epoch 32 time used: 19  seconds  train loss: 0.5755846763233711 validation loss: 0.6371195068703362
epoch 33 time used: 19  seconds  train loss: 0.5713471116161618 validation loss: 0.6200202937742963
epoch 34 time used: 19  seconds  train loss: 0.5707510149326297 validation loss: 0.6232066815765342
epoch 35 time used: 19  seconds  train loss: 0.5688017720348635 validation loss: 0.6302677173519609
epoch 36 time used: 19  seconds  train loss: 0.5688381679621055 validation loss: 0.6199590519293031
epoch 37 time used: 19  seconds  train loss: 0.5661930703845506 validation loss: 0.64277157839851
epoch 38 time used: 19  seconds  train loss: 0.5657960320604305 validation loss: 0.6355570913547307
epoch 39 time used: 19  seconds  train loss: 0.5640354202278647 validation loss: 0.6193845085243681
epoch 40 time used: 19  seconds  train loss: 0.562018681047312 validation loss: 0.6140577588508378
epoch 41 time used: 19  seconds  train loss: 0.5604578686472701 validation loss: 0.622649769284832
epoch 42 time used: 19  seconds  train loss: 0.5595249766815099 validation loss: 0.6137664243949587
epoch 43 time used: 19  seconds  train loss: 0.5583072860074756 validation loss: 0.6338387247341782
epoch 44 time used: 19  seconds  train loss: 0.5585475544502182 validation loss: 0.6188104096336744
epoch 45 time used: 19  seconds  train loss: 0.558375610735474 validation loss: 0.6186694612550498
epoch 46 time used: 19  seconds  train loss: 0.5551938434498408 validation loss: 0.6239792256806027
epoch 47 time used: 19  seconds  train loss: 0.554203155963214 validation loss: 0.6169526778643404
epoch 48 time used: 19  seconds  train loss: 0.5539920971878561 validation loss: 0.6179497846916541
epoch 49 time used: 19  seconds  train loss: 0.5526399606491729 validation loss: 0.6187711544890901
epoch 50 time used: 19  seconds  train loss: 0.5518844880555805 validation loss: 0.6131201484310094
epoch 51 time used: 19  seconds  train loss: 0.5510894979216465 validation loss: 0.6377591381025551
epoch 52 time used: 19  seconds  train loss: 0.5501118376109203 validation loss: 0.6173363846925953
epoch 53 time used: 19  seconds  train loss: 0.5503417722361525 validation loss: 0.6217908844425903
epoch 54 time used: 19  seconds  train loss: 0.5490038022716897 validation loss: 0.6234916629482857
epoch 55 time used: 19  seconds  train loss: 0.5478855006047028 validation loss: 0.6193885450339436
epoch 56 time used: 19  seconds  train loss: 0.5465721937365416 validation loss: 0.6299904955560295
epoch 57 time used: 19  seconds  train loss: 0.5463520297793881 validation loss: 0.6214584545116519
epoch 58 time used: 19  seconds  train loss: 0.5472999349935974 validation loss: 0.6211672833013298
epoch 59 time used: 19  seconds  train loss: 0.5460483222394377 validation loss: 0.6224315288055002
Early stopping at epoch: 60
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.5781537023e-01, 0.5578153702
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 22.9829286011, 4.7940513766, 3.6120542165, 31.5248906612
Model Training Ended ... Tue May 31 00:58:28 2022
pred_SZTAXI_GraphWaveNet_2205310038 testing started Tue May 31 00:58:28 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:58:28 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3166647975e-01, 0.5316664798
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0359144506, 4.6942426919, 3.5811554560, 33.8970303535
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.2034637967, 4.2665517455, 3.3109691549, 31.7400455475
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.0968038477, 4.3699889986, 3.3777281064, 32.2657436132
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.7289882172, 4.4417325693, 3.4203706145, 32.5386703014
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.3682858249, 4.5131237325, 3.4642348384, 32.9008847475
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9694475637, 4.5792409375, 3.5108407427, 33.2996159792
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.6619251436, 4.6542373321, 3.5633544790, 33.7669402361
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.2512658559, 4.7171247446, 3.6052518255, 34.1181844473
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.9967316410, 4.7954907612, 3.6549339139, 34.5407456160
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.5086399309, 4.8485709164, 3.6876718755, 34.7597658634
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.4663414806, 4.9463462758, 3.7488602593, 35.2607280016
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.1540198138, 5.0153783321, 3.7902153860, 35.5858564377
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.0784133548, 5.1067027870, 3.8430765839, 36.0165387392
Model Testing Ended ... Tue May 31 00:58:33 2022
