../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_4.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310058 training started Tue May 31 00:58:39 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:58:40 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6948646690648785 validation loss: 0.7074073977138272
epoch 1 time used: 19  seconds  train loss: 0.6603786098329645 validation loss: 0.6967039087518531
epoch 2 time used: 19  seconds  train loss: 0.6475927071754488 validation loss: 0.6939627442193862
epoch 3 time used: 19  seconds  train loss: 0.640353949361641 validation loss: 0.7193167945045736
epoch 4 time used: 19  seconds  train loss: 0.6334877923915261 validation loss: 0.6729168126832193
epoch 5 time used: 19  seconds  train loss: 0.6333943894543654 validation loss: 0.6663882453643267
epoch 6 time used: 19  seconds  train loss: 0.6261416964476682 validation loss: 0.6750946590556434
epoch 7 time used: 19  seconds  train loss: 0.6248458227934912 validation loss: 0.6585276820025041
epoch 8 time used: 19  seconds  train loss: 0.6221382921484762 validation loss: 0.6544205153462899
epoch 9 time used: 19  seconds  train loss: 0.6186160112851714 validation loss: 0.6603039206557013
epoch 10 time used: 19  seconds  train loss: 0.6169623781742785 validation loss: 0.6489327536590064
epoch 11 time used: 19  seconds  train loss: 0.6130537807856651 validation loss: 0.6686532740569233
epoch 12 time used: 19  seconds  train loss: 0.6110771958044549 validation loss: 0.6475331409653621
epoch 13 time used: 19  seconds  train loss: 0.6092401540720276 validation loss: 0.6481054016013643
epoch 14 time used: 19  seconds  train loss: 0.6075182808920805 validation loss: 0.649508305449984
epoch 15 time used: 19  seconds  train loss: 0.6060851591070888 validation loss: 0.6475314999101174
epoch 16 time used: 19  seconds  train loss: 0.6037052944832472 validation loss: 0.6441972672346219
epoch 17 time used: 19  seconds  train loss: 0.6012106351289437 validation loss: 0.6553948481581104
epoch 18 time used: 19  seconds  train loss: 0.5985707627082109 validation loss: 0.6448914316756216
epoch 19 time used: 19  seconds  train loss: 0.5964532919323461 validation loss: 0.6383980690543332
epoch 20 time used: 19  seconds  train loss: 0.597654848061449 validation loss: 0.6426501715954264
epoch 21 time used: 19  seconds  train loss: 0.5922929806526152 validation loss: 0.6498741609836692
epoch 22 time used: 19  seconds  train loss: 0.5922222035707824 validation loss: 0.6365279347742375
epoch 23 time used: 19  seconds  train loss: 0.5889464384461535 validation loss: 0.6381640137724616
epoch 24 time used: 19  seconds  train loss: 0.5868159626659594 validation loss: 0.6296232280446522
epoch 25 time used: 19  seconds  train loss: 0.58479747074427 validation loss: 0.6469879752367883
epoch 26 time used: 19  seconds  train loss: 0.5820332317908492 validation loss: 0.6302983155891076
epoch 27 time used: 19  seconds  train loss: 0.580266018086782 validation loss: 0.6248096005240483
epoch 28 time used: 19  seconds  train loss: 0.577288240406286 validation loss: 0.6384438661793571
epoch 29 time used: 19  seconds  train loss: 0.574610033550778 validation loss: 0.6270295980557874
epoch 30 time used: 19  seconds  train loss: 0.5738729265641691 validation loss: 0.6240039269129435
epoch 31 time used: 19  seconds  train loss: 0.5725535323067037 validation loss: 0.6393604029470416
epoch 32 time used: 19  seconds  train loss: 0.5715303861060489 validation loss: 0.6264309023150164
epoch 33 time used: 19  seconds  train loss: 0.5687939993093906 validation loss: 0.6183476053660188
epoch 34 time used: 19  seconds  train loss: 0.5677071999689594 validation loss: 0.6226819070120949
epoch 35 time used: 19  seconds  train loss: 0.5657935490988057 validation loss: 0.6317140255401383
epoch 36 time used: 19  seconds  train loss: 0.5650532556801059 validation loss: 0.6173929788579988
epoch 37 time used: 19  seconds  train loss: 0.5626476410442531 validation loss: 0.6179123068626841
epoch 38 time used: 19  seconds  train loss: 0.5607335743829502 validation loss: 0.6334955899869624
epoch 39 time used: 19  seconds  train loss: 0.5603728152779732 validation loss: 0.6227483292717245
epoch 40 time used: 19  seconds  train loss: 0.5580133810999722 validation loss: 0.6147871257653877
epoch 41 time used: 19  seconds  train loss: 0.5566788297120063 validation loss: 0.6142243192860143
epoch 42 time used: 19  seconds  train loss: 0.5555927906063508 validation loss: 0.6085581963335104
epoch 43 time used: 19  seconds  train loss: 0.5537024882236551 validation loss: 0.6323318173043171
epoch 44 time used: 19  seconds  train loss: 0.5547477617372321 validation loss: 0.6152193285339508
epoch 45 time used: 19  seconds  train loss: 0.5541619138731217 validation loss: 0.6114077372337455
epoch 46 time used: 19  seconds  train loss: 0.5506565466120437 validation loss: 0.6270679090153518
epoch 47 time used: 19  seconds  train loss: 0.5494152443592104 validation loss: 0.6172300399239383
epoch 48 time used: 19  seconds  train loss: 0.5486630134358684 validation loss: 0.612624641081587
epoch 49 time used: 19  seconds  train loss: 0.547554812085408 validation loss: 0.6071274461437813
epoch 50 time used: 19  seconds  train loss: 0.547690002541793 validation loss: 0.618876248746369
epoch 51 time used: 19  seconds  train loss: 0.5465513505942452 validation loss: 0.6210757624450608
epoch 52 time used: 19  seconds  train loss: 0.5448705719341425 validation loss: 0.6088332673210409
epoch 53 time used: 19  seconds  train loss: 0.5452497649837185 validation loss: 0.6165981473614327
epoch 54 time used: 19  seconds  train loss: 0.5428995771564088 validation loss: 0.6116614021472077
epoch 55 time used: 19  seconds  train loss: 0.5428201471419626 validation loss: 0.6204347826948213
epoch 56 time used: 19  seconds  train loss: 0.5414985972820949 validation loss: 0.6237798288686952
epoch 57 time used: 19  seconds  train loss: 0.5410826512285181 validation loss: 0.6130869542781393
epoch 58 time used: 19  seconds  train loss: 0.5409891157706466 validation loss: 0.6188274549311074
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4080362077e-01, 0.5408036208
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.3634068492, 4.6220565606, 3.5018928770, 31.3218891621
Model Training Ended ... Tue May 31 01:18:39 2022
pred_SZTAXI_GraphWaveNet_2205310058 testing started Tue May 31 01:18:39 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:18:39 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2589241366e-01, 0.5258924137
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.9914437613, 4.6895035730, 3.6051506691, 33.9444756508
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.3739829512, 4.2864884173, 3.3458620993, 31.8848699331
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.0389732495, 4.3633671917, 3.3908411035, 32.2442471981
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.7862155934, 4.4481699151, 3.4498907627, 32.6479941607
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.3892868631, 4.5154497963, 3.4957323118, 33.0107867718
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9580409858, 4.5779953021, 3.5359590847, 33.4032773972
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.6168099877, 4.6493881305, 3.5867819433, 33.8377207518
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.1428832730, 4.7056225171, 3.6239559063, 34.1358155012
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.7966106880, 4.7745796347, 3.6687921332, 34.4818621874
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.5145706272, 4.8491824700, 3.7223646447, 34.9184364080
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.2955699413, 4.9290536558, 3.7696339930, 35.2576613426
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0786791028, 5.0078617296, 3.8122594582, 35.5558186769
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.9575582601, 5.0948560588, 3.8633329050, 35.9840273857
Model Testing Ended ... Tue May 31 01:18:44 2022
