../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_5.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310118 training started Tue May 31 01:18:51 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:18:51 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6916966408618314 validation loss: 0.7080776731469738
epoch 1 time used: 19  seconds  train loss: 0.6561738997485865 validation loss: 0.6927069778466106
epoch 2 time used: 19  seconds  train loss: 0.6440964729484081 validation loss: 0.6908747841469685
epoch 3 time used: 19  seconds  train loss: 0.6366000177171797 validation loss: 0.7103185790095163
epoch 4 time used: 19  seconds  train loss: 0.6308701508923581 validation loss: 0.668620158783832
epoch 5 time used: 19  seconds  train loss: 0.6296018642687357 validation loss: 0.6677671406992632
epoch 6 time used: 19  seconds  train loss: 0.6221728514387123 validation loss: 0.6722876201221599
epoch 7 time used: 19  seconds  train loss: 0.6211267256126295 validation loss: 0.6539035897646377
epoch 8 time used: 19  seconds  train loss: 0.6180660109092636 validation loss: 0.659583187370158
epoch 9 time used: 19  seconds  train loss: 0.6162696719847905 validation loss: 0.6627764070211951
epoch 10 time used: 19  seconds  train loss: 0.6139948050972408 validation loss: 0.6489863434241185
epoch 11 time used: 19  seconds  train loss: 0.6091796568413378 validation loss: 0.6811430056889852
epoch 12 time used: 19  seconds  train loss: 0.6074581272571559 validation loss: 0.6447891008794604
epoch 13 time used: 19  seconds  train loss: 0.6064318542714479 validation loss: 0.6432871516071149
epoch 14 time used: 19  seconds  train loss: 0.605032641721484 validation loss: 0.645805055822306
epoch 15 time used: 19  seconds  train loss: 0.6030905858042569 validation loss: 0.6404504856066917
epoch 16 time used: 19  seconds  train loss: 0.6011290214054954 validation loss: 0.6430528235079637
epoch 17 time used: 19  seconds  train loss: 0.5989106274600727 validation loss: 0.6499469434443991
epoch 18 time used: 19  seconds  train loss: 0.5965915765735198 validation loss: 0.644262950218732
epoch 19 time used: 19  seconds  train loss: 0.5941103191497824 validation loss: 0.6368649259432039
epoch 20 time used: 19  seconds  train loss: 0.5970579239077453 validation loss: 0.6539888708152581
epoch 21 time used: 19  seconds  train loss: 0.5905846592203143 validation loss: 0.6433753762672196
epoch 22 time used: 19  seconds  train loss: 0.5906569743224263 validation loss: 0.638714765138294
epoch 23 time used: 19  seconds  train loss: 0.5876342334584526 validation loss: 0.6424694351889008
epoch 24 time used: 19  seconds  train loss: 0.5852281487683314 validation loss: 0.6337471648828307
epoch 25 time used: 19  seconds  train loss: 0.5828762574182296 validation loss: 0.6353114116844253
epoch 26 time used: 19  seconds  train loss: 0.5798937579985194 validation loss: 0.6264821649783879
epoch 27 time used: 19  seconds  train loss: 0.5784545590833444 validation loss: 0.6246024521429148
epoch 28 time used: 19  seconds  train loss: 0.5762577890332359 validation loss: 0.6315177091911658
epoch 29 time used: 19  seconds  train loss: 0.5742090218945554 validation loss: 0.6243005136945354
epoch 30 time used: 19  seconds  train loss: 0.5727955846494834 validation loss: 0.6274495750517395
epoch 31 time used: 19  seconds  train loss: 0.5711642407082222 validation loss: 0.646950580290894
epoch 32 time used: 19  seconds  train loss: 0.5705336679944273 validation loss: 0.6247297952424234
epoch 33 time used: 19  seconds  train loss: 0.5672282127618451 validation loss: 0.6174289400304728
epoch 34 time used: 19  seconds  train loss: 0.5658286893859527 validation loss: 0.6265578679184416
epoch 35 time used: 19  seconds  train loss: 0.5640454767099654 validation loss: 0.6324697202117882
epoch 36 time used: 19  seconds  train loss: 0.563777426016619 validation loss: 0.6198352538234558
epoch 37 time used: 19  seconds  train loss: 0.5606999180225356 validation loss: 0.6228522182400547
epoch 38 time used: 19  seconds  train loss: 0.5591331642348939 validation loss: 0.6278444718365646
epoch 39 time used: 19  seconds  train loss: 0.5581507869753695 validation loss: 0.6144346989209379
epoch 40 time used: 19  seconds  train loss: 0.5562095739593885 validation loss: 0.6118810541594206
epoch 41 time used: 19  seconds  train loss: 0.5545865524544316 validation loss: 0.6208749545450828
epoch 42 time used: 19  seconds  train loss: 0.5528932997207044 validation loss: 0.6135939831164345
epoch 43 time used: 19  seconds  train loss: 0.5516348789799773 validation loss: 0.6350915153228228
epoch 44 time used: 19  seconds  train loss: 0.5524414180013567 validation loss: 0.6159558067867412
epoch 45 time used: 19  seconds  train loss: 0.5522952050945668 validation loss: 0.6126289596011982
epoch 46 time used: 19  seconds  train loss: 0.5488211948366287 validation loss: 0.6164121832420577
epoch 47 time used: 19  seconds  train loss: 0.5475294545059692 validation loss: 0.611995845291745
epoch 48 time used: 19  seconds  train loss: 0.5462443803146927 validation loss: 0.6135498448390866
epoch 49 time used: 19  seconds  train loss: 0.5460028710270335 validation loss: 0.613769907263381
Early stopping at epoch: 50
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.4818439704e-01, 0.5481843970
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.7091038865, 4.6593029400, 3.5310822163, 31.5652400255
Model Training Ended ... Tue May 31 01:35:53 2022
pred_SZTAXI_GraphWaveNet_2205310118 testing started Tue May 31 01:35:53 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:35:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3275004669e-01, 0.5327500467
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.6931905021, 4.7637370312, 3.6302792619, 34.2656016350
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.1136687744, 4.2560155985, 3.3143405372, 31.8660795689
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.9236277538, 4.3501296249, 3.3765115844, 32.3103159666
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.6789575599, 4.4360971089, 3.4305056766, 32.7066600323
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.4256765339, 4.5194774625, 3.4833713999, 33.1527411938
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.1554252842, 4.5995027214, 3.5333958785, 33.5412710905
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.8771800451, 4.6773047843, 3.5848512203, 33.9085787535
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8870388427, 4.7840400127, 3.6463042098, 34.3780815601
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7467325112, 4.8730619236, 3.7031850578, 34.7981929779
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.5660672433, 4.9564167746, 3.7557548783, 35.1919263601
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.8837385664, 5.0876063691, 3.8388750967, 35.8554244041
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 27.0452419000, 5.2005040044, 3.9165924788, 36.4774793386
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 28.0845574928, 5.2994865311, 3.9842906440, 37.0361953974
Model Testing Ended ... Tue May 31 01:35:59 2022
