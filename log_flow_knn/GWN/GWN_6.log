../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_6.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310136 training started Tue May 31 01:36:05 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:36:05 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6893805674095751 validation loss: 0.7028359379341353
epoch 1 time used: 19  seconds  train loss: 0.6533493177904344 validation loss: 0.7005475412553815
epoch 2 time used: 19  seconds  train loss: 0.6415294809836581 validation loss: 0.6861347013445043
epoch 3 time used: 19  seconds  train loss: 0.6341008821218824 validation loss: 0.7054382518156251
epoch 4 time used: 19  seconds  train loss: 0.6290157952824155 validation loss: 0.6638285852783355
epoch 5 time used: 19  seconds  train loss: 0.6275118710645402 validation loss: 0.6685399196634245
epoch 6 time used: 19  seconds  train loss: 0.6208779940734038 validation loss: 0.6714213996087733
epoch 7 time used: 19  seconds  train loss: 0.6200210304551919 validation loss: 0.6521790675559447
epoch 8 time used: 19  seconds  train loss: 0.6164220775852501 validation loss: 0.6564980616320425
epoch 9 time used: 19  seconds  train loss: 0.6154354644533919 validation loss: 0.6653970310937113
epoch 10 time used: 19  seconds  train loss: 0.6113618352843891 validation loss: 0.6473169707836797
epoch 11 time used: 19  seconds  train loss: 0.6086553789643441 validation loss: 0.6732138318208912
epoch 12 time used: 19  seconds  train loss: 0.6062424650911247 validation loss: 0.6435612505348167
epoch 13 time used: 19  seconds  train loss: 0.6047525583510718 validation loss: 0.6417137126424419
epoch 14 time used: 19  seconds  train loss: 0.6030453260389195 validation loss: 0.6470011460840406
epoch 15 time used: 19  seconds  train loss: 0.6019870840638325 validation loss: 0.6479925958078299
epoch 16 time used: 19  seconds  train loss: 0.6007201542725434 validation loss: 0.6437910793729089
epoch 17 time used: 19  seconds  train loss: 0.5983860883570328 validation loss: 0.6453827173259128
epoch 18 time used: 19  seconds  train loss: 0.5959756484581091 validation loss: 0.6379323186565987
epoch 19 time used: 19  seconds  train loss: 0.5934099417662044 validation loss: 0.635050328513283
epoch 20 time used: 19  seconds  train loss: 0.5952638943029163 validation loss: 0.6440323878876606
epoch 21 time used: 19  seconds  train loss: 0.5904380605790558 validation loss: 0.6491301590530434
epoch 22 time used: 19  seconds  train loss: 0.5908600411577889 validation loss: 0.6342666786701525
epoch 23 time used: 19  seconds  train loss: 0.5874873377690105 validation loss: 0.6386403337639955
epoch 24 time used: 19  seconds  train loss: 0.5852695652634796 validation loss: 0.6372071709205855
epoch 25 time used: 19  seconds  train loss: 0.5833481433635755 validation loss: 0.6346889734268188
epoch 26 time used: 19  seconds  train loss: 0.5803326477706009 validation loss: 0.6284497700520416
epoch 27 time used: 19  seconds  train loss: 0.5794012663544157 validation loss: 0.6226115472874238
epoch 28 time used: 19  seconds  train loss: 0.5765506008356428 validation loss: 0.6368834557224862
epoch 29 time used: 19  seconds  train loss: 0.5754053984393775 validation loss: 0.6257315998646751
epoch 30 time used: 19  seconds  train loss: 0.5731568043974691 validation loss: 0.634017442292835
epoch 31 time used: 19  seconds  train loss: 0.5722436149462867 validation loss: 0.6438899923912922
epoch 32 time used: 19  seconds  train loss: 0.5722328525349222 validation loss: 0.6290709182101103
epoch 33 time used: 19  seconds  train loss: 0.5683186518433763 validation loss: 0.6183609375313147
epoch 34 time used: 19  seconds  train loss: 0.5667934062894683 validation loss: 0.62784377526288
epoch 35 time used: 19  seconds  train loss: 0.5656811616159605 validation loss: 0.631460337199975
epoch 36 time used: 19  seconds  train loss: 0.564582367031537 validation loss: 0.6243139198466913
epoch 37 time used: 19  seconds  train loss: 0.5619012803305603 validation loss: 0.6261670841506465
epoch 38 time used: 19  seconds  train loss: 0.560197055170241 validation loss: 0.6358451520032551
epoch 39 time used: 19  seconds  train loss: 0.5589251623384305 validation loss: 0.6177852073712136
epoch 40 time used: 19  seconds  train loss: 0.5569593585911041 validation loss: 0.6156118604081187
epoch 41 time used: 19  seconds  train loss: 0.5560586977310235 validation loss: 0.6182961441687683
epoch 42 time used: 19  seconds  train loss: 0.5534962470806171 validation loss: 0.6163470982319087
epoch 43 time used: 19  seconds  train loss: 0.5522803542115441 validation loss: 0.6436587358588604
epoch 44 time used: 19  seconds  train loss: 0.5527842831645547 validation loss: 0.6134362191110108
epoch 45 time used: 19  seconds  train loss: 0.5527486010940791 validation loss: 0.614764809905
epoch 46 time used: 19  seconds  train loss: 0.549259015031763 validation loss: 0.6116698360561732
epoch 47 time used: 19  seconds  train loss: 0.5482136069202151 validation loss: 0.6087493813453029
epoch 48 time used: 19  seconds  train loss: 0.5465267114924164 validation loss: 0.6185284252487012
epoch 49 time used: 19  seconds  train loss: 0.5459503828207426 validation loss: 0.6099171460564456
epoch 50 time used: 19  seconds  train loss: 0.5450928911545537 validation loss: 0.6135187146082446
epoch 51 time used: 19  seconds  train loss: 0.5439011847989828 validation loss: 0.6286095443056591
epoch 52 time used: 19  seconds  train loss: 0.5423299370924406 validation loss: 0.6103339174493628
epoch 53 time used: 19  seconds  train loss: 0.5416524187260298 validation loss: 0.6106784779634049
epoch 54 time used: 19  seconds  train loss: 0.5403072407540692 validation loss: 0.6216461717785887
epoch 55 time used: 19  seconds  train loss: 0.5401982768501021 validation loss: 0.6154277982996471
epoch 56 time used: 19  seconds  train loss: 0.5389378029286098 validation loss: 0.6382544126676682
Early stopping at epoch: 57
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.3648101618e-01, 0.5364810162
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.5369138744, 4.6407880661, 3.5292736397, 31.4856529236
Model Training Ended ... Tue May 31 01:55:25 2022
pred_SZTAXI_GraphWaveNet_2205310136 testing started Tue May 31 01:55:25 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:55:25 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.1898883534e-01, 0.5189888353
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.3436633191, 4.6199202719, 3.5413310875, 33.5650682449
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.0804761498, 4.2521143152, 3.3156155658, 31.8580657244
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8033812842, 4.3362865777, 3.3699299210, 32.2511374950
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.4642546518, 4.4118312130, 3.4125406483, 32.6078206301
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.0362581621, 4.4761879051, 3.4522848209, 32.8966170549
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.5010458973, 4.5278080676, 3.4862649400, 33.1381767988
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9040784158, 4.5720978135, 3.5109716121, 33.3134144545
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.4993616464, 4.6367404118, 3.5575905519, 33.7009400129
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0759661024, 4.6985067950, 3.5937482909, 33.9911520481
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.6471040321, 4.7588973547, 3.6325513534, 34.2716962099
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.2906333741, 4.8260370258, 3.6783662732, 34.5853179693
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.0697241750, 4.9060905184, 3.7251266806, 34.9429190159
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.7968276645, 4.9796413189, 3.7640327878, 35.2466464043
Model Testing Ended ... Tue May 31 01:55:31 2022
