../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_7.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310155 training started Tue May 31 01:55:37 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:55:37 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6878876433857474 validation loss: 0.6971802062063075
epoch 1 time used: 19  seconds  train loss: 0.6518515099163246 validation loss: 0.696017500179917
epoch 2 time used: 19  seconds  train loss: 0.6409013025452029 validation loss: 0.6788516014962647
epoch 3 time used: 19  seconds  train loss: 0.6336096894011898 validation loss: 0.6999980240911987
epoch 4 time used: 19  seconds  train loss: 0.628784204360262 validation loss: 0.6644759056580007
epoch 5 time used: 19  seconds  train loss: 0.6249188058406835 validation loss: 0.6636559939503077
epoch 6 time used: 19  seconds  train loss: 0.6215691539335726 validation loss: 0.6719346053861267
epoch 7 time used: 19  seconds  train loss: 0.6191950375969345 validation loss: 0.6504798940758207
epoch 8 time used: 19  seconds  train loss: 0.6169987915250689 validation loss: 0.653882702339941
epoch 9 time used: 19  seconds  train loss: 0.6143333630405822 validation loss: 0.6690261233505325
epoch 10 time used: 19  seconds  train loss: 0.6116571527287088 validation loss: 0.648741377082037
epoch 11 time used: 19  seconds  train loss: 0.6085336185451252 validation loss: 0.6690286347522071
epoch 12 time used: 19  seconds  train loss: 0.6059099833453193 validation loss: 0.6457191848043186
epoch 13 time used: 19  seconds  train loss: 0.6047155352608747 validation loss: 0.6445493775220653
epoch 14 time used: 19  seconds  train loss: 0.6027910772970696 validation loss: 0.6551387665876701
epoch 15 time used: 19  seconds  train loss: 0.6018118958385028 validation loss: 0.6469016208577512
epoch 16 time used: 19  seconds  train loss: 0.5999054335598247 validation loss: 0.6472239423154006
epoch 17 time used: 19  seconds  train loss: 0.5986370680851075 validation loss: 0.6416743416987841
epoch 18 time used: 19  seconds  train loss: 0.5956676974574668 validation loss: 0.6403707218407398
epoch 19 time used: 19  seconds  train loss: 0.5933959150890876 validation loss: 0.6319801642823575
epoch 20 time used: 19  seconds  train loss: 0.5943104238971368 validation loss: 0.6405948839377408
epoch 21 time used: 19  seconds  train loss: 0.5896229697749082 validation loss: 0.6468396302479417
epoch 22 time used: 19  seconds  train loss: 0.5898990692149525 validation loss: 0.6463750141177012
epoch 23 time used: 19  seconds  train loss: 0.587210566356545 validation loss: 0.6381166663335923
epoch 24 time used: 19  seconds  train loss: 0.5850624407338214 validation loss: 0.6344673372619781
epoch 25 time used: 19  seconds  train loss: 0.5827941039463195 validation loss: 0.6318984446833976
epoch 26 time used: 19  seconds  train loss: 0.5804192691744645 validation loss: 0.6272196950604073
epoch 27 time used: 19  seconds  train loss: 0.5787846154373028 validation loss: 0.6279218321415916
epoch 28 time used: 19  seconds  train loss: 0.5765993279294981 validation loss: 0.6365090285367634
epoch 29 time used: 19  seconds  train loss: 0.5747332168507203 validation loss: 0.6249972137052622
epoch 30 time used: 19  seconds  train loss: 0.5734943913701249 validation loss: 0.633918034496592
epoch 31 time used: 19  seconds  train loss: 0.571591245500665 validation loss: 0.6487190059168422
epoch 32 time used: 19  seconds  train loss: 0.5715116248870133 validation loss: 0.6311474223042008
epoch 33 time used: 19  seconds  train loss: 0.5676521959040277 validation loss: 0.62212386119425
epoch 34 time used: 19  seconds  train loss: 0.5661768184532312 validation loss: 0.6195194220068443
epoch 35 time used: 19  seconds  train loss: 0.5652148305606707 validation loss: 0.6245035268181
epoch 36 time used: 19  seconds  train loss: 0.5641291401803409 validation loss: 0.6156062486752942
epoch 37 time used: 19  seconds  train loss: 0.5613849658206381 validation loss: 0.6179796827966301
epoch 38 time used: 19  seconds  train loss: 0.5597822975637563 validation loss: 0.6291316486709747
epoch 39 time used: 19  seconds  train loss: 0.5595161924575843 validation loss: 0.6163142741616092
epoch 40 time used: 19  seconds  train loss: 0.5566699204709418 validation loss: 0.6120007293141303
epoch 41 time used: 19  seconds  train loss: 0.5556241908080208 validation loss: 0.6175346113556061
epoch 42 time used: 19  seconds  train loss: 0.5528543499082454 validation loss: 0.6123794364691967
epoch 43 time used: 19  seconds  train loss: 0.5523057736000668 validation loss: 0.6209939037685963
epoch 44 time used: 19  seconds  train loss: 0.5517297354904381 validation loss: 0.6157764851750426
epoch 45 time used: 19  seconds  train loss: 0.551878905398069 validation loss: 0.6137333915601322
epoch 46 time used: 19  seconds  train loss: 0.5488894515661562 validation loss: 0.6121937635526136
epoch 47 time used: 19  seconds  train loss: 0.5479748000630613 validation loss: 0.6101350096327749
epoch 48 time used: 19  seconds  train loss: 0.5463896156374795 validation loss: 0.6151072442235045
epoch 49 time used: 19  seconds  train loss: 0.5453560828823453 validation loss: 0.6066676977261976
epoch 50 time used: 19  seconds  train loss: 0.5440987752986327 validation loss: 0.6121621550019107
epoch 51 time used: 19  seconds  train loss: 0.543551444159463 validation loss: 0.6273416571356171
epoch 52 time used: 19  seconds  train loss: 0.54243184280599 validation loss: 0.6196022514087051
epoch 53 time used: 19  seconds  train loss: 0.5421725528508128 validation loss: 0.6092417266831469
epoch 54 time used: 19  seconds  train loss: 0.5408099472607522 validation loss: 0.6185755361965046
epoch 55 time used: 19  seconds  train loss: 0.5401220598905897 validation loss: 0.6101531679950544
epoch 56 time used: 19  seconds  train loss: 0.5384670938570503 validation loss: 0.6289732334625662
epoch 57 time used: 19  seconds  train loss: 0.538735385131022 validation loss: 0.6093057586779049
epoch 58 time used: 19  seconds  train loss: 0.5378948374628851 validation loss: 0.6132598722455513
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.3005411496e-01, 0.5300541150
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 20.8891448185, 4.5704643986, 3.4739163986, 30.9588015079
Model Training Ended ... Tue May 31 02:15:36 2022
pred_SZTAXI_GraphWaveNet_2205310155 testing started Tue May 31 02:15:36 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:15:36 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2151942901e-01, 0.5215194290
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.6840155122, 4.6566098733, 3.5803125101, 33.6813986301
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.2025662836, 4.2664465640, 3.3269487576, 31.7724496126
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8500829391, 4.3416682208, 3.3742024011, 32.1412861347
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.5974553123, 4.4269013217, 3.4326621873, 32.5244992971
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.2779087544, 4.5030999050, 3.4835539372, 32.9067587852
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.8351287902, 4.5645513241, 3.5230861624, 33.2425624132
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.4187006324, 4.6280342082, 3.5691028857, 33.6470931768
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.9730413367, 4.6875410757, 3.6110272551, 33.9718580246
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.5146641173, 4.7449619722, 3.6455700358, 34.2128276825
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.1766099339, 4.8142091701, 3.6945573946, 34.5885753632
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.8046371136, 4.8789996017, 3.7301979497, 34.7874075174
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.4677030055, 4.9464839033, 3.7672812694, 35.0377827883
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.1374273557, 5.0137239010, 3.8089026127, 35.3684425354
Model Testing Ended ... Tue May 31 02:15:42 2022
