../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_8.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310215 training started Tue May 31 02:15:47 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:15:47 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6867779569639421 validation loss: 0.6944699142109695
epoch 1 time used: 19  seconds  train loss: 0.6514149907218613 validation loss: 0.6934214527927228
epoch 2 time used: 19  seconds  train loss: 0.6406664779650877 validation loss: 0.6729790740345248
epoch 3 time used: 19  seconds  train loss: 0.6326950866501159 validation loss: 0.6981423251071379
epoch 4 time used: 19  seconds  train loss: 0.6277091252176386 validation loss: 0.6636831573585966
epoch 5 time used: 19  seconds  train loss: 0.6234113640161192 validation loss: 0.6682690663717279
epoch 6 time used: 19  seconds  train loss: 0.6194325900433921 validation loss: 0.6726714452700828
epoch 7 time used: 19  seconds  train loss: 0.6181531439125961 validation loss: 0.6524461206067261
epoch 8 time used: 19  seconds  train loss: 0.6142958584923832 validation loss: 0.6528824899920184
epoch 9 time used: 19  seconds  train loss: 0.6131276054199186 validation loss: 0.670723579119687
epoch 10 time used: 19  seconds  train loss: 0.611210076432479 validation loss: 0.6473428940595086
epoch 11 time used: 19  seconds  train loss: 0.6077397532686909 validation loss: 0.6711984000988861
epoch 12 time used: 19  seconds  train loss: 0.6056304261999822 validation loss: 0.6423713570803552
epoch 13 time used: 19  seconds  train loss: 0.6039966586897756 validation loss: 0.6493943953395482
epoch 14 time used: 19  seconds  train loss: 0.6025919638690704 validation loss: 0.648530837315232
epoch 15 time used: 19  seconds  train loss: 0.6008266112204127 validation loss: 0.650812706247491
epoch 16 time used: 19  seconds  train loss: 0.6002586317774581 validation loss: 0.6421627093903461
epoch 17 time used: 19  seconds  train loss: 0.5975536076646102 validation loss: 0.6368955086119732
epoch 18 time used: 19  seconds  train loss: 0.5953084511912904 validation loss: 0.6469427020988654
epoch 19 time used: 19  seconds  train loss: 0.5925790642945898 validation loss: 0.6316937332722679
epoch 20 time used: 19  seconds  train loss: 0.5934026215866653 validation loss: 0.6484125609421612
epoch 21 time used: 19  seconds  train loss: 0.5892375676679408 validation loss: 0.6412093968533757
epoch 22 time used: 19  seconds  train loss: 0.5886026294438292 validation loss: 0.6367453310027051
epoch 23 time used: 19  seconds  train loss: 0.5863434358646995 validation loss: 0.6349942945129242
epoch 24 time used: 19  seconds  train loss: 0.5843999964922963 validation loss: 0.6393193383121965
epoch 25 time used: 19  seconds  train loss: 0.5825354602309752 validation loss: 0.6261213937802101
epoch 26 time used: 19  seconds  train loss: 0.5799951064128794 validation loss: 0.6294802593354561
epoch 27 time used: 19  seconds  train loss: 0.577570119843544 validation loss: 0.619702321973013
epoch 28 time used: 19  seconds  train loss: 0.5758271638733224 validation loss: 0.6380206103348613
epoch 29 time used: 19  seconds  train loss: 0.5741547922660751 validation loss: 0.6266671063295052
epoch 30 time used: 19  seconds  train loss: 0.572961661927561 validation loss: 0.6292988070801123
epoch 31 time used: 19  seconds  train loss: 0.5708148716014955 validation loss: 0.6417905875106356
epoch 32 time used: 19  seconds  train loss: 0.5707223027902172 validation loss: 0.6216178898194537
epoch 33 time used: 19  seconds  train loss: 0.566785555687941 validation loss: 0.6172603766123453
epoch 34 time used: 19  seconds  train loss: 0.5653131828877869 validation loss: 0.6158782098423782
epoch 35 time used: 19  seconds  train loss: 0.5656467697359251 validation loss: 0.641317835198113
epoch 36 time used: 19  seconds  train loss: 0.5662377571228727 validation loss: 0.6145877001890495
epoch 37 time used: 19  seconds  train loss: 0.5607034067171566 validation loss: 0.6108669991516948
epoch 38 time used: 19  seconds  train loss: 0.5585114931314124 validation loss: 0.6322536352855056
epoch 39 time used: 19  seconds  train loss: 0.5575242463080676 validation loss: 0.611748805093528
epoch 40 time used: 19  seconds  train loss: 0.5559668810574462 validation loss: 0.6110053676277843
epoch 41 time used: 19  seconds  train loss: 0.5544705243402321 validation loss: 0.6132068682962389
epoch 42 time used: 19  seconds  train loss: 0.5516903213891671 validation loss: 0.6109794855710879
epoch 43 time used: 19  seconds  train loss: 0.551222209740499 validation loss: 0.6188043504212033
epoch 44 time used: 19  seconds  train loss: 0.5505922967475305 validation loss: 0.6084026434824834
epoch 45 time used: 19  seconds  train loss: 0.5517332211327587 validation loss: 0.6140080601421755
epoch 46 time used: 19  seconds  train loss: 0.5479991093044769 validation loss: 0.6114446313226994
epoch 47 time used: 19  seconds  train loss: 0.5468524763967371 validation loss: 0.6087677538098387
epoch 48 time used: 19  seconds  train loss: 0.5451077922309615 validation loss: 0.60623207910737
epoch 49 time used: 19  seconds  train loss: 0.5442732653950221 validation loss: 0.6033602754275004
epoch 50 time used: 19  seconds  train loss: 0.5429076236986673 validation loss: 0.6105924278349426
epoch 51 time used: 19  seconds  train loss: 0.5427370150262227 validation loss: 0.6192751013817479
epoch 52 time used: 19  seconds  train loss: 0.5416629456863294 validation loss: 0.6120913132506224
epoch 53 time used: 19  seconds  train loss: 0.5409296647583268 validation loss: 0.6082749989495349
epoch 54 time used: 19  seconds  train loss: 0.5399106880848642 validation loss: 0.609656748190448
epoch 55 time used: 19  seconds  train loss: 0.5391640556316457 validation loss: 0.6131025884875018
epoch 56 time used: 19  seconds  train loss: 0.5377195372350864 validation loss: 0.648205837207054
epoch 57 time used: 19  seconds  train loss: 0.5377755120163452 validation loss: 0.6081892775362404
epoch 58 time used: 19  seconds  train loss: 0.5360484606934814 validation loss: 0.6096582544680259
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.3220749826e-01, 0.5322074983
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 20.8917910500, 4.5707538820, 3.4696685326, 30.9860557318
Model Training Ended ... Tue May 31 02:35:46 2022
pred_SZTAXI_GraphWaveNet_2205310215 testing started Tue May 31 02:35:46 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:35:46 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2495677555e-01, 0.5249567756
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.0941178767, 4.7004380516, 3.6157833945, 33.9511275291
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.3183826051, 4.2799979679, 3.3373852317, 31.8081289530
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.0129701381, 4.3603864666, 3.3886727960, 32.1942180395
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.8285490237, 4.4529258947, 3.4538240878, 32.6583296061
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.5667202618, 4.5350546041, 3.5097813567, 33.0943137407
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.2168708786, 4.6061774693, 3.5575336199, 33.5132092237
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.9333108424, 4.6833012761, 3.6120201918, 33.9820623398
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.5293204819, 4.7465061342, 3.6544835082, 34.3122839928
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.0550284792, 4.8015652114, 3.6895605685, 34.5669418573
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.7219386737, 4.8705172902, 3.7383498517, 34.9353194237
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3349486117, 4.9330465852, 3.7768250856, 35.1615905762
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.9925745301, 4.9992573979, 3.8163070460, 35.4413747787
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.6696354114, 5.0665210363, 3.8582748735, 35.7732415199
Model Testing Ended ... Tue May 31 02:35:52 2022
