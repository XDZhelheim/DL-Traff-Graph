../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/adj_9.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310235 training started Tue May 31 02:35:58 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:35:58 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.6858495825724107 validation loss: 0.6937332120700855
epoch 1 time used: 19  seconds  train loss: 0.6509567155353037 validation loss: 0.6908374763839874
epoch 2 time used: 19  seconds  train loss: 0.640429436482203 validation loss: 0.6695946392728321
epoch 3 time used: 19  seconds  train loss: 0.632307309005542 validation loss: 0.6954618004424062
epoch 4 time used: 19  seconds  train loss: 0.6276138502028724 validation loss: 0.6626003002052876
epoch 5 time used: 19  seconds  train loss: 0.6227504750064562 validation loss: 0.6667516863168176
epoch 6 time used: 19  seconds  train loss: 0.6188933562333689 validation loss: 0.6696920329658547
epoch 7 time used: 19  seconds  train loss: 0.61761350007688 validation loss: 0.6590928104682942
epoch 8 time used: 19  seconds  train loss: 0.6143066732167859 validation loss: 0.6527398654180973
epoch 9 time used: 19  seconds  train loss: 0.6123675613281229 validation loss: 0.6642791661457043
epoch 10 time used: 19  seconds  train loss: 0.6104260781411596 validation loss: 0.6466221781215857
epoch 11 time used: 19  seconds  train loss: 0.6068314582660561 validation loss: 0.6666308350824005
epoch 12 time used: 19  seconds  train loss: 0.6053309594075676 validation loss: 0.6406076099742112
epoch 13 time used: 19  seconds  train loss: 0.6035125389546792 validation loss: 0.649775715609688
epoch 14 time used: 19  seconds  train loss: 0.6018582250112151 validation loss: 0.6545324681410148
epoch 15 time used: 19  seconds  train loss: 0.6020043354115818 validation loss: 0.6474585381906424
epoch 16 time used: 19  seconds  train loss: 0.6016065797120714 validation loss: 0.639283770500724
epoch 17 time used: 19  seconds  train loss: 0.5991882831070195 validation loss: 0.6374250491756704
epoch 18 time used: 19  seconds  train loss: 0.5956721395720459 validation loss: 0.6387275724268672
epoch 19 time used: 19  seconds  train loss: 0.5936194935530043 validation loss: 0.6314209849383701
epoch 20 time used: 19  seconds  train loss: 0.5941188806829547 validation loss: 0.6467436718110421
epoch 21 time used: 19  seconds  train loss: 0.5903917726123994 validation loss: 0.6429416839756182
epoch 22 time used: 19  seconds  train loss: 0.5907987864902654 validation loss: 0.6367732120390556
epoch 23 time used: 19  seconds  train loss: 0.5879148742552333 validation loss: 0.6393256632249746
epoch 24 time used: 19  seconds  train loss: 0.5853044416962104 validation loss: 0.6354913171844103
epoch 25 time used: 19  seconds  train loss: 0.5843859516709492 validation loss: 0.6284317730078056
epoch 26 time used: 19  seconds  train loss: 0.5821059440311632 validation loss: 0.6259771241477473
epoch 27 time used: 19  seconds  train loss: 0.5794326548556006 validation loss: 0.6242155527594078
epoch 28 time used: 19  seconds  train loss: 0.5774558375604122 validation loss: 0.6332276991350734
epoch 29 time used: 19  seconds  train loss: 0.5759595094161217 validation loss: 0.6342169070125219
epoch 30 time used: 19  seconds  train loss: 0.5744879617121277 validation loss: 0.6347798488626433
epoch 31 time used: 19  seconds  train loss: 0.5724845262374173 validation loss: 0.6405028688966932
epoch 32 time used: 19  seconds  train loss: 0.5726713701807079 validation loss: 0.6236936641273214
epoch 33 time used: 19  seconds  train loss: 0.5685538689408499 validation loss: 0.6266417909617448
epoch 34 time used: 19  seconds  train loss: 0.5669679793490794 validation loss: 0.62022686760817
epoch 35 time used: 19  seconds  train loss: 0.5668660369231385 validation loss: 0.6282181852492527
epoch 36 time used: 19  seconds  train loss: 0.563961338606871 validation loss: 0.6156728553831281
epoch 37 time used: 19  seconds  train loss: 0.5619483135672416 validation loss: 0.6138168282769806
epoch 38 time used: 19  seconds  train loss: 0.5603983525192077 validation loss: 0.628587551377899
epoch 39 time used: 19  seconds  train loss: 0.5587001920255116 validation loss: 0.6177965963064734
epoch 40 time used: 19  seconds  train loss: 0.5573961902648253 validation loss: 0.6153092689775116
epoch 41 time used: 19  seconds  train loss: 0.5552159229857824 validation loss: 0.6161957983650378
epoch 42 time used: 19  seconds  train loss: 0.5531185203222597 validation loss: 0.6117043684964156
epoch 43 time used: 19  seconds  train loss: 0.552337899994884 validation loss: 0.6194285771146936
epoch 44 time used: 19  seconds  train loss: 0.5509740263435613 validation loss: 0.6107767037491301
epoch 45 time used: 19  seconds  train loss: 0.5513391560460222 validation loss: 0.6085157596056734
epoch 46 time used: 19  seconds  train loss: 0.5488740904826358 validation loss: 0.6096517369521791
epoch 47 time used: 19  seconds  train loss: 0.5473554309876172 validation loss: 0.609472186411198
epoch 48 time used: 19  seconds  train loss: 0.546115661243965 validation loss: 0.6093682528135196
epoch 49 time used: 19  seconds  train loss: 0.5447215754141339 validation loss: 0.6052396078014848
epoch 50 time used: 19  seconds  train loss: 0.5438621926782481 validation loss: 0.6108219582050001
epoch 51 time used: 19  seconds  train loss: 0.5432482498299177 validation loss: 0.6207907250271508
epoch 52 time used: 19  seconds  train loss: 0.542119807149065 validation loss: 0.6098295648892721
epoch 53 time used: 19  seconds  train loss: 0.540852528462878 validation loss: 0.607390821573153
epoch 54 time used: 19  seconds  train loss: 0.5396346567704702 validation loss: 0.6146116657043571
epoch 55 time used: 19  seconds  train loss: 0.5395629071070154 validation loss: 0.6139928419791644
epoch 56 time used: 19  seconds  train loss: 0.5384466511596148 validation loss: 0.6203787753831095
epoch 57 time used: 19  seconds  train loss: 0.5375187678493104 validation loss: 0.6112402980007342
epoch 58 time used: 19  seconds  train loss: 0.536840696126265 validation loss: 0.6073252646187645
Early stopping at epoch: 59
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.3199505925e-01, 0.5319950592
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 21.1360135840, 4.5973920416, 3.4936184552, 31.1981230974
Model Training Ended ... Tue May 31 02:55:57 2022
pred_SZTAXI_GraphWaveNet_2205310235 testing started Tue May 31 02:55:57 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:55:57 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.2148886261e-01, 0.5214888626
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.8186910070, 4.6710481701, 3.5875156895, 33.7017059326
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.1319612985, 4.2581640760, 3.3185752520, 31.6321104765
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.8661192281, 4.3435146170, 3.3733929422, 32.0830076933
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.6852642023, 4.4368078843, 3.4374029385, 32.5222492218
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.4167321296, 4.5184878145, 3.4922984013, 32.9497098923
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.9795439034, 4.5803432080, 3.5324190771, 33.3020389080
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.6534456104, 4.6533262953, 3.5842956950, 33.7474703789
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.1722911664, 4.7087462415, 3.6225195817, 34.0213179588
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.7582851127, 4.7705644438, 3.6605704089, 34.2946976423
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.3798187620, 4.8352682203, 3.7056572379, 34.6431046724
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.9833181097, 4.8972766013, 3.7399318953, 34.8308533430
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.6186301213, 4.9617164491, 3.7754174912, 35.0780516863
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.2276601266, 5.0227144182, 3.8111115472, 35.3415280581
Model Testing Ended ... Tue May 31 02:56:03 2022
