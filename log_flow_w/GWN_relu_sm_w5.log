../SZTAXI/SZTAXI-flow.pkl
../SZTAXI/cor_matrix_relu_sm_w5.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2211111536 training started Fri Nov 11 15:36:37 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Fri Nov 11 15:36:37 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 27  seconds  train loss: 0.7022846053284229 validation loss: 0.7210658756061573
epoch 1 time used: 27  seconds  train loss: 0.6773282916922319 validation loss: 0.7368495425774684
epoch 2 time used: 27  seconds  train loss: 0.6646395641912946 validation loss: 0.7077811756240788
epoch 3 time used: 27  seconds  train loss: 0.6557221599188163 validation loss: 0.8092575862039975
epoch 4 time used: 27  seconds  train loss: 0.6463193556831707 validation loss: 0.6969572050654473
epoch 5 time used: 27  seconds  train loss: 0.6407667620592402 validation loss: 0.6782464465098594
epoch 6 time used: 27  seconds  train loss: 0.637686798531843 validation loss: 0.6794945054979467
epoch 7 time used: 27  seconds  train loss: 0.633703596222282 validation loss: 0.6691407263278961
epoch 8 time used: 27  seconds  train loss: 0.6313586115497952 validation loss: 0.6694367698472531
epoch 9 time used: 27  seconds  train loss: 0.6280957206892933 validation loss: 0.6701978851313615
epoch 10 time used: 27  seconds  train loss: 0.6264658847540235 validation loss: 0.6624749059700847
epoch 11 time used: 27  seconds  train loss: 0.6207001996074258 validation loss: 0.67094427791994
epoch 12 time used: 28  seconds  train loss: 0.6190959190576208 validation loss: 0.6517544717931035
epoch 13 time used: 27  seconds  train loss: 0.617849258660931 validation loss: 0.6525759014917251
epoch 14 time used: 27  seconds  train loss: 0.6167866821648555 validation loss: 0.6586627456086191
epoch 15 time used: 27  seconds  train loss: 0.6146619319915771 validation loss: 0.6683077085670547
epoch 16 time used: 27  seconds  train loss: 0.61282762681607 validation loss: 0.6485528180848307
epoch 17 time used: 27  seconds  train loss: 0.6094082905082919 validation loss: 0.653150720234534
epoch 18 time used: 27  seconds  train loss: 0.608249414526721 validation loss: 0.6516501111770744
epoch 19 time used: 27  seconds  train loss: 0.6051136134020125 validation loss: 0.655991297752703
epoch 20 time used: 27  seconds  train loss: 0.6057836536323363 validation loss: 0.6525447066150495
epoch 21 time used: 27  seconds  train loss: 0.602247866212389 validation loss: 0.6788304311719107
epoch 22 time used: 27  seconds  train loss: 0.6023284574151887 validation loss: 0.6461274798829757
epoch 23 time used: 27  seconds  train loss: 0.5999348311980452 validation loss: 0.6481914241515582
epoch 24 time used: 27  seconds  train loss: 0.5964884721537572 validation loss: 0.637476649746966
epoch 25 time used: 27  seconds  train loss: 0.5954358017715926 validation loss: 0.6483305203380869
epoch 26 time used: 27  seconds  train loss: 0.5929626776687112 validation loss: 0.6424585512621486
epoch 27 time used: 27  seconds  train loss: 0.5928604937718909 validation loss: 0.6373167361193035
epoch 28 time used: 27  seconds  train loss: 0.5893375432253901 validation loss: 0.6435170431635273
epoch 29 time used: 27  seconds  train loss: 0.5876115332456944 validation loss: 0.6341009027329251
epoch 30 time used: 27  seconds  train loss: 0.5873977084078457 validation loss: 0.6509771136502128
epoch 31 time used: 27  seconds  train loss: 0.5856538838037895 validation loss: 0.6485491647056086
epoch 32 time used: 27  seconds  train loss: 0.5861061297643235 validation loss: 0.6385733895930484
epoch 33 time used: 27  seconds  train loss: 0.5821972684365079 validation loss: 0.627649026427103
epoch 34 time used: 27  seconds  train loss: 0.5816490612023246 validation loss: 0.6431781108403087
epoch 35 time used: 27  seconds  train loss: 0.580302092547437 validation loss: 0.6336123436244566
epoch 36 time used: 27  seconds  train loss: 0.5801494533612074 validation loss: 0.6296207462970297
epoch 37 time used: 27  seconds  train loss: 0.5778574730729311 validation loss: 0.6509408854429994
epoch 38 time used: 27  seconds  train loss: 0.577613765111519 validation loss: 0.6473334606607162
epoch 39 time used: 27  seconds  train loss: 0.5761677033531547 validation loss: 0.629488634825939
epoch 40 time used: 27  seconds  train loss: 0.5737751699443562 validation loss: 0.6301775272212812
epoch 41 time used: 27  seconds  train loss: 0.5728076624327669 validation loss: 0.6255793955492143
epoch 42 time used: 27  seconds  train loss: 0.5724055681425342 validation loss: 0.6223777233071588
epoch 43 time used: 27  seconds  train loss: 0.5717204526851052 validation loss: 0.6441816491867179
epoch 44 time used: 27  seconds  train loss: 0.5714328292423427 validation loss: 0.6342734095469043
epoch 45 time used: 27  seconds  train loss: 0.5697557743039952 validation loss: 0.6214777812435852
epoch 46 time used: 27  seconds  train loss: 0.5684065243088843 validation loss: 0.6369363297870503
epoch 47 time used: 27  seconds  train loss: 0.5671842272047637 validation loss: 0.6312309924642838
epoch 48 time used: 27  seconds  train loss: 0.565591549042448 validation loss: 0.6402795282169361
epoch 49 time used: 27  seconds  train loss: 0.5665648159058301 validation loss: 0.6280319290374642
epoch 50 time used: 27  seconds  train loss: 0.5639461262806041 validation loss: 0.62248310906377
epoch 51 time used: 27  seconds  train loss: 0.5639719098255271 validation loss: 0.6477476835843936
epoch 52 time used: 27  seconds  train loss: 0.5629471989817504 validation loss: 0.6274959338245107
epoch 53 time used: 27  seconds  train loss: 0.56290173937552 validation loss: 0.6441558338516388
epoch 54 time used: 27  seconds  train loss: 0.5609380144991543 validation loss: 0.6324682366195603
Early stopping at epoch: 55
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 5.6275538030e-01, 0.5627553803
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 23.5515609510, 4.8529950496, 3.6736686443, 31.9078296423
Model Training Ended ... Fri Nov 11 16:02:59 2022
pred_SZTAXI_GraphWaveNet_2211111536 testing started Fri Nov 11 16:02:59 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Fri Nov 11 16:02:59 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 5.3206268972e-01, 0.5320626897
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.5785531801, 4.7516895080, 3.6430571346, 34.2415392399
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 18.2403363809, 4.2708706818, 3.3268673424, 31.8959772587
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 19.2176507303, 4.3837941022, 3.3967750085, 32.3927015066
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 20.1868685959, 4.4929799238, 3.4695244310, 32.9567521811
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.0469453324, 4.5876949912, 3.5367161388, 33.4913402796
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 21.7682787697, 4.6656488048, 3.5941602129, 33.9506268501
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.1781179204, 4.7093649169, 3.6281510947, 34.1692894697
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 22.8381050622, 4.7789230023, 3.6749187000, 34.5006078482
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 23.5038714183, 4.8480791473, 3.7181272057, 34.8080933094
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 24.3143495386, 4.9309582779, 3.7727233107, 35.2099686861
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.0565523305, 5.0056520385, 3.8209233560, 35.5182290077
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 25.8318932401, 5.0825085578, 3.8625881590, 35.8140587807
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 26.8164938759, 5.1784644322, 3.9191895463, 36.2198650837
Model Testing Ended ... Fri Nov 11 16:03:06 2022
