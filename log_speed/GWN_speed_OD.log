../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/OD_matrix.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302247 training started Mon May 30 22:47:52 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 22:47:52 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.850780704197809 validation loss: 0.9482615136388522
epoch 1 time used: 19  seconds  train loss: 0.8343481641066702 validation loss: 0.9585254595647403
epoch 2 time used: 19  seconds  train loss: 0.8283182388518647 validation loss: 0.9209644966457614
epoch 3 time used: 19  seconds  train loss: 0.8240157570133507 validation loss: 0.9190804169545719
epoch 4 time used: 19  seconds  train loss: 0.8204256297005699 validation loss: 0.9100707463957184
epoch 5 time used: 19  seconds  train loss: 0.8169326261639764 validation loss: 0.913182773993383
epoch 6 time used: 19  seconds  train loss: 0.8158585324056796 validation loss: 0.9243547121683756
epoch 7 time used: 19  seconds  train loss: 0.8136713472572533 validation loss: 0.9065971840080337
epoch 8 time used: 19  seconds  train loss: 0.8116433334723645 validation loss: 0.9144617443654075
epoch 9 time used: 19  seconds  train loss: 0.8109157956172189 validation loss: 0.9155400131472308
epoch 10 time used: 19  seconds  train loss: 0.8100172766241884 validation loss: 0.8999461587981799
epoch 11 time used: 19  seconds  train loss: 0.80719023951426 validation loss: 0.9291250171946056
epoch 12 time used: 19  seconds  train loss: 0.8068658316966311 validation loss: 0.914357945100585
epoch 13 time used: 19  seconds  train loss: 0.8049491182669128 validation loss: 0.8989892154190671
epoch 14 time used: 19  seconds  train loss: 0.8034787385765553 validation loss: 0.8993612696875387
epoch 15 time used: 19  seconds  train loss: 0.8026456908345392 validation loss: 0.9082056135680545
epoch 16 time used: 19  seconds  train loss: 0.8013967273923784 validation loss: 0.9058174953531863
epoch 17 time used: 19  seconds  train loss: 0.8001044765644697 validation loss: 0.9018977764827102
epoch 18 time used: 19  seconds  train loss: 0.7993976757841802 validation loss: 0.903347350768189
epoch 19 time used: 19  seconds  train loss: 0.7972843674134733 validation loss: 0.894424466054831
epoch 20 time used: 19  seconds  train loss: 0.7966162886253292 validation loss: 0.8935111918259616
epoch 21 time used: 19  seconds  train loss: 0.7947672604666665 validation loss: 0.8959028053639541
epoch 22 time used: 19  seconds  train loss: 0.7956464234660054 validation loss: 0.9005425652461265
epoch 23 time used: 19  seconds  train loss: 0.7939759377565018 validation loss: 0.9168477506186832
epoch 24 time used: 19  seconds  train loss: 0.7912968620128008 validation loss: 0.889950288765466
epoch 25 time used: 19  seconds  train loss: 0.7912329102139045 validation loss: 0.9041460233541271
epoch 26 time used: 19  seconds  train loss: 0.7907050441881671 validation loss: 0.8981157200253425
epoch 27 time used: 19  seconds  train loss: 0.7894957949053681 validation loss: 0.9016425333805939
epoch 28 time used: 19  seconds  train loss: 0.7880659517149837 validation loss: 0.8861499203378288
epoch 29 time used: 19  seconds  train loss: 0.7872046892707413 validation loss: 0.8978164928469492
epoch 30 time used: 19  seconds  train loss: 0.7858599591390846 validation loss: 0.9089143863364831
epoch 31 time used: 19  seconds  train loss: 0.7852550009066824 validation loss: 0.8898843950893155
epoch 32 time used: 19  seconds  train loss: 0.7846235782967862 validation loss: 0.89823137764907
epoch 33 time used: 19  seconds  train loss: 0.7836951532879392 validation loss: 0.9061099857240174
epoch 34 time used: 19  seconds  train loss: 0.7827352170076004 validation loss: 0.8992802574859923
epoch 35 time used: 19  seconds  train loss: 0.7816690783921211 validation loss: 0.8920957899805325
epoch 36 time used: 19  seconds  train loss: 0.7812376196998282 validation loss: 0.9071303606033325
epoch 37 time used: 19  seconds  train loss: 0.7804515515248772 validation loss: 0.8891968181477258
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.7883120443e-01, 0.7788312044
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.8892926416, 6.5489917271, 4.6127348140, 24.5707109571
Model Training Ended ... Mon May 30 23:01:02 2022
pred_SZTAXI_GraphWaveNet_2205302247 testing started Mon May 30 23:01:02 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 23:01:02 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1984668665e-01, 0.8198466867
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2170331624, 6.6495889469, 4.6847361268, 24.1145312786
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2452838743, 6.5761146488, 4.6010177254, 23.6497864127
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5001240203, 6.5954623811, 4.6207986171, 23.7865597010
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6628969887, 6.6077906284, 4.6383363935, 23.8317862153
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8440440477, 6.6214835232, 4.6543339521, 23.9248409867
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0015899051, 6.6333694232, 4.6676491140, 24.0223318338
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1651451953, 6.6456862095, 4.6809587719, 24.0651607513
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3157286427, 6.6570059819, 4.6952003102, 24.1864606738
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4871025367, 6.6698652563, 4.7039888950, 24.2875650525
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6200423016, 6.6798235232, 4.7179539964, 24.3534579873
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7833345984, 6.6920351612, 4.7335534400, 24.3834674358
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9192856341, 6.7021851388, 4.7438043416, 24.4368478656
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0598202038, 6.7126611864, 4.7592379648, 24.4460195303
Model Testing Ended ... Mon May 30 23:01:07 2022
