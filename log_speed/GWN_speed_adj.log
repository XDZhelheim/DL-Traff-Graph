../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_mx.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302220 training started Mon May 30 22:20:53 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 22:20:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8430376514940818 validation loss: 0.9492169428820634
epoch 1 time used: 19  seconds  train loss: 0.831965560509504 validation loss: 0.9531778767334288
epoch 2 time used: 19  seconds  train loss: 0.8285134570357809 validation loss: 0.9268797250529427
epoch 3 time used: 19  seconds  train loss: 0.8256195495342292 validation loss: 0.9327881804746182
epoch 4 time used: 19  seconds  train loss: 0.8218323676548845 validation loss: 0.9196034296235042
epoch 5 time used: 19  seconds  train loss: 0.8194167208705484 validation loss: 0.9340678032357894
epoch 6 time used: 19  seconds  train loss: 0.8175315179492467 validation loss: 0.9372888254882091
epoch 7 time used: 19  seconds  train loss: 0.8154966543782317 validation loss: 0.9316787912477902
epoch 8 time used: 19  seconds  train loss: 0.8130470382878994 validation loss: 0.9122323678500617
epoch 9 time used: 19  seconds  train loss: 0.8111679208058212 validation loss: 0.9265118852183594
epoch 10 time used: 19  seconds  train loss: 0.8098698373709091 validation loss: 0.9197943922299058
epoch 11 time used: 19  seconds  train loss: 0.8072576183682655 validation loss: 0.90921968547859
epoch 12 time used: 19  seconds  train loss: 0.8053397547299967 validation loss: 0.9319576244449141
epoch 13 time used: 19  seconds  train loss: 0.8034309673614556 validation loss: 0.911283023618347
epoch 14 time used: 19  seconds  train loss: 0.8022460395716672 validation loss: 0.9118488253052555
epoch 15 time used: 19  seconds  train loss: 0.8009910840398048 validation loss: 0.9168850011493436
epoch 16 time used: 19  seconds  train loss: 0.7993445162413639 validation loss: 0.9078213163276216
epoch 17 time used: 19  seconds  train loss: 0.7971998463314593 validation loss: 0.9016103619959817
epoch 18 time used: 19  seconds  train loss: 0.7969009418406154 validation loss: 0.9080567837354556
epoch 19 time used: 19  seconds  train loss: 0.7948369120127107 validation loss: 0.8994495201466689
epoch 20 time used: 19  seconds  train loss: 0.7946101991753829 validation loss: 0.9091822671059945
epoch 21 time used: 19  seconds  train loss: 0.7926427047079692 validation loss: 0.9046523075791734
epoch 22 time used: 19  seconds  train loss: 0.7923840175821296 validation loss: 0.904626741338132
epoch 23 time used: 19  seconds  train loss: 0.7904255473257638 validation loss: 0.9056151129713106
epoch 24 time used: 19  seconds  train loss: 0.7890621134600633 validation loss: 0.8973841690898534
epoch 25 time used: 19  seconds  train loss: 0.7877125722246183 validation loss: 0.9087949030434908
epoch 26 time used: 19  seconds  train loss: 0.78707963287576 validation loss: 0.9092085687675286
epoch 27 time used: 19  seconds  train loss: 0.7856338994940517 validation loss: 0.9082932887385734
epoch 28 time used: 19  seconds  train loss: 0.7844664075466172 validation loss: 0.8956696883362917
epoch 29 time used: 19  seconds  train loss: 0.7830014332259871 validation loss: 0.9012278371782445
epoch 30 time used: 19  seconds  train loss: 0.7823394346203268 validation loss: 0.9245701298784854
epoch 31 time used: 19  seconds  train loss: 0.781599304669273 validation loss: 0.9095438004133121
epoch 32 time used: 19  seconds  train loss: 0.781185103853261 validation loss: 0.9054184796205208
epoch 33 time used: 19  seconds  train loss: 0.7806869787647578 validation loss: 0.9063338708521714
epoch 34 time used: 19  seconds  train loss: 0.778689483914572 validation loss: 0.91223583707762
epoch 35 time used: 19  seconds  train loss: 0.7791396123416733 validation loss: 0.9288365324931358
epoch 36 time used: 19  seconds  train loss: 0.7774717197309686 validation loss: 0.9113817879216588
epoch 37 time used: 19  seconds  train loss: 0.7768481593382986 validation loss: 0.9031903263348252
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.7770302179e-01, 0.7777030218
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.7520100563, 6.5385021264, 4.5834577109, 24.4176656008
Model Training Ended ... Mon May 30 22:33:58 2022
pred_SZTAXI_GraphWaveNet_2205302220 testing started Mon May 30 22:33:58 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 22:33:58 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 9.6297278029e-01, 0.9629727803
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 51.8315449537, 7.1994128201, 5.1757262064, 27.6611477137
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3171964743, 6.7318048452, 4.7508381996, 24.7500702739
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.0604155507, 6.7867824152, 4.7934327368, 25.1160800457
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.7331153608, 6.8361623270, 4.8412440879, 25.5101233721
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 47.6240865386, 6.9010206882, 4.9058351206, 26.0175168514
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 48.0317096185, 6.9304912970, 4.9376199510, 26.1844754219
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 49.8356878333, 7.0594396260, 5.0558074999, 27.0697802305
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 51.1069585128, 7.1489131001, 5.1393074876, 27.5881052017
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 53.2121304020, 7.2946645161, 5.2723606019, 28.4407466650
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 55.1898714794, 7.4289885906, 5.3993319957, 29.1710585356
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 57.3930170063, 7.5758179101, 5.5342867754, 29.9461334944
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 59.4469523845, 7.7101849773, 5.6605974283, 30.6559920311
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 62.0273982831, 7.8757474746, 5.8180525918, 31.4834177494
Model Testing Ended ... Mon May 30 22:34:07 2022
