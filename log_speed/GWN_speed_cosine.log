../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/speed_cosine.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205312057 training started Tue May 31 20:57:41 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 20:57:41 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.843634788884886 validation loss: 0.9441083912825703
epoch 1 time used: 19  seconds  train loss: 0.8312273580861804 validation loss: 0.9434677931799818
epoch 2 time used: 19  seconds  train loss: 0.8259305703860428 validation loss: 0.9128155649004884
epoch 3 time used: 19  seconds  train loss: 0.8220214105262865 validation loss: 0.9186068432248053
epoch 4 time used: 19  seconds  train loss: 0.8177608669567243 validation loss: 0.9091158645663096
epoch 5 time used: 19  seconds  train loss: 0.8154115782014676 validation loss: 0.9077776762383494
epoch 6 time used: 19  seconds  train loss: 0.8145958627779487 validation loss: 0.9130833249780076
epoch 7 time used: 19  seconds  train loss: 0.8121623343458216 validation loss: 0.9130915931208217
epoch 8 time used: 19  seconds  train loss: 0.810702388944531 validation loss: 0.908733043208051
epoch 9 time used: 19  seconds  train loss: 0.8095938993212508 validation loss: 0.920046175890301
epoch 10 time used: 19  seconds  train loss: 0.8087729555614304 validation loss: 0.8995507463293883
epoch 11 time used: 19  seconds  train loss: 0.8063265792336607 validation loss: 0.9057282064091506
epoch 12 time used: 19  seconds  train loss: 0.8063591109909339 validation loss: 0.9062473293560654
epoch 13 time used: 19  seconds  train loss: 0.804980241133173 validation loss: 0.8962818301139186
epoch 14 time used: 19  seconds  train loss: 0.8039309195061327 validation loss: 0.8999482064104792
epoch 15 time used: 19  seconds  train loss: 0.8043218244868695 validation loss: 0.9011048475901285
epoch 16 time used: 19  seconds  train loss: 0.8026858311289574 validation loss: 0.9022992027932731
epoch 17 time used: 19  seconds  train loss: 0.8015874008705063 validation loss: 0.8937404200212279
epoch 18 time used: 19  seconds  train loss: 0.8015896927242089 validation loss: 0.9019679507212852
epoch 19 time used: 19  seconds  train loss: 0.8003452614394903 validation loss: 0.8932973359947773
epoch 20 time used: 19  seconds  train loss: 0.8000238423327124 validation loss: 0.8849299277239178
epoch 21 time used: 19  seconds  train loss: 0.7988313751064696 validation loss: 0.8900223777661869
epoch 22 time used: 19  seconds  train loss: 0.7987962354976117 validation loss: 0.892534969161399
epoch 23 time used: 19  seconds  train loss: 0.7984311639160384 validation loss: 0.896744464167315
epoch 24 time used: 19  seconds  train loss: 0.7974059692826414 validation loss: 0.8903772676762064
epoch 25 time used: 19  seconds  train loss: 0.7972154958149786 validation loss: 0.8965065049294808
epoch 26 time used: 19  seconds  train loss: 0.7967758678949066 validation loss: 0.9064456535809076
epoch 27 time used: 19  seconds  train loss: 0.7964867117733908 validation loss: 0.9041767093672681
epoch 28 time used: 19  seconds  train loss: 0.7950040029088938 validation loss: 0.889940787903705
epoch 29 time used: 19  seconds  train loss: 0.7948525462347278 validation loss: 0.8957876723204086
Early stopping at epoch: 30
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.9510430930e-01, 0.7951043093
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 43.6156139241, 6.6042118322, 4.6414488533, 24.9803796411
Model Training Ended ... Tue May 31 21:08:13 2022
pred_SZTAXI_GraphWaveNet_2205312057 testing started Tue May 31 21:08:13 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 21:08:13 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2729411482e-01, 0.8272941148
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5756226739, 6.6764977851, 4.7207350090, 24.2179170251
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5059921764, 6.5959072292, 4.6368445140, 23.8546594977
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7887625276, 6.6173078006, 4.6571676894, 24.0200832486
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9932408437, 6.6327400706, 4.6746375031, 24.0534543991
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2247184754, 6.6501668006, 4.6959126188, 24.1653457284
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4087437498, 6.6639885767, 4.7073236515, 24.2001727223
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5581200779, 6.6751868946, 4.7151854368, 24.2506787181
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7000742859, 6.6858114157, 4.7297472009, 24.2998600006
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8665250513, 6.6982479091, 4.7437424951, 24.3130862713
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0020477654, 6.7083565622, 4.7543684397, 24.3094921112
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1447875078, 6.7189870894, 4.7649523984, 24.3358939886
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.2987752169, 6.7304364804, 4.7807169750, 24.3704512715
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.4156844083, 6.7391159961, 4.7882211852, 24.4416162372
Model Testing Ended ... Tue May 31 21:08:18 2022
