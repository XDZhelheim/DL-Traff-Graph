../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_10.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310145 training started Tue May 31 01:45:12 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:45:13 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8454388460597476 validation loss: 0.9500120065698576
epoch 1 time used: 19  seconds  train loss: 0.8312340743341622 validation loss: 0.9528735579542853
epoch 2 time used: 19  seconds  train loss: 0.8266085659287563 validation loss: 0.9295965356020192
epoch 3 time used: 19  seconds  train loss: 0.8226562511191768 validation loss: 0.9232237949893249
epoch 4 time used: 19  seconds  train loss: 0.818767159626121 validation loss: 0.913989210603249
epoch 5 time used: 19  seconds  train loss: 0.8165934902336316 validation loss: 0.9483973665616998
epoch 6 time used: 19  seconds  train loss: 0.8159665472137809 validation loss: 0.9266901244571553
epoch 7 time used: 19  seconds  train loss: 0.8139474114686632 validation loss: 0.9234460731643942
epoch 8 time used: 19  seconds  train loss: 0.8122954962094172 validation loss: 0.9141644372868893
epoch 9 time used: 19  seconds  train loss: 0.8112439852350976 validation loss: 0.920563328918533
epoch 10 time used: 19  seconds  train loss: 0.810471795785478 validation loss: 0.9112740333993636
epoch 11 time used: 19  seconds  train loss: 0.8083113488737245 validation loss: 0.9183356287467539
epoch 12 time used: 19  seconds  train loss: 0.8082341810378377 validation loss: 0.9152044247632003
epoch 13 time used: 19  seconds  train loss: 0.8065638044480749 validation loss: 0.9081017114036712
epoch 14 time used: 19  seconds  train loss: 0.8056063655430019 validation loss: 0.9054383724483092
epoch 15 time used: 19  seconds  train loss: 0.8057589061229701 validation loss: 0.9095383289441541
epoch 16 time used: 19  seconds  train loss: 0.804043422467678 validation loss: 0.9109225551880414
epoch 17 time used: 19  seconds  train loss: 0.8026150877920017 validation loss: 0.9108246381009989
epoch 18 time used: 19  seconds  train loss: 0.8019735937776471 validation loss: 0.905143456376014
epoch 19 time used: 19  seconds  train loss: 0.8004775221113799 validation loss: 0.9011963098796446
epoch 20 time used: 19  seconds  train loss: 0.7998946605841093 validation loss: 0.9040913403923831
epoch 21 time used: 19  seconds  train loss: 0.7986829202002177 validation loss: 0.8963784702974765
epoch 22 time used: 19  seconds  train loss: 0.7975753661918098 validation loss: 0.8977199864031663
epoch 23 time used: 19  seconds  train loss: 0.7966683278890965 validation loss: 0.9068520834196859
epoch 24 time used: 19  seconds  train loss: 0.7944330477273651 validation loss: 0.8949300483684635
epoch 25 time used: 19  seconds  train loss: 0.7930982465594795 validation loss: 0.9159123375641173
epoch 26 time used: 19  seconds  train loss: 0.7915865087068268 validation loss: 0.8974915653911989
epoch 27 time used: 19  seconds  train loss: 0.7900984885851995 validation loss: 0.9073658585548401
epoch 28 time used: 19  seconds  train loss: 0.7882200134427924 validation loss: 0.8838505819069212
epoch 29 time used: 19  seconds  train loss: 0.7855997069461925 validation loss: 0.909352016686207
epoch 30 time used: 19  seconds  train loss: 0.7835391747154518 validation loss: 0.9140255747742914
epoch 31 time used: 19  seconds  train loss: 0.7812858742806176 validation loss: 0.89305963089217
epoch 32 time used: 19  seconds  train loss: 0.7793199056242811 validation loss: 0.894614717853603
epoch 33 time used: 19  seconds  train loss: 0.7764672670900228 validation loss: 0.887507403964427
epoch 34 time used: 19  seconds  train loss: 0.7737967675474935 validation loss: 0.9044751943047367
epoch 35 time used: 19  seconds  train loss: 0.7730498635243216 validation loss: 0.9077658881595478
epoch 36 time used: 19  seconds  train loss: 0.7711190134498845 validation loss: 0.8976792758377037
epoch 37 time used: 19  seconds  train loss: 0.7690803131372118 validation loss: 0.8770063902015117
epoch 38 time used: 19  seconds  train loss: 0.7670176154688785 validation loss: 0.8778753230227759
epoch 39 time used: 19  seconds  train loss: 0.7654327033763251 validation loss: 0.8781359830305944
epoch 40 time used: 19  seconds  train loss: 0.7635185091966925 validation loss: 0.8800237929050009
epoch 41 time used: 19  seconds  train loss: 0.761710815121066 validation loss: 0.8823482506903843
epoch 42 time used: 19  seconds  train loss: 0.760107068215122 validation loss: 0.8941603735904788
epoch 43 time used: 19  seconds  train loss: 0.7606908946932633 validation loss: 0.8906001104644282
epoch 44 time used: 19  seconds  train loss: 0.759419888046015 validation loss: 0.8943143777586334
epoch 45 time used: 19  seconds  train loss: 0.757171571085158 validation loss: 0.8863250639901232
epoch 46 time used: 19  seconds  train loss: 0.7566288956368122 validation loss: 0.8785595962064183
Early stopping at epoch: 47
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5453580850e-01, 0.7545358085
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.5532651084, 6.4461822119, 4.5137082296, 24.1607606411
Model Training Ended ... Tue May 31 02:01:15 2022
pred_SZTAXI_GraphWaveNet_2205310145 testing started Tue May 31 02:01:15 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:01:15 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2456863194e-01, 0.8245686319
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4336673653, 6.6658583367, 4.7303248545, 23.7568870187
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2861597860, 6.5792218222, 4.6334076756, 23.4772667289
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5214802188, 6.5970811893, 4.6520782979, 23.5537961125
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7352269134, 6.6132614430, 4.6737350418, 23.6269384623
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9177336301, 6.6270456185, 4.6887250017, 23.6838728189
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1245357142, 6.6426301805, 4.7088251632, 23.7174808979
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3449550179, 6.6592007792, 4.7246870421, 23.7288445234
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5298815243, 6.6730713711, 4.7411111057, 23.7663090229
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7219219489, 6.6874450988, 4.7562511139, 23.8195493817
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9336134476, 6.7032539447, 4.7718005861, 23.8648563623
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1641946177, 6.7204311333, 4.7879663634, 23.8997220993
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3686090172, 6.7356223927, 4.8070833203, 23.9590078592
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.5556965475, 6.7494960217, 4.8182275425, 23.9848971367
Model Testing Ended ... Tue May 31 02:01:20 2022
