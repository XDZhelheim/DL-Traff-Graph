../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_11.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310201 training started Tue May 31 02:01:26 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:01:26 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8452381606122339 validation loss: 0.9492893782421131
epoch 1 time used: 19  seconds  train loss: 0.8311905509038466 validation loss: 0.9498249814284975
epoch 2 time used: 19  seconds  train loss: 0.8266369925115051 validation loss: 0.9278919601914895
epoch 3 time used: 19  seconds  train loss: 0.8225769908465498 validation loss: 0.9225446501774575
epoch 4 time used: 19  seconds  train loss: 0.818701750353763 validation loss: 0.9124309382035365
epoch 5 time used: 19  seconds  train loss: 0.8165280788416205 validation loss: 0.9404773715123609
epoch 6 time used: 19  seconds  train loss: 0.815790706983162 validation loss: 0.9270847807476177
epoch 7 time used: 19  seconds  train loss: 0.8138309350902292 validation loss: 0.9219381847784887
epoch 8 time used: 19  seconds  train loss: 0.8121927990174056 validation loss: 0.9123497688355138
epoch 9 time used: 19  seconds  train loss: 0.8112332465638477 validation loss: 0.9186798203643874
epoch 10 time used: 19  seconds  train loss: 0.8104739662254518 validation loss: 0.9069100476022977
epoch 11 time used: 19  seconds  train loss: 0.8083751685758404 validation loss: 0.9128324754202544
epoch 12 time used: 19  seconds  train loss: 0.8081282963115155 validation loss: 0.915355056672547
epoch 13 time used: 19  seconds  train loss: 0.8065559295129301 validation loss: 0.9066764602613686
epoch 14 time used: 19  seconds  train loss: 0.8052688426686554 validation loss: 0.9030287034475981
epoch 15 time used: 19  seconds  train loss: 0.805378780934753 validation loss: 0.9104657155364307
epoch 16 time used: 19  seconds  train loss: 0.8045019844856913 validation loss: 0.908035598287535
epoch 17 time used: 19  seconds  train loss: 0.8028632350700509 validation loss: 0.9091743986998031
epoch 18 time used: 19  seconds  train loss: 0.8027290320328594 validation loss: 0.9052629304762504
epoch 19 time used: 19  seconds  train loss: 0.8009887437732257 validation loss: 0.8972833550984587
epoch 20 time used: 19  seconds  train loss: 0.8003412879378154 validation loss: 0.9029754020681429
epoch 21 time used: 19  seconds  train loss: 0.7991068368276865 validation loss: 0.8983944965832269
epoch 22 time used: 19  seconds  train loss: 0.79838479616564 validation loss: 0.8976127724742415
epoch 23 time used: 19  seconds  train loss: 0.7974823455552797 validation loss: 0.9006471912659223
epoch 24 time used: 19  seconds  train loss: 0.7953441678884189 validation loss: 0.8889589953185314
epoch 25 time used: 19  seconds  train loss: 0.7942319361447949 validation loss: 0.9231089498866257
epoch 26 time used: 19  seconds  train loss: 0.7930705078465501 validation loss: 0.8969598878082351
epoch 27 time used: 19  seconds  train loss: 0.7916410281342768 validation loss: 0.9015021463531759
epoch 28 time used: 19  seconds  train loss: 0.7899613817928526 validation loss: 0.8877414278130034
epoch 29 time used: 19  seconds  train loss: 0.7872604279226463 validation loss: 0.9032119984057412
epoch 30 time used: 19  seconds  train loss: 0.7856110722716808 validation loss: 0.9058922816864887
epoch 31 time used: 19  seconds  train loss: 0.7832335689837698 validation loss: 0.8972330102280005
epoch 32 time used: 19  seconds  train loss: 0.7823880130841078 validation loss: 0.8871384414274301
epoch 33 time used: 19  seconds  train loss: 0.7793158609870487 validation loss: 0.8933035141199975
epoch 34 time used: 19  seconds  train loss: 0.7758922788869606 validation loss: 0.8921165258730229
epoch 35 time used: 19  seconds  train loss: 0.7748863946323205 validation loss: 0.8939058531576128
epoch 36 time used: 19  seconds  train loss: 0.7722310988526595 validation loss: 0.894554684411234
epoch 37 time used: 19  seconds  train loss: 0.7702720567986772 validation loss: 0.8824491586851243
epoch 38 time used: 19  seconds  train loss: 0.7677774311468577 validation loss: 0.8795833815982685
epoch 39 time used: 19  seconds  train loss: 0.7670083342710905 validation loss: 0.8836339507529984
epoch 40 time used: 19  seconds  train loss: 0.764206157554773 validation loss: 0.8877298627326737
epoch 41 time used: 19  seconds  train loss: 0.7625901730437028 validation loss: 0.880470349717496
epoch 42 time used: 19  seconds  train loss: 0.7607690814039955 validation loss: 0.8954337387535702
epoch 43 time used: 19  seconds  train loss: 0.7607163655469631 validation loss: 0.8921729836297866
epoch 44 time used: 19  seconds  train loss: 0.7592575094777863 validation loss: 0.9045826404248897
epoch 45 time used: 19  seconds  train loss: 0.7575040809799564 validation loss: 0.8897515994992422
epoch 46 time used: 19  seconds  train loss: 0.7572659256617681 validation loss: 0.8856616462048014
epoch 47 time used: 19  seconds  train loss: 0.756785035218148 validation loss: 0.8796184848790145
epoch 48 time used: 19  seconds  train loss: 0.7553933531597024 validation loss: 0.8770564732266896
epoch 49 time used: 19  seconds  train loss: 0.7540840293740481 validation loss: 0.8882035126733543
epoch 50 time used: 19  seconds  train loss: 0.7537719974477125 validation loss: 0.8829607290415028
epoch 51 time used: 19  seconds  train loss: 0.7521542476047662 validation loss: 0.8899194636748204
epoch 52 time used: 19  seconds  train loss: 0.7515531734246788 validation loss: 0.8843929542237846
epoch 53 time used: 19  seconds  train loss: 0.7506801670001207 validation loss: 0.8866806964376079
epoch 54 time used: 19  seconds  train loss: 0.750587040804867 validation loss: 0.892801207986044
epoch 55 time used: 19  seconds  train loss: 0.7511771325535999 validation loss: 0.885821366488044
epoch 56 time used: 19  seconds  train loss: 0.7491979047041359 validation loss: 0.8806505713296767
epoch 57 time used: 19  seconds  train loss: 0.7482106855210675 validation loss: 0.8840232091163521
Early stopping at epoch: 58
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.4655201340e-01, 0.7465520134
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.1932358765, 6.4181956870, 4.4835107821, 23.9706888795
Model Training Ended ... Tue May 31 02:21:09 2022
pred_SZTAXI_GraphWaveNet_2205310201 testing started Tue May 31 02:21:09 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:21:09 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1569024240e-01, 0.8156902424
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9612566805, 6.6303285500, 4.6749708038, 23.6018896103
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.0547945181, 6.5616152370, 4.5966413843, 23.3326956630
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2734182481, 6.5782534345, 4.6173152968, 23.4022930264
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.4372132009, 6.5906914054, 4.6358383554, 23.4605699778
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6207015197, 6.6045969990, 4.6514041459, 23.5066130757
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8146741874, 6.6192653813, 4.6671080329, 23.5233128071
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9451191261, 6.6291114884, 4.6767783699, 23.5642611980
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0574503104, 6.6375786482, 4.6838592641, 23.6268535256
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2289142018, 6.6504822533, 4.6944694992, 23.6522525549
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3288552899, 6.6579918361, 4.7019916996, 23.7456396222
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4806673741, 6.6693828331, 4.7131536622, 23.7455651164
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5953741585, 6.6779768013, 4.7245995955, 23.8103672862
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6978980315, 6.6856486620, 4.7364903393, 23.8519474864
Model Testing Ended ... Tue May 31 02:21:14 2022
