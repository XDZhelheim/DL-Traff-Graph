../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_12.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310221 training started Tue May 31 02:21:19 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:21:20 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8449474791035714 validation loss: 0.9499405853783907
epoch 1 time used: 19  seconds  train loss: 0.831212183150594 validation loss: 0.9419963774989494
epoch 2 time used: 19  seconds  train loss: 0.8264538932321421 validation loss: 0.9290307131572743
epoch 3 time used: 19  seconds  train loss: 0.8223744096661021 validation loss: 0.9213626411423754
epoch 4 time used: 19  seconds  train loss: 0.8185343314200683 validation loss: 0.9130297086725188
epoch 5 time used: 19  seconds  train loss: 0.816036921307169 validation loss: 0.9287283310842751
epoch 6 time used: 19  seconds  train loss: 0.815689177889573 validation loss: 0.922729840919153
epoch 7 time used: 19  seconds  train loss: 0.8134785232638906 validation loss: 0.9230745947776149
epoch 8 time used: 19  seconds  train loss: 0.8120992829755563 validation loss: 0.9144200709328723
epoch 9 time used: 19  seconds  train loss: 0.811110725189171 validation loss: 0.9164999928047408
epoch 10 time used: 19  seconds  train loss: 0.8102269034467076 validation loss: 0.9072271460917458
epoch 11 time used: 19  seconds  train loss: 0.8083453448025634 validation loss: 0.9121644929866886
epoch 12 time used: 19  seconds  train loss: 0.8080719503366083 validation loss: 0.9182458659309652
epoch 13 time used: 19  seconds  train loss: 0.8068192672424263 validation loss: 0.9023832231018674
epoch 14 time used: 19  seconds  train loss: 0.8056119076727464 validation loss: 0.9035502004979262
epoch 15 time used: 19  seconds  train loss: 0.8055500744247165 validation loss: 0.9084294773452911
epoch 16 time used: 19  seconds  train loss: 0.8046104493385359 validation loss: 0.9055571372236185
epoch 17 time used: 19  seconds  train loss: 0.8032737229321454 validation loss: 0.9019777656194583
epoch 18 time used: 19  seconds  train loss: 0.8030275251414325 validation loss: 0.9063631738003214
epoch 19 time used: 19  seconds  train loss: 0.8014970268328193 validation loss: 0.897312238441771
epoch 20 time used: 19  seconds  train loss: 0.8008587748702526 validation loss: 0.9026492691751736
epoch 21 time used: 19  seconds  train loss: 0.7996824980629966 validation loss: 0.8974072663345147
epoch 22 time used: 19  seconds  train loss: 0.7993499640889392 validation loss: 0.8974438202914907
epoch 23 time used: 19  seconds  train loss: 0.7983356675247041 validation loss: 0.90232717279178
epoch 24 time used: 19  seconds  train loss: 0.7965918201979668 validation loss: 0.8878334505641046
epoch 25 time used: 19  seconds  train loss: 0.7958518040298906 validation loss: 0.9157929613222531
epoch 26 time used: 19  seconds  train loss: 0.794997884911799 validation loss: 0.9004335563574264
epoch 27 time used: 19  seconds  train loss: 0.793408251503962 validation loss: 0.8991477824562225
epoch 28 time used: 19  seconds  train loss: 0.7917708400133494 validation loss: 0.8865488310951498
epoch 29 time used: 19  seconds  train loss: 0.7898456728984079 validation loss: 0.89649074646964
epoch 30 time used: 19  seconds  train loss: 0.7884523208924751 validation loss: 0.9039258227419498
epoch 31 time used: 19  seconds  train loss: 0.7864577489591086 validation loss: 0.8968672613006327
epoch 32 time used: 19  seconds  train loss: 0.7857462763786316 validation loss: 0.8882279182547954
epoch 33 time used: 19  seconds  train loss: 0.7835032343016579 validation loss: 0.8946840505101787
epoch 34 time used: 19  seconds  train loss: 0.7808680495361177 validation loss: 0.9015034407525513
epoch 35 time used: 19  seconds  train loss: 0.779671674093515 validation loss: 0.8834665554079844
epoch 36 time used: 19  seconds  train loss: 0.776843443449327 validation loss: 0.8949093163309999
epoch 37 time used: 19  seconds  train loss: 0.7758588210108609 validation loss: 0.8821626163240689
epoch 38 time used: 19  seconds  train loss: 0.7735791064767037 validation loss: 0.8869995080416475
epoch 39 time used: 19  seconds  train loss: 0.7723659010733853 validation loss: 0.8845404715680364
epoch 40 time used: 19  seconds  train loss: 0.7692456390406635 validation loss: 0.8861862106702814
epoch 41 time used: 19  seconds  train loss: 0.7674405033015256 validation loss: 0.8793871456117772
epoch 42 time used: 19  seconds  train loss: 0.7652533063678281 validation loss: 0.8888133331317807
epoch 43 time used: 19  seconds  train loss: 0.7653202327182927 validation loss: 0.8937629482046289
epoch 44 time used: 19  seconds  train loss: 0.7630082708843063 validation loss: 0.8920273635517898
epoch 45 time used: 19  seconds  train loss: 0.7613186649713204 validation loss: 0.8888153232152189
epoch 46 time used: 19  seconds  train loss: 0.7607429947486812 validation loss: 0.8842573699666493
epoch 47 time used: 19  seconds  train loss: 0.7598809050462324 validation loss: 0.8808711681199904
epoch 48 time used: 19  seconds  train loss: 0.7585319954674071 validation loss: 0.8798587102795121
epoch 49 time used: 19  seconds  train loss: 0.7567920884061843 validation loss: 0.884419224748564
epoch 50 time used: 19  seconds  train loss: 0.7568023112386593 validation loss: 0.8831714459912694
Early stopping at epoch: 51
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5441693310e-01, 0.7544169331
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.5769695601, 6.4480205924, 4.5248387586, 24.2179825902
Model Training Ended ... Tue May 31 02:38:43 2022
pred_SZTAXI_GraphWaveNet_2205310221 testing started Tue May 31 02:38:43 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:38:43 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2385351848e-01, 0.8238535185
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3683718342, 6.6609587774, 4.7123606465, 23.9269524813
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.1908483393, 6.5719744628, 4.6137737072, 23.6617282033
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.4896757180, 6.5946702509, 4.6432254610, 23.7144097686
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7123074516, 6.6115283749, 4.6606852326, 23.7955436110
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9456804287, 6.6291538245, 4.6808660361, 23.8524883986
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1663949989, 6.6457802400, 4.6974926531, 23.8555461168
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3374846971, 6.6586398534, 4.7072549736, 23.9488363266
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5944960113, 6.6779110515, 4.7318280159, 23.9422902465
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7151996846, 6.6869424765, 4.7364483756, 23.9872172475
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8583159541, 6.6976351016, 4.7500722571, 24.0305364132
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0206793307, 6.7097451018, 4.7654339103, 24.0742549300
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1447407570, 6.7189836104, 4.7745478336, 24.0940898657
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.2446386396, 6.7264135049, 4.7866993013, 24.1663366556
Model Testing Ended ... Tue May 31 02:38:48 2022
