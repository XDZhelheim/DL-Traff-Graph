../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_13.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310238 training started Tue May 31 02:38:55 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:38:55 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8447999194539967 validation loss: 0.9490533735028547
epoch 1 time used: 19  seconds  train loss: 0.8311540453905402 validation loss: 0.9426143264296043
epoch 2 time used: 19  seconds  train loss: 0.826357660727684 validation loss: 0.9331576515786091
epoch 3 time used: 19  seconds  train loss: 0.8223557969075688 validation loss: 0.923443665551902
epoch 4 time used: 19  seconds  train loss: 0.8185550582358033 validation loss: 0.9122521073664006
epoch 5 time used: 19  seconds  train loss: 0.8160835893700167 validation loss: 0.9208791671107658
epoch 6 time used: 19  seconds  train loss: 0.8156650983761587 validation loss: 0.9246645830756989
epoch 7 time used: 19  seconds  train loss: 0.8134682301437194 validation loss: 0.9223094505457142
epoch 8 time used: 19  seconds  train loss: 0.8121056704229515 validation loss: 0.9188958756366179
epoch 9 time used: 19  seconds  train loss: 0.8112760294721612 validation loss: 0.9176181181153255
epoch 10 time used: 19  seconds  train loss: 0.8104116116275489 validation loss: 0.906926740461321
epoch 11 time used: 19  seconds  train loss: 0.8083185914739606 validation loss: 0.9119360532926682
epoch 12 time used: 19  seconds  train loss: 0.8082119300219616 validation loss: 0.9172362717823009
epoch 13 time used: 19  seconds  train loss: 0.8068157742237129 validation loss: 0.9016969936404062
epoch 14 time used: 19  seconds  train loss: 0.8057238868256212 validation loss: 0.9044600526491801
epoch 15 time used: 19  seconds  train loss: 0.805399107220841 validation loss: 0.908151765367878
epoch 16 time used: 19  seconds  train loss: 0.8046280519551946 validation loss: 0.9063717200981444
epoch 17 time used: 19  seconds  train loss: 0.8032387082980333 validation loss: 0.89805535475413
epoch 18 time used: 19  seconds  train loss: 0.8029752198188098 validation loss: 0.9048785917201445
epoch 19 time used: 19  seconds  train loss: 0.8013862397728401 validation loss: 0.8956274941786012
epoch 20 time used: 19  seconds  train loss: 0.8007690324891852 validation loss: 0.8980292906215535
epoch 21 time used: 19  seconds  train loss: 0.7991939820402207 validation loss: 0.893664921101053
epoch 22 time used: 19  seconds  train loss: 0.7990576720678619 validation loss: 0.8961715982921088
epoch 23 time used: 19  seconds  train loss: 0.7976075989932119 validation loss: 0.9016694512533311
epoch 24 time used: 19  seconds  train loss: 0.7958659895962027 validation loss: 0.8892800733817751
epoch 25 time used: 19  seconds  train loss: 0.7945682525973911 validation loss: 0.9167700584848129
epoch 26 time used: 19  seconds  train loss: 0.7938516790293698 validation loss: 0.9018950079804036
epoch 27 time used: 19  seconds  train loss: 0.7920369401595332 validation loss: 0.9038077406029204
epoch 28 time used: 19  seconds  train loss: 0.7905632007342484 validation loss: 0.8866865341343096
epoch 29 time used: 19  seconds  train loss: 0.7882518978580133 validation loss: 0.8956204246525741
epoch 30 time used: 19  seconds  train loss: 0.7865353668397386 validation loss: 0.913119926974548
epoch 31 time used: 19  seconds  train loss: 0.784684220469354 validation loss: 0.896401234823673
epoch 32 time used: 19  seconds  train loss: 0.7836613156547926 validation loss: 0.8841474554431972
epoch 33 time used: 19  seconds  train loss: 0.7805663245500915 validation loss: 0.8930565385676142
epoch 34 time used: 19  seconds  train loss: 0.7779577774648816 validation loss: 0.889203820655595
epoch 35 time used: 19  seconds  train loss: 0.7769233172343432 validation loss: 0.8809376379743737
epoch 36 time used: 19  seconds  train loss: 0.7740254476772434 validation loss: 0.9072400328531787
epoch 37 time used: 19  seconds  train loss: 0.7723194443823433 validation loss: 0.883762400245192
epoch 38 time used: 19  seconds  train loss: 0.7703594845185748 validation loss: 0.8808999847416854
epoch 39 time used: 19  seconds  train loss: 0.7690933484949734 validation loss: 0.8765768743866119
epoch 40 time used: 19  seconds  train loss: 0.7664089034156474 validation loss: 0.8801595820716365
epoch 41 time used: 19  seconds  train loss: 0.7648953499529474 validation loss: 0.8838561286973716
epoch 42 time used: 19  seconds  train loss: 0.762735706135355 validation loss: 0.8875588979294051
epoch 43 time used: 19  seconds  train loss: 0.7629927295878806 validation loss: 0.8905229538827393
epoch 44 time used: 19  seconds  train loss: 0.7611988971107885 validation loss: 0.88790978602509
epoch 45 time used: 19  seconds  train loss: 0.7591716458922938 validation loss: 0.8883534349612335
epoch 46 time used: 19  seconds  train loss: 0.758838251678228 validation loss: 0.8809486701713866
epoch 47 time used: 19  seconds  train loss: 0.7582525657556135 validation loss: 0.8828757523897275
epoch 48 time used: 19  seconds  train loss: 0.7568635881201471 validation loss: 0.8829875618071106
Early stopping at epoch: 49
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5134637176e-01, 0.7513463718
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.4092257311, 6.4350000568, 4.5007634718, 24.0388765931
Model Training Ended ... Tue May 31 02:55:38 2022
pred_SZTAXI_GraphWaveNet_2205310238 testing started Tue May 31 02:55:38 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 02:55:38 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1719342644e-01, 0.8171934264
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0640298262, 6.6380742559, 4.6900356652, 23.7727835774
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.1660873071, 6.5700903576, 4.6113507259, 23.5552906990
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.3686829689, 6.5854903363, 4.6307261280, 23.5821545124
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5301561691, 6.5977387163, 4.6424870306, 23.5715419054
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6674308435, 6.6081336884, 4.6571230220, 23.6825808883
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8172625630, 6.6194608967, 4.6711038374, 23.7635478377
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9775326946, 6.6315558276, 4.6851604623, 23.7446859479
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0986125339, 6.6406786200, 4.6942876139, 23.8170638680
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2587927273, 6.6527282168, 4.7095904725, 23.8380864263
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4397057739, 6.6663112569, 4.7245299417, 23.8810613751
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6322725271, 6.6807389207, 4.7394333899, 23.9196598530
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8331339055, 6.6957549168, 4.7548468862, 23.9294975996
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9786879011, 6.7066152343, 4.7597884722, 23.9883452654
Model Testing Ended ... Tue May 31 02:55:43 2022
