../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_14.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310255 training started Tue May 31 02:55:49 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 02:55:49 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8446766196579207 validation loss: 0.9492785645954644
epoch 1 time used: 19  seconds  train loss: 0.8310665718013498 validation loss: 0.9427271013829246
epoch 2 time used: 19  seconds  train loss: 0.8262076397369461 validation loss: 0.9254985116607514
epoch 3 time used: 19  seconds  train loss: 0.8221724724362619 validation loss: 0.9233345828246121
epoch 4 time used: 19  seconds  train loss: 0.8183766397439569 validation loss: 0.9113269792267339
epoch 5 time used: 19  seconds  train loss: 0.8159035381517912 validation loss: 0.9157018228549862
epoch 6 time used: 19  seconds  train loss: 0.815545481774071 validation loss: 0.9237270254400832
epoch 7 time used: 19  seconds  train loss: 0.8132668106179488 validation loss: 0.9223476405167461
epoch 8 time used: 19  seconds  train loss: 0.8119650826515209 validation loss: 0.9155709254207895
epoch 9 time used: 19  seconds  train loss: 0.8109697734309125 validation loss: 0.9170136608887668
epoch 10 time used: 19  seconds  train loss: 0.8101947072729108 validation loss: 0.904208792975886
epoch 11 time used: 19  seconds  train loss: 0.8080081994808246 validation loss: 0.9126605388536975
epoch 12 time used: 19  seconds  train loss: 0.8079772466107419 validation loss: 0.9102922322145149
epoch 13 time used: 19  seconds  train loss: 0.8065882977177714 validation loss: 0.8976849519198213
epoch 14 time used: 19  seconds  train loss: 0.8054932718765345 validation loss: 0.9043881982120116
epoch 15 time used: 19  seconds  train loss: 0.8054290118800796 validation loss: 0.9069447582633934
epoch 16 time used: 19  seconds  train loss: 0.8042317642426253 validation loss: 0.9024488558223591
epoch 17 time used: 19  seconds  train loss: 0.8030302071808751 validation loss: 0.8983984399790788
epoch 18 time used: 19  seconds  train loss: 0.802759762254582 validation loss: 0.9040400356202576
epoch 19 time used: 19  seconds  train loss: 0.8013680747698245 validation loss: 0.8941281408219788
epoch 20 time used: 19  seconds  train loss: 0.8006537284484798 validation loss: 0.896789208276948
epoch 21 time used: 19  seconds  train loss: 0.7992990142420718 validation loss: 0.8927242723270435
epoch 22 time used: 19  seconds  train loss: 0.7990291211886562 validation loss: 0.893709820004838
epoch 23 time used: 19  seconds  train loss: 0.7976946955385114 validation loss: 0.900481989431144
epoch 24 time used: 19  seconds  train loss: 0.7963071204350989 validation loss: 0.8887876361163695
epoch 25 time used: 19  seconds  train loss: 0.7952820918977176 validation loss: 0.9080438261008381
epoch 26 time used: 19  seconds  train loss: 0.79479941865628 validation loss: 0.9019297091522027
epoch 27 time used: 19  seconds  train loss: 0.7933188013806621 validation loss: 0.9054245530669369
epoch 28 time used: 19  seconds  train loss: 0.791822781942647 validation loss: 0.8891968074722669
epoch 29 time used: 19  seconds  train loss: 0.7904075101802224 validation loss: 0.8950252352069267
epoch 30 time used: 19  seconds  train loss: 0.7893372905542637 validation loss: 0.9121289668391593
epoch 31 time used: 19  seconds  train loss: 0.7878272546982528 validation loss: 0.8934868081885191
epoch 32 time used: 19  seconds  train loss: 0.7870394347572055 validation loss: 0.8901398519971477
epoch 33 time used: 19  seconds  train loss: 0.7848847758549545 validation loss: 0.9153936084230148
Early stopping at epoch: 34
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.7984625169e-01, 0.7798462517
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.8218390286, 6.5438397771, 4.6061413670, 24.7109442949
Model Training Ended ... Tue May 31 03:07:37 2022
pred_SZTAXI_GraphWaveNet_2205310255 testing started Tue May 31 03:07:37 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 03:07:37 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.3045078128e-01, 0.8304507813
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7813687585, 6.6918882805, 4.7316641762, 24.0872740746
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5575303039, 6.5998128992, 4.6277901843, 23.7259671092
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8638604074, 6.6229797227, 4.6519525161, 23.7966239452
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0762186028, 6.6389922882, 4.6713667390, 23.8336995244
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3533368590, 6.6598300923, 4.6970414429, 23.8861545920
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5233941247, 6.6725852655, 4.7103653838, 24.0008696914
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7305354413, 6.6880890725, 4.7273140549, 24.0653619170
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9559455299, 6.7049195021, 4.7448389381, 24.1410672665
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1029061786, 6.7158697261, 4.7578207980, 24.2217749357
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.2730406158, 6.7285244011, 4.7756283389, 24.2821410298
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.4992304822, 6.7453117409, 4.7910347926, 24.2770925164
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.6518768467, 6.7566172636, 4.8052122400, 24.3991374969
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.7885497092, 6.7667237057, 4.8196046857, 24.4175806642
Model Testing Ended ... Tue May 31 03:07:42 2022
