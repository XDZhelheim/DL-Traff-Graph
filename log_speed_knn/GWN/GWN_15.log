../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_15.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310307 training started Tue May 31 03:07:47 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 03:07:48 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8445739492583241 validation loss: 0.9483145718550801
epoch 1 time used: 19  seconds  train loss: 0.8309158034209337 validation loss: 0.9410747046494365
epoch 2 time used: 19  seconds  train loss: 0.82615801374061 validation loss: 0.9234991210017038
epoch 3 time used: 19  seconds  train loss: 0.8220497596145185 validation loss: 0.9225655533188019
epoch 4 time used: 19  seconds  train loss: 0.8183741404186102 validation loss: 0.9102574889339617
epoch 5 time used: 19  seconds  train loss: 0.8156955114129936 validation loss: 0.9153857842013611
epoch 6 time used: 19  seconds  train loss: 0.8154395989130435 validation loss: 0.9223516948187529
epoch 7 time used: 19  seconds  train loss: 0.8131094429944012 validation loss: 0.9227558181653568
epoch 8 time used: 19  seconds  train loss: 0.8119712444830416 validation loss: 0.9165206830299909
epoch 9 time used: 19  seconds  train loss: 0.8109401199081714 validation loss: 0.9196187059084574
epoch 10 time used: 19  seconds  train loss: 0.8101148479863217 validation loss: 0.9060011093889303
epoch 11 time used: 19  seconds  train loss: 0.8080546224269894 validation loss: 0.9148725733828189
epoch 12 time used: 19  seconds  train loss: 0.8082626623924223 validation loss: 0.9115052863733092
epoch 13 time used: 19  seconds  train loss: 0.80648507451265 validation loss: 0.8981581875933936
epoch 14 time used: 19  seconds  train loss: 0.8054018168157737 validation loss: 0.9045054743539042
epoch 15 time used: 19  seconds  train loss: 0.8055326181489069 validation loss: 0.9062690527284917
epoch 16 time used: 19  seconds  train loss: 0.8044259024209013 validation loss: 0.902936040168971
epoch 17 time used: 19  seconds  train loss: 0.8031756633715135 validation loss: 0.8985296905930362
epoch 18 time used: 19  seconds  train loss: 0.8029783862413756 validation loss: 0.9040370123896433
epoch 19 time used: 19  seconds  train loss: 0.8016855280904648 validation loss: 0.8950891417650441
epoch 20 time used: 19  seconds  train loss: 0.801185469030486 validation loss: 0.8933141181124976
epoch 21 time used: 19  seconds  train loss: 0.7997620680593325 validation loss: 0.8923444789440478
epoch 22 time used: 19  seconds  train loss: 0.7994173062305532 validation loss: 0.8964300639000699
epoch 23 time used: 19  seconds  train loss: 0.7982893837125677 validation loss: 0.9021467195814522
epoch 24 time used: 19  seconds  train loss: 0.7970372240031257 validation loss: 0.8907868957045066
epoch 25 time used: 19  seconds  train loss: 0.7960087261871457 validation loss: 0.9052524750505514
epoch 26 time used: 19  seconds  train loss: 0.7956565394679649 validation loss: 0.9118186457833247
epoch 27 time used: 19  seconds  train loss: 0.7942518485898145 validation loss: 0.9121923019636923
epoch 28 time used: 19  seconds  train loss: 0.7930097406992362 validation loss: 0.8894161946737944
epoch 29 time used: 19  seconds  train loss: 0.7915906756904353 validation loss: 0.9004133337765784
epoch 30 time used: 19  seconds  train loss: 0.7906442187927865 validation loss: 0.9143771051767453
epoch 31 time used: 19  seconds  train loss: 0.7894945904336986 validation loss: 0.8946817594381115
epoch 32 time used: 19  seconds  train loss: 0.7883757905634504 validation loss: 0.8913534583143927
epoch 33 time used: 19  seconds  train loss: 0.7870752953872572 validation loss: 0.9065943837758914
epoch 34 time used: 19  seconds  train loss: 0.784910976717177 validation loss: 0.8977224731919777
epoch 35 time used: 19  seconds  train loss: 0.7839646738759145 validation loss: 0.8918009946002295
epoch 36 time used: 19  seconds  train loss: 0.781414668132706 validation loss: 0.907485689689864
epoch 37 time used: 19  seconds  train loss: 0.7804485448393679 validation loss: 0.8876122633616129
epoch 38 time used: 19  seconds  train loss: 0.7785317956299056 validation loss: 0.8904859474049279
epoch 39 time used: 19  seconds  train loss: 0.7771676630417619 validation loss: 0.8857526245401867
epoch 40 time used: 19  seconds  train loss: 0.7745771525085905 validation loss: 0.8866774122513349
epoch 41 time used: 19  seconds  train loss: 0.7721790412750895 validation loss: 0.8905592201954097
epoch 42 time used: 19  seconds  train loss: 0.7707188422785036 validation loss: 0.9016241718880573
epoch 43 time used: 19  seconds  train loss: 0.7699564497806609 validation loss: 0.8909818020033006
epoch 44 time used: 19  seconds  train loss: 0.767401703645291 validation loss: 0.8918273187988434
epoch 45 time used: 19  seconds  train loss: 0.765204130924952 validation loss: 0.9005766288558049
epoch 46 time used: 19  seconds  train loss: 0.7644528029314315 validation loss: 0.8855510822576077
epoch 47 time used: 19  seconds  train loss: 0.7634770081697793 validation loss: 0.8879801281056001
epoch 48 time used: 19  seconds  train loss: 0.7617133147855571 validation loss: 0.8855695427946784
epoch 49 time used: 19  seconds  train loss: 0.7597737977887964 validation loss: 0.8966461304408401
epoch 50 time used: 19  seconds  train loss: 0.7594441592608543 validation loss: 0.8870466680669072
epoch 51 time used: 19  seconds  train loss: 0.7579241133007522 validation loss: 0.8902142801095004
epoch 52 time used: 19  seconds  train loss: 0.7563300639772483 validation loss: 0.8847246217490429
epoch 53 time used: 19  seconds  train loss: 0.7556082229017363 validation loss: 0.8839008983094894
epoch 54 time used: 19  seconds  train loss: 0.7548158033134927 validation loss: 0.9095710189781379
epoch 55 time used: 19  seconds  train loss: 0.7557394875910339 validation loss: 0.8890810908369757
epoch 56 time used: 19  seconds  train loss: 0.7529049319868237 validation loss: 0.8820496311235191
epoch 57 time used: 19  seconds  train loss: 0.7514768704920372 validation loss: 0.8909511453476712
epoch 58 time used: 19  seconds  train loss: 0.751757560125625 validation loss: 0.884613958164234
epoch 59 time used: 19  seconds  train loss: 0.7512955273876488 validation loss: 0.8939906263825905
epoch 60 time used: 19  seconds  train loss: 0.7496169440946403 validation loss: 0.8832019689071238
epoch 61 time used: 19  seconds  train loss: 0.7504257338484523 validation loss: 0.8991830912395496
epoch 62 time used: 19  seconds  train loss: 0.7493027873432653 validation loss: 0.8966808399157737
epoch 63 time used: 19  seconds  train loss: 0.7490499282459785 validation loss: 0.8747374195957658
epoch 64 time used: 19  seconds  train loss: 0.7474289723005607 validation loss: 0.90340306183592
epoch 65 time used: 19  seconds  train loss: 0.7472297706949931 validation loss: 0.8884140519953486
epoch 66 time used: 19  seconds  train loss: 0.7465495305244478 validation loss: 0.8898658853265183
epoch 67 time used: 19  seconds  train loss: 0.7454217397640982 validation loss: 0.8968727683546531
epoch 68 time used: 19  seconds  train loss: 0.7453497180219735 validation loss: 0.8892637989414272
epoch 69 time used: 19  seconds  train loss: 0.745122835697185 validation loss: 0.9021476347055009
epoch 70 time used: 19  seconds  train loss: 0.7441594069068497 validation loss: 0.8910997293481779
epoch 71 time used: 19  seconds  train loss: 0.7433820080282338 validation loss: 0.8979507014526064
epoch 72 time used: 19  seconds  train loss: 0.7429632452948504 validation loss: 0.8961149759553558
Early stopping at epoch: 73
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.3936251395e-01, 0.7393625140
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 40.9441533734, 6.3987618625, 4.4794387659, 23.6571177840
Model Training Ended ... Tue May 31 03:32:21 2022
pred_SZTAXI_GraphWaveNet_2205310307 testing started Tue May 31 03:32:21 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 03:32:21 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1823647484e-01, 0.8182364748
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0804153155, 6.6393083462, 4.6680655941, 23.8917693496
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.1145726076, 6.5661687922, 4.5974610074, 23.5633507371
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.3721343293, 6.5857523738, 4.6131676899, 23.6816853285
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5644672425, 6.6003384188, 4.6302278517, 23.7050533295
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7325188922, 6.6130566981, 4.6439950856, 23.7686544657
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9100948509, 6.6264692598, 4.6581962225, 23.8244757056
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0462970886, 6.6367384376, 4.6624851194, 23.9313960075
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1899787521, 6.6475543437, 4.6743801511, 23.9434838295
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3595467795, 6.6602962982, 4.6860169198, 23.9915311337
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5088602438, 6.6714961024, 4.6974045081, 24.0415647626
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6283345758, 6.6804441900, 4.7092428351, 24.0512445569
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7414509258, 6.6889050618, 4.7186346108, 24.0728631616
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7967274976, 6.6930357460, 4.7255751285, 24.1256937385
Model Testing Ended ... Tue May 31 03:32:26 2022
