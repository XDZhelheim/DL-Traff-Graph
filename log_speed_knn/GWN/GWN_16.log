../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_16.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310332 training started Tue May 31 03:32:33 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 03:32:33 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8444897217058694 validation loss: 0.9470650995548685
epoch 1 time used: 19  seconds  train loss: 0.830827778043652 validation loss: 0.9399522821701581
epoch 2 time used: 19  seconds  train loss: 0.8261807531245572 validation loss: 0.9229578017002315
epoch 3 time used: 19  seconds  train loss: 0.8220062586525256 validation loss: 0.9191935142474388
epoch 4 time used: 19  seconds  train loss: 0.8183305201625417 validation loss: 0.9115878082626495
epoch 5 time used: 19  seconds  train loss: 0.8157864533481354 validation loss: 0.9153001255063868
epoch 6 time used: 19  seconds  train loss: 0.8154354521085324 validation loss: 0.9233628102202913
epoch 7 time used: 19  seconds  train loss: 0.8131524772935708 validation loss: 0.9211152602190995
epoch 8 time used: 19  seconds  train loss: 0.8119719436294154 validation loss: 0.9182073284144425
epoch 9 time used: 19  seconds  train loss: 0.8110970720797142 validation loss: 0.9200342819465334
epoch 10 time used: 19  seconds  train loss: 0.8101805107691888 validation loss: 0.9039562222969473
epoch 11 time used: 19  seconds  train loss: 0.808259880305354 validation loss: 0.9107620852503611
epoch 12 time used: 19  seconds  train loss: 0.8083556565756819 validation loss: 0.9102852469059959
epoch 13 time used: 19  seconds  train loss: 0.8066115156345991 validation loss: 0.8987557434324008
epoch 14 time used: 19  seconds  train loss: 0.8057435314312767 validation loss: 0.9063852853442899
epoch 15 time used: 19  seconds  train loss: 0.8058311611117204 validation loss: 0.9064137615374664
epoch 16 time used: 19  seconds  train loss: 0.8046818644359475 validation loss: 0.9018033114238758
epoch 17 time used: 19  seconds  train loss: 0.8036167955669875 validation loss: 0.8973389614873858
epoch 18 time used: 19  seconds  train loss: 0.8034229513422015 validation loss: 0.9054539657350796
epoch 19 time used: 19  seconds  train loss: 0.8021139936630282 validation loss: 0.8962907613213382
epoch 20 time used: 19  seconds  train loss: 0.8015356185934791 validation loss: 0.8943798628019456
epoch 21 time used: 19  seconds  train loss: 0.8001989926586449 validation loss: 0.893124138537924
epoch 22 time used: 19  seconds  train loss: 0.8001024305905251 validation loss: 0.8947318279328038
epoch 23 time used: 19  seconds  train loss: 0.7992465544391323 validation loss: 0.9005285623061716
epoch 24 time used: 19  seconds  train loss: 0.7980480883402981 validation loss: 0.8895853654069094
epoch 25 time used: 19  seconds  train loss: 0.7972120364563563 validation loss: 0.9075477144018335
epoch 26 time used: 19  seconds  train loss: 0.7968076381032192 validation loss: 0.9041131717055592
epoch 27 time used: 19  seconds  train loss: 0.7956931811477856 validation loss: 0.9033543256977897
epoch 28 time used: 19  seconds  train loss: 0.7944180304939682 validation loss: 0.8899182253216037
epoch 29 time used: 19  seconds  train loss: 0.7932838722957486 validation loss: 0.9069204128796782
epoch 30 time used: 19  seconds  train loss: 0.7922762055824356 validation loss: 0.9075707582692009
epoch 31 time used: 19  seconds  train loss: 0.79141150523046 validation loss: 0.8939957384446368
epoch 32 time used: 19  seconds  train loss: 0.7904766930285761 validation loss: 0.8917866364047302
epoch 33 time used: 19  seconds  train loss: 0.7891271609500327 validation loss: 0.9027680553014006
Early stopping at epoch: 34
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.8476734309e-01, 0.7847673431
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 43.1015363803, 6.5651760357, 4.6177738939, 24.8918518424
Model Training Ended ... Tue May 31 03:44:20 2022
pred_SZTAXI_GraphWaveNet_2205310332 testing started Tue May 31 03:44:20 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 03:44:20 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2956177748e-01, 0.8295617775
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7387825075, 6.6887055928, 4.7262315042, 24.1000428796
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5533796600, 6.5994984400, 4.6282462912, 23.7349137664
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8638360139, 6.6229778811, 4.6525168509, 23.8145172596
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0907689520, 6.6400880229, 4.6722783696, 23.8510832191
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3566365883, 6.6600778215, 4.6944126488, 23.8951295614
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5163568475, 6.6720579170, 4.7080658630, 24.0042120218
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7030318463, 6.6860325939, 4.7206244175, 24.0730255842
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8955738817, 6.7004159484, 4.7379359858, 24.1543576121
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0453868664, 6.7115860172, 4.7503598136, 24.2495372891
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.2028727352, 6.7233081690, 4.7660094959, 24.2985635996
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3932707879, 6.7374528412, 4.7807066524, 24.2889136076
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.5469168648, 6.7488455950, 4.7943362870, 24.4087517262
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.6973590453, 6.7599821779, 4.8092853750, 24.4276702404
Model Testing Ended ... Tue May 31 03:44:25 2022
