../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_18.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310356 training started Tue May 31 03:56:31 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 03:56:31 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8443777065188922 validation loss: 0.9467208604907515
epoch 1 time used: 19  seconds  train loss: 0.8307231682462679 validation loss: 0.9425515683729258
epoch 2 time used: 19  seconds  train loss: 0.8259823077264246 validation loss: 0.9226679807871728
epoch 3 time used: 19  seconds  train loss: 0.8220396520911715 validation loss: 0.9219760954083495
epoch 4 time used: 19  seconds  train loss: 0.8183222914149039 validation loss: 0.9085679163980247
epoch 5 time used: 19  seconds  train loss: 0.8158094763416653 validation loss: 0.9130240073844568
epoch 6 time used: 19  seconds  train loss: 0.8153366135329984 validation loss: 0.9222010827776211
epoch 7 time used: 19  seconds  train loss: 0.8130901555926837 validation loss: 0.921553206087938
epoch 8 time used: 19  seconds  train loss: 0.8118890321271688 validation loss: 0.9223578014777074
epoch 9 time used: 19  seconds  train loss: 0.8108667094541309 validation loss: 0.9185610828708061
epoch 10 time used: 19  seconds  train loss: 0.8101264169680784 validation loss: 0.904854959516383
epoch 11 time used: 19  seconds  train loss: 0.8081251666861272 validation loss: 0.9106816762122348
epoch 12 time used: 19  seconds  train loss: 0.8083298726068282 validation loss: 0.9090981341120022
epoch 13 time used: 19  seconds  train loss: 0.8064130430201208 validation loss: 0.8989007277275199
epoch 14 time used: 19  seconds  train loss: 0.8056695257786497 validation loss: 0.9058992729258182
epoch 15 time used: 19  seconds  train loss: 0.8058521996012453 validation loss: 0.9062919794623532
epoch 16 time used: 19  seconds  train loss: 0.8047076895260709 validation loss: 0.9042238931157696
epoch 17 time used: 19  seconds  train loss: 0.8040191819454156 validation loss: 0.8967130287962767
epoch 18 time used: 19  seconds  train loss: 0.8036076064469295 validation loss: 0.9050098624988575
epoch 19 time used: 19  seconds  train loss: 0.8023557852036922 validation loss: 0.8976010463724089
epoch 20 time used: 19  seconds  train loss: 0.8019691270750922 validation loss: 0.8937427988692895
epoch 21 time used: 19  seconds  train loss: 0.8007872381047538 validation loss: 0.895331077907809
epoch 22 time used: 19  seconds  train loss: 0.8004972076687331 validation loss: 0.8976894557772584
epoch 23 time used: 19  seconds  train loss: 0.7997851192018555 validation loss: 0.9006356573223475
epoch 24 time used: 19  seconds  train loss: 0.798767879796062 validation loss: 0.8910440784781727
epoch 25 time used: 19  seconds  train loss: 0.7979845581827937 validation loss: 0.9046938241417728
epoch 26 time used: 19  seconds  train loss: 0.7976573794698647 validation loss: 0.9055489654564739
epoch 27 time used: 19  seconds  train loss: 0.7967501007984915 validation loss: 0.9024353178579416
epoch 28 time used: 19  seconds  train loss: 0.7954767420146068 validation loss: 0.8904951469815192
epoch 29 time used: 19  seconds  train loss: 0.7947354090332476 validation loss: 0.9052297994865114
epoch 30 time used: 19  seconds  train loss: 0.7943356895175462 validation loss: 0.9041477524819066
epoch 31 time used: 19  seconds  train loss: 0.7931157388693917 validation loss: 0.8931315938631693
epoch 32 time used: 19  seconds  train loss: 0.7930219816110212 validation loss: 0.8906099529408696
epoch 33 time used: 19  seconds  train loss: 0.7910945800425827 validation loss: 0.8993605743000164
epoch 34 time used: 19  seconds  train loss: 0.7899381251287664 validation loss: 0.9044111777300858
epoch 35 time used: 19  seconds  train loss: 0.7893604355550253 validation loss: 0.8928568143749711
epoch 36 time used: 19  seconds  train loss: 0.7874142619997135 validation loss: 0.8998377195638211
epoch 37 time used: 19  seconds  train loss: 0.7868020520949601 validation loss: 0.898125388432498
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.8318428086e-01, 0.7831842809
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 43.0009529798, 6.5575111879, 4.6100280254, 24.5246678591
Model Training Ended ... Tue May 31 04:09:36 2022
pred_SZTAXI_GraphWaveNet_2205310356 testing started Tue May 31 04:09:36 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:09:36 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2770101363e-01, 0.8277010136
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6407773238, 6.6813754066, 4.7177243323, 23.9785015583
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5458587742, 6.5989286081, 4.6189088367, 23.5917791724
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7808477278, 6.6167097358, 4.6420128164, 23.7120449543
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0044068395, 6.6335817504, 4.6658759926, 23.7564176321
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2337375223, 6.6508448728, 4.6852125837, 23.8379105926
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4262033081, 6.6652984410, 4.7015502966, 23.9140540361
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6247608199, 6.6801767057, 4.7166881632, 23.9436432719
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7788356376, 6.6916990098, 4.7321372318, 24.0269780159
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9483593840, 6.7043537633, 4.7413966933, 24.1116300225
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1086022544, 6.7162937886, 4.7566417045, 24.1680443287
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.2666635456, 6.7280505011, 4.7725822890, 24.2075517774
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.4066846479, 6.7384482374, 4.7829701408, 24.2324471474
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.5643674240, 6.7501383263, 4.7967152386, 24.2393881083
Model Testing Ended ... Tue May 31 04:09:41 2022
