../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_19.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310409 training started Tue May 31 04:09:47 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 04:09:47 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8443725803498693 validation loss: 0.9460101109832081
epoch 1 time used: 19  seconds  train loss: 0.8306893184039196 validation loss: 0.9386373408398225
epoch 2 time used: 19  seconds  train loss: 0.8259915375438218 validation loss: 0.922484473209476
epoch 3 time used: 19  seconds  train loss: 0.82196225711326 validation loss: 0.9209209778415623
epoch 4 time used: 19  seconds  train loss: 0.8182118908948613 validation loss: 0.9088220261222687
epoch 5 time used: 19  seconds  train loss: 0.8156989536448189 validation loss: 0.9119383737222472
epoch 6 time used: 19  seconds  train loss: 0.8151602330452009 validation loss: 0.9212227947083279
epoch 7 time used: 19  seconds  train loss: 0.812866142939029 validation loss: 0.9209142804738895
epoch 8 time used: 19  seconds  train loss: 0.8116350385915504 validation loss: 0.9188001520598112
epoch 9 time used: 19  seconds  train loss: 0.8106934727510042 validation loss: 0.9182414605249813
epoch 10 time used: 19  seconds  train loss: 0.8098476512164174 validation loss: 0.9028394026542778
epoch 11 time used: 19  seconds  train loss: 0.8078535434870767 validation loss: 0.91024577469375
epoch 12 time used: 19  seconds  train loss: 0.8082368930067819 validation loss: 0.9084794610293944
epoch 13 time used: 19  seconds  train loss: 0.8063060905821462 validation loss: 0.8998294374836024
epoch 14 time used: 19  seconds  train loss: 0.8055880000208044 validation loss: 0.9057350247653563
epoch 15 time used: 19  seconds  train loss: 0.8056969019461153 validation loss: 0.9066718176229677
epoch 16 time used: 19  seconds  train loss: 0.8044795191304952 validation loss: 0.9014359324132625
epoch 17 time used: 19  seconds  train loss: 0.803932510517739 validation loss: 0.8980459274344184
epoch 18 time used: 19  seconds  train loss: 0.8032785708331113 validation loss: 0.9047040814784035
epoch 19 time used: 19  seconds  train loss: 0.8019967838846264 validation loss: 0.896476372557493
epoch 20 time used: 19  seconds  train loss: 0.8017509893367165 validation loss: 0.8937519868808006
epoch 21 time used: 19  seconds  train loss: 0.8004286075554057 validation loss: 0.894960336424225
epoch 22 time used: 19  seconds  train loss: 0.8002110996083549 validation loss: 0.8932295551347496
epoch 23 time used: 19  seconds  train loss: 0.7996433648581526 validation loss: 0.900376614053451
epoch 24 time used: 19  seconds  train loss: 0.7983256051075747 validation loss: 0.8917329504122189
epoch 25 time used: 19  seconds  train loss: 0.7977059853195635 validation loss: 0.9051989785474331
epoch 26 time used: 19  seconds  train loss: 0.7974219169589568 validation loss: 0.903010417869435
epoch 27 time used: 19  seconds  train loss: 0.7965217269162196 validation loss: 0.900795612465683
epoch 28 time used: 19  seconds  train loss: 0.7951999559341419 validation loss: 0.8900782062639645
epoch 29 time used: 19  seconds  train loss: 0.7940913341292956 validation loss: 0.9050710571939079
epoch 30 time used: 19  seconds  train loss: 0.7936010215733502 validation loss: 0.9095634589740886
epoch 31 time used: 19  seconds  train loss: 0.7927860530307927 validation loss: 0.8905543014777834
epoch 32 time used: 19  seconds  train loss: 0.7931673745512114 validation loss: 0.891388176092461
epoch 33 time used: 19  seconds  train loss: 0.7909785888951331 validation loss: 0.8973927622410789
epoch 34 time used: 19  seconds  train loss: 0.7894246235680614 validation loss: 0.8984786847337561
epoch 35 time used: 19  seconds  train loss: 0.7888267906766867 validation loss: 0.8910068724285903
epoch 36 time used: 19  seconds  train loss: 0.7868119975072392 validation loss: 0.9006625858705435
epoch 37 time used: 19  seconds  train loss: 0.786220553758982 validation loss: 0.8924358187623285
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.8678072415e-01, 0.7867807241
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 43.1700542181, 6.5703922423, 4.6247280847, 24.5018750429
Model Training Ended ... Tue May 31 04:22:53 2022
pred_SZTAXI_GraphWaveNet_2205310409 testing started Tue May 31 04:22:53 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:22:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2684036751e-01, 0.8268403675
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5901356851, 6.6775845697, 4.7124433204, 23.9917382598
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5472232504, 6.5990319934, 4.6176921411, 23.6001744866
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7720754515, 6.6160468145, 4.6374207885, 23.7341120839
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9878243849, 6.6323317457, 4.6622660564, 23.7639769912
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1998979906, 6.6483003836, 4.6790442055, 23.8457053900
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3809172931, 6.6619004265, 4.6961475128, 23.9193737507
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5682175555, 6.6759431959, 4.7076411923, 23.9575073123
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7172855006, 6.6870984366, 4.7244071972, 24.0420699120
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8761235115, 6.6989643611, 4.7365072507, 24.1212531924
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0170125883, 6.7094718561, 4.7488774532, 24.1858258843
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1817774765, 6.7217391705, 4.7677491849, 24.2334172130
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3309835234, 6.7328287906, 4.7777195338, 24.2443665862
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.5022896950, 6.7455385030, 4.7938473279, 24.2530211806
Model Testing Ended ... Tue May 31 04:22:58 2022
