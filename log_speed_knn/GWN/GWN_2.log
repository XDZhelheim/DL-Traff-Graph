../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_2.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302338 training started Mon May 30 23:38:39 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:38:39 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.853948345564168 validation loss: 0.970985089368488
epoch 1 time used: 19  seconds  train loss: 0.8447464054203982 validation loss: 0.962489659513407
epoch 2 time used: 19  seconds  train loss: 0.8425708797205224 validation loss: 0.9418442148474319
epoch 3 time used: 19  seconds  train loss: 0.8408633651129721 validation loss: 0.9493945315109557
epoch 4 time used: 19  seconds  train loss: 0.8379760149702069 validation loss: 0.938011884689331
epoch 5 time used: 19  seconds  train loss: 0.8373216895087175 validation loss: 0.9464482943810041
epoch 6 time used: 19  seconds  train loss: 0.8363130056162816 validation loss: 0.9510309957153168
epoch 7 time used: 19  seconds  train loss: 0.8348138193317701 validation loss: 0.9680242413905129
epoch 8 time used: 19  seconds  train loss: 0.8343235813028274 validation loss: 0.941397507392352
epoch 9 time used: 19  seconds  train loss: 0.8330350146015542 validation loss: 0.9445865688039295
epoch 10 time used: 19  seconds  train loss: 0.8325606772774145 validation loss: 0.9327046645814506
epoch 11 time used: 19  seconds  train loss: 0.8305778885803385 validation loss: 0.9351954575794846
epoch 12 time used: 19  seconds  train loss: 0.8297591933485116 validation loss: 0.955535666859565
epoch 13 time used: 19  seconds  train loss: 0.8283904864642223 validation loss: 0.9321368253646205
epoch 14 time used: 19  seconds  train loss: 0.8273541035387628 validation loss: 0.9405884991830854
epoch 15 time used: 19  seconds  train loss: 0.8265285090904996 validation loss: 0.9478426626072595
epoch 16 time used: 19  seconds  train loss: 0.8248037148166347 validation loss: 0.9426516706670695
epoch 17 time used: 19  seconds  train loss: 0.8232947108925321 validation loss: 0.9342607577048724
epoch 18 time used: 19  seconds  train loss: 0.8224088201990847 validation loss: 0.9462382470197346
epoch 19 time used: 19  seconds  train loss: 0.8208915235986072 validation loss: 0.9316889367886444
epoch 20 time used: 19  seconds  train loss: 0.8193275303623585 validation loss: 0.934991570551004
epoch 21 time used: 19  seconds  train loss: 0.8178297381312885 validation loss: 0.9398340686636778
epoch 22 time used: 19  seconds  train loss: 0.8178452561115302 validation loss: 0.9472120253007803
epoch 23 time used: 19  seconds  train loss: 0.8158827184104648 validation loss: 0.9484205213352223
epoch 24 time used: 19  seconds  train loss: 0.8143841504711514 validation loss: 0.9289183610707373
epoch 25 time used: 19  seconds  train loss: 0.812973331251999 validation loss: 0.9534719070391868
epoch 26 time used: 19  seconds  train loss: 0.8121839217407096 validation loss: 0.9452477311020466
epoch 27 time used: 19  seconds  train loss: 0.8108296374847336 validation loss: 0.938024285124309
epoch 28 time used: 19  seconds  train loss: 0.8093796440242534 validation loss: 0.9276898343171647
epoch 29 time used: 19  seconds  train loss: 0.8077854193630463 validation loss: 0.9312751862540174
epoch 30 time used: 19  seconds  train loss: 0.8068104999333323 validation loss: 0.9445276230721924
epoch 31 time used: 19  seconds  train loss: 0.8060316374766539 validation loss: 0.94309370790548
epoch 32 time used: 19  seconds  train loss: 0.8046458898533458 validation loss: 0.93933909864568
epoch 33 time used: 19  seconds  train loss: 0.8044057427395458 validation loss: 0.9389898708803737
epoch 34 time used: 19  seconds  train loss: 0.8023274189886633 validation loss: 0.9501680734738782
epoch 35 time used: 19  seconds  train loss: 0.8019641541145943 validation loss: 0.9412773141813515
epoch 36 time used: 19  seconds  train loss: 0.8010361455751855 validation loss: 0.9477502848971543
epoch 37 time used: 19  seconds  train loss: 0.7998654030973508 validation loss: 0.9421149993417275
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.9591304581e-01, 0.7959130458
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 43.7892393871, 6.6173438317, 4.6804641947, 24.8891040683
Model Training Ended ... Mon May 30 23:51:46 2022
pred_SZTAXI_GraphWaveNet_2205302338 testing started Mon May 30 23:51:46 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Mon May 30 23:51:46 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.4234257286e-01, 0.8423425729
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3694184527, 6.7356824786, 4.7646216662, 24.3055209517
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0730057726, 6.6387503171, 4.6550233803, 23.7254023552
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3637633797, 6.6606128381, 4.6800423153, 23.8662943244
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5967343140, 6.6780786394, 4.7046707662, 23.9357694983
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8912119108, 6.7000904405, 4.7269453945, 24.0433216095
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0875401171, 6.7147256174, 4.7430141033, 24.1846904159
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.3392522970, 6.7334428264, 4.7599713492, 24.2378488183
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.4989450676, 6.7452905844, 4.7774676382, 24.3682622910
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.7358223041, 6.7628265026, 4.7926240573, 24.5254009962
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.8899805045, 6.7742143828, 4.8093932692, 24.5870813727
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.1245128040, 6.7915029856, 4.8264922862, 24.6615797281
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.3210378991, 6.8059560606, 4.8418174272, 24.7476875782
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.5112150617, 6.8199131271, 4.8579980078, 24.7829407454
Model Testing Ended ... Mon May 30 23:51:51 2022
