../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_20.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310423 training started Tue May 31 04:23:05 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 04:23:05 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8443167019704327 validation loss: 0.9453129833610496
epoch 1 time used: 19  seconds  train loss: 0.8307106957835798 validation loss: 0.9390539927269096
epoch 2 time used: 19  seconds  train loss: 0.8260278062494856 validation loss: 0.9214990821050767
epoch 3 time used: 19  seconds  train loss: 0.8220376799659403 validation loss: 0.9220086988525011
epoch 4 time used: 19  seconds  train loss: 0.8181782969370336 validation loss: 0.9087700867534276
epoch 5 time used: 19  seconds  train loss: 0.8157196362869837 validation loss: 0.9108526247057749
epoch 6 time used: 19  seconds  train loss: 0.8152050636231815 validation loss: 0.9207928213314037
epoch 7 time used: 19  seconds  train loss: 0.8128699584841559 validation loss: 0.9197613238102168
epoch 8 time used: 19  seconds  train loss: 0.8115861203049868 validation loss: 0.9214001469944247
epoch 9 time used: 19  seconds  train loss: 0.8106515027720422 validation loss: 0.9179457292627933
epoch 10 time used: 19  seconds  train loss: 0.8098635019821937 validation loss: 0.9037019441376871
epoch 11 time used: 19  seconds  train loss: 0.8078249436862778 validation loss: 0.910262251671274
epoch 12 time used: 19  seconds  train loss: 0.8082014448612208 validation loss: 0.9088616341500733
epoch 13 time used: 19  seconds  train loss: 0.8064090663813596 validation loss: 0.9008740880596104
epoch 14 time used: 19  seconds  train loss: 0.8055673832574576 validation loss: 0.9062263591965632
epoch 15 time used: 19  seconds  train loss: 0.8056221910425134 validation loss: 0.9048507243246582
epoch 16 time used: 19  seconds  train loss: 0.8045527199084525 validation loss: 0.9040635062094352
epoch 17 time used: 19  seconds  train loss: 0.8039035800510586 validation loss: 0.8987636281483209
epoch 18 time used: 19  seconds  train loss: 0.8033588157269898 validation loss: 0.9066748939343353
epoch 19 time used: 19  seconds  train loss: 0.8021608178171291 validation loss: 0.89698988762661
epoch 20 time used: 19  seconds  train loss: 0.8018412289036118 validation loss: 0.8927208235607812
epoch 21 time used: 19  seconds  train loss: 0.8006064801094034 validation loss: 0.892284979867698
epoch 22 time used: 19  seconds  train loss: 0.8004396102506439 validation loss: 0.8944889938653405
epoch 23 time used: 19  seconds  train loss: 0.7997908764339952 validation loss: 0.901501086517353
epoch 24 time used: 19  seconds  train loss: 0.7988060185444643 validation loss: 0.8924860310791737
epoch 25 time used: 19  seconds  train loss: 0.7980806450246917 validation loss: 0.9077813450376786
epoch 26 time used: 19  seconds  train loss: 0.7978258944337772 validation loss: 0.9043461084365845
epoch 27 time used: 19  seconds  train loss: 0.7969740998015804 validation loss: 0.9020834203383222
epoch 28 time used: 19  seconds  train loss: 0.7953587659392214 validation loss: 0.8911532249616746
epoch 29 time used: 19  seconds  train loss: 0.794601854949045 validation loss: 0.9004260752331558
epoch 30 time used: 19  seconds  train loss: 0.794023597393063 validation loss: 0.9030448026324979
epoch 31 time used: 19  seconds  train loss: 0.793508873131672 validation loss: 0.8910858850574019
epoch 32 time used: 19  seconds  train loss: 0.7932422691863428 validation loss: 0.8893105011081222
epoch 33 time used: 19  seconds  train loss: 0.79172509255823 validation loss: 0.894880103827709
epoch 34 time used: 19  seconds  train loss: 0.7901452923058446 validation loss: 0.8977664252418783
epoch 35 time used: 19  seconds  train loss: 0.7897417544470742 validation loss: 0.8941791864176888
epoch 36 time used: 19  seconds  train loss: 0.7882391942683528 validation loss: 0.9035508917338813
epoch 37 time used: 19  seconds  train loss: 0.7874336256241561 validation loss: 0.8964621982171168
epoch 38 time used: 19  seconds  train loss: 0.7858124443172222 validation loss: 0.8927011676688692
epoch 39 time used: 19  seconds  train loss: 0.7857472576932243 validation loss: 0.9032259968975883
epoch 40 time used: 19  seconds  train loss: 0.7837681062360576 validation loss: 0.8890881087649521
epoch 41 time used: 19  seconds  train loss: 0.7818939276304557 validation loss: 0.8900376048254136
epoch 42 time used: 19  seconds  train loss: 0.7799769775626669 validation loss: 0.8944455604648116
epoch 43 time used: 19  seconds  train loss: 0.7801655390184601 validation loss: 0.895087468090342
epoch 44 time used: 19  seconds  train loss: 0.7787589023835628 validation loss: 0.896635994685823
epoch 45 time used: 19  seconds  train loss: 0.775886661127994 validation loss: 0.8972327166528844
epoch 46 time used: 19  seconds  train loss: 0.7752740761294303 validation loss: 0.8877453777327466
epoch 47 time used: 19  seconds  train loss: 0.7730717101951751 validation loss: 0.8875968832874772
epoch 48 time used: 19  seconds  train loss: 0.7721338346706516 validation loss: 0.88802152545891
epoch 49 time used: 19  seconds  train loss: 0.7692749300179407 validation loss: 0.8999226117015477
epoch 50 time used: 19  seconds  train loss: 0.7684207506064501 validation loss: 0.9007849444204302
epoch 51 time used: 19  seconds  train loss: 0.767819094284839 validation loss: 0.8885800752473708
epoch 52 time used: 19  seconds  train loss: 0.764904618517603 validation loss: 0.8820542464801922
epoch 53 time used: 19  seconds  train loss: 0.7633098536840035 validation loss: 0.8856628154640767
epoch 54 time used: 19  seconds  train loss: 0.7625892654930375 validation loss: 0.90347693660366
epoch 55 time used: 19  seconds  train loss: 0.7631207866485563 validation loss: 0.8847346608318499
epoch 56 time used: 19  seconds  train loss: 0.7597500614048237 validation loss: 0.8836122294563559
epoch 57 time used: 19  seconds  train loss: 0.7583616745590654 validation loss: 0.8851223739225473
epoch 58 time used: 19  seconds  train loss: 0.7577936048188895 validation loss: 0.8848081747097756
epoch 59 time used: 19  seconds  train loss: 0.7566842212107239 validation loss: 0.8881944806421574
epoch 60 time used: 19  seconds  train loss: 0.7568523348819142 validation loss: 0.9002721959085607
epoch 61 time used: 19  seconds  train loss: 0.7565580844709578 validation loss: 0.9012106321937409
Early stopping at epoch: 62
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5444626639e-01, 0.7544462664
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.6381586528, 6.4527636446, 4.5149198830, 24.2385640740
Model Training Ended ... Tue May 31 04:44:04 2022
pred_SZTAXI_GraphWaveNet_2205310423 testing started Tue May 31 04:44:04 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 04:44:04 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1662849213e-01, 0.8166284921
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0136954715, 6.6342818354, 4.6732825408, 23.9770397544
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.1732347146, 6.5706342703, 4.6069332556, 23.7422198057
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.3802711101, 6.5863701012, 4.6257457483, 23.7986385822
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5179778595, 6.5968157364, 4.6340744707, 23.8167062402
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6896267031, 6.6098129098, 4.6474708013, 23.8839238882
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8217613692, 6.6198007046, 4.6552823277, 23.9527463913
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9627370656, 6.6304401864, 4.6673757037, 23.9173844457
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0984360178, 6.6406653295, 4.6741716028, 24.0022972226
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2394850842, 6.6512769514, 4.6888574897, 24.0492090583
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3831499321, 6.6620679922, 4.7042205154, 24.0823268890
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5399521483, 6.6738259004, 4.7171635809, 24.1266116500
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6162181564, 6.6795372711, 4.7230627430, 24.1455748677
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7414954965, 6.6889083935, 4.7350322510, 24.2069885135
Model Testing Ended ... Tue May 31 04:44:09 2022
