../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_3.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205302351 training started Mon May 30 23:51:58 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Mon May 30 23:51:58 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8504144032174459 validation loss: 0.9687485700816064
epoch 1 time used: 19  seconds  train loss: 0.8386992997838287 validation loss: 0.9755202549607006
epoch 2 time used: 19  seconds  train loss: 0.8341564140143469 validation loss: 0.9342960338687423
epoch 3 time used: 19  seconds  train loss: 0.8312883707741077 validation loss: 0.9304888082380912
epoch 4 time used: 19  seconds  train loss: 0.8267695476456014 validation loss: 0.9338634197984762
epoch 5 time used: 19  seconds  train loss: 0.8248004245215426 validation loss: 0.9393952293182487
epoch 6 time used: 19  seconds  train loss: 0.8227052603812509 validation loss: 0.9419893524540004
epoch 7 time used: 19  seconds  train loss: 0.8203382392017804 validation loss: 0.9453637718561276
epoch 8 time used: 19  seconds  train loss: 0.819065681561976 validation loss: 0.9281326582775781
epoch 9 time used: 19  seconds  train loss: 0.8177653594342608 validation loss: 0.9200716846024812
epoch 10 time used: 19  seconds  train loss: 0.8166311908073479 validation loss: 0.9181150043781717
epoch 11 time used: 19  seconds  train loss: 0.813899665350256 validation loss: 0.9267773702369994
epoch 12 time used: 19  seconds  train loss: 0.8127104505197082 validation loss: 0.9556733286795924
epoch 13 time used: 19  seconds  train loss: 0.8113562716528837 validation loss: 0.9452812757658128
epoch 14 time used: 19  seconds  train loss: 0.8092453412785808 validation loss: 0.9114199986505271
epoch 15 time used: 19  seconds  train loss: 0.8075794784476713 validation loss: 0.9241456143298552
epoch 16 time used: 19  seconds  train loss: 0.8058421727942878 validation loss: 0.9247106897890272
epoch 17 time used: 19  seconds  train loss: 0.8038182795302118 validation loss: 0.9089758906198379
epoch 18 time used: 19  seconds  train loss: 0.8018546044233005 validation loss: 0.9177315567263323
epoch 19 time used: 19  seconds  train loss: 0.7993876388028879 validation loss: 0.8999253840588811
epoch 20 time used: 19  seconds  train loss: 0.7975096265079287 validation loss: 0.8946670213742043
epoch 21 time used: 19  seconds  train loss: 0.7940224071654622 validation loss: 0.8989654669714211
epoch 22 time used: 19  seconds  train loss: 0.794094891839821 validation loss: 0.9158306708976404
epoch 23 time used: 19  seconds  train loss: 0.7912341988781947 validation loss: 0.9314283909489266
epoch 24 time used: 19  seconds  train loss: 0.7887327777033679 validation loss: 0.8937065251431062
epoch 25 time used: 19  seconds  train loss: 0.7860463889869483 validation loss: 0.9329884805489536
epoch 26 time used: 19  seconds  train loss: 0.7848541765430065 validation loss: 0.9204131788875333
epoch 27 time used: 19  seconds  train loss: 0.7829225024322358 validation loss: 0.9178339901255138
epoch 28 time used: 19  seconds  train loss: 0.7808586113992151 validation loss: 0.89180180830742
epoch 29 time used: 19  seconds  train loss: 0.7778318948291274 validation loss: 0.8959737007890768
epoch 30 time used: 19  seconds  train loss: 0.7766311013512048 validation loss: 0.9169849640694424
epoch 31 time used: 19  seconds  train loss: 0.7758439034859452 validation loss: 0.8934159670303117
epoch 32 time used: 19  seconds  train loss: 0.7746367003466632 validation loss: 0.9046061329580658
epoch 33 time used: 19  seconds  train loss: 0.7738130675101518 validation loss: 0.8926892357679149
epoch 34 time used: 19  seconds  train loss: 0.771167417084679 validation loss: 0.9052773162500182
epoch 35 time used: 19  seconds  train loss: 0.7710503103214171 validation loss: 0.9317186335426065
epoch 36 time used: 19  seconds  train loss: 0.76971893010404 validation loss: 0.8979478493258728
epoch 37 time used: 19  seconds  train loss: 0.7686866782976587 validation loss: 0.903316520339814
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.7382577627e-01, 0.7738257763
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.4992166874, 6.5191423276, 4.5910538205, 24.0219265223
Model Training Ended ... Tue May 31 00:05:05 2022
pred_SZTAXI_GraphWaveNet_2205302351 testing started Tue May 31 00:05:05 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:05:05 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2181999686e-01, 0.8218199969
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2834186163, 6.6545787708, 4.6960630096, 23.9469513297
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2871435199, 6.5792965825, 4.6100695867, 23.5993117094
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5207947006, 6.5970292330, 4.6297188252, 23.7066328526
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6985346903, 6.6104867211, 4.6486575010, 23.7256720662
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8738373963, 6.6237328899, 4.6636241466, 23.7847477198
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0543877012, 6.6373479419, 4.6773291363, 23.8805040717
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2394485774, 6.6512742071, 4.6911845314, 23.8951995969
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3840361328, 6.6621345028, 4.7047634413, 23.9837512374
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5390967635, 6.6737618150, 4.7167425483, 24.0708902478
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6909747308, 6.6851308686, 4.7312551747, 24.1195306182
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8933636188, 6.7002510116, 4.7481296559, 24.1557598114
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.0403586177, 6.7112114121, 4.7586366095, 24.2064058781
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1790469457, 6.7215360555, 4.7726449589, 24.2347538471
Model Testing Ended ... Tue May 31 00:05:10 2022
