../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_4.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310005 training started Tue May 31 00:05:16 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:05:16 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8485304396149105 validation loss: 0.9705400799044329
epoch 1 time used: 19  seconds  train loss: 0.8351944224593649 validation loss: 0.952561226057176
epoch 2 time used: 19  seconds  train loss: 0.8302095351822855 validation loss: 0.9330997057815096
epoch 3 time used: 19  seconds  train loss: 0.8268423753646156 validation loss: 0.930213632275216
epoch 4 time used: 19  seconds  train loss: 0.8226471358478323 validation loss: 0.9210668034221402
epoch 5 time used: 19  seconds  train loss: 0.8207034828143981 validation loss: 0.9261453768507165
epoch 6 time used: 19  seconds  train loss: 0.819660931952817 validation loss: 0.9391726374033078
epoch 7 time used: 19  seconds  train loss: 0.8172859897145506 validation loss: 0.9414342843477999
epoch 8 time used: 19  seconds  train loss: 0.8161863834725674 validation loss: 0.9145787115120769
epoch 9 time used: 19  seconds  train loss: 0.8149503992597544 validation loss: 0.943109157073557
epoch 10 time used: 19  seconds  train loss: 0.8139363323811277 validation loss: 0.9222060495348119
epoch 11 time used: 19  seconds  train loss: 0.8111610644911634 validation loss: 0.9452781929305537
epoch 12 time used: 19  seconds  train loss: 0.8109497652623596 validation loss: 0.9247540431236153
epoch 13 time used: 19  seconds  train loss: 0.8095034115005862 validation loss: 0.9125177886948657
epoch 14 time used: 19  seconds  train loss: 0.8078126992982617 validation loss: 0.9100486858567195
epoch 15 time used: 19  seconds  train loss: 0.8069127010417357 validation loss: 0.9116728792143105
epoch 16 time used: 19  seconds  train loss: 0.8047808017025292 validation loss: 0.9152281720246842
epoch 17 time used: 19  seconds  train loss: 0.8035628800710947 validation loss: 0.9109340796423195
epoch 18 time used: 19  seconds  train loss: 0.8016915615557946 validation loss: 0.9172358174822224
epoch 19 time used: 19  seconds  train loss: 0.7994816033633302 validation loss: 0.904588666721363
epoch 20 time used: 19  seconds  train loss: 0.798068793111641 validation loss: 0.9009161214923385
epoch 21 time used: 19  seconds  train loss: 0.7955352992963994 validation loss: 0.9003302641768953
epoch 22 time used: 19  seconds  train loss: 0.7949899596136969 validation loss: 0.8998687869280725
epoch 23 time used: 19  seconds  train loss: 0.7922437207118885 validation loss: 0.9196722943391373
epoch 24 time used: 19  seconds  train loss: 0.7904353402925928 validation loss: 0.8960625692386532
epoch 25 time used: 19  seconds  train loss: 0.7873280681722703 validation loss: 0.9486966726198718
epoch 26 time used: 19  seconds  train loss: 0.7858263059157565 validation loss: 0.8948330464054696
epoch 27 time used: 19  seconds  train loss: 0.7832402733616944 validation loss: 0.9342963986135834
epoch 28 time used: 19  seconds  train loss: 0.7806448988181938 validation loss: 0.8840376281026584
epoch 29 time used: 19  seconds  train loss: 0.7778508232463983 validation loss: 0.8911209088652882
epoch 30 time used: 19  seconds  train loss: 0.7760124636408614 validation loss: 0.898792383386128
epoch 31 time used: 19  seconds  train loss: 0.7746065691389027 validation loss: 0.8907295162998029
epoch 32 time used: 19  seconds  train loss: 0.7735131076016433 validation loss: 0.9132187781642326
epoch 33 time used: 19  seconds  train loss: 0.7721531491191425 validation loss: 0.890605028885514
epoch 34 time used: 19  seconds  train loss: 0.769115636986316 validation loss: 0.9093572186000312
epoch 35 time used: 19  seconds  train loss: 0.7688487017816026 validation loss: 0.9251790616049695
epoch 36 time used: 19  seconds  train loss: 0.7673523219177767 validation loss: 0.8975671248056403
epoch 37 time used: 19  seconds  train loss: 0.7662962081591741 validation loss: 0.8852358525665245
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.7287629107e-01, 0.7728762911
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.4540294126, 6.5156756682, 4.5717210745, 24.1657644510
Model Training Ended ... Tue May 31 00:18:43 2022
pred_SZTAXI_GraphWaveNet_2205310005 testing started Tue May 31 00:18:43 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:18:43 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.2096767470e-01, 0.8209676747
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2452683866, 6.6517116885, 4.7019949046, 24.0484669805
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2877728432, 6.5793444083, 4.6178285676, 23.6675098538
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5046121760, 6.5958026180, 4.6377862542, 23.7761139870
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6930089122, 6.6100687525, 4.6595221891, 23.8089039922
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8406222378, 6.6212251312, 4.6719853498, 23.8652274013
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0009304635, 6.6333197167, 4.6843572334, 23.9567294717
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1627401246, 6.6455052573, 4.6968247532, 23.9844322205
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3385427886, 6.6587193054, 4.7108955555, 24.0928992629
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4933711052, 6.6703351569, 4.7206862699, 24.1798356175
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6584651337, 6.6826989408, 4.7353397999, 24.2429405451
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.8361140435, 6.6959774524, 4.7493078395, 24.2876306176
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.9947278502, 6.7078109581, 4.7633162888, 24.3477374315
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.1323129611, 6.7180587197, 4.7760887539, 24.3717983365
Model Testing Ended ... Tue May 31 00:18:48 2022
