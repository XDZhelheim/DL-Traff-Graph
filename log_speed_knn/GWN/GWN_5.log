../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_5.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310018 training started Tue May 31 00:18:55 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:18:55 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8475149346788442 validation loss: 0.9632356831090367
epoch 1 time used: 19  seconds  train loss: 0.8332406407908389 validation loss: 0.9687627156575521
epoch 2 time used: 19  seconds  train loss: 0.8285612791225547 validation loss: 0.9348580944004343
epoch 3 time used: 19  seconds  train loss: 0.8251599672000066 validation loss: 0.9259551778361572
epoch 4 time used: 19  seconds  train loss: 0.8211543619378363 validation loss: 0.9267267836860164
epoch 5 time used: 19  seconds  train loss: 0.8190570804336841 validation loss: 0.9260277490117657
epoch 6 time used: 19  seconds  train loss: 0.81812937865047 validation loss: 0.9289758845941344
epoch 7 time used: 19  seconds  train loss: 0.8157270518509118 validation loss: 0.9310475320958379
epoch 8 time used: 19  seconds  train loss: 0.8144378552735275 validation loss: 0.9219886556786684
epoch 9 time used: 19  seconds  train loss: 0.8132356724901864 validation loss: 0.9266677937697415
epoch 10 time used: 19  seconds  train loss: 0.8124260475930585 validation loss: 0.9179473895931718
epoch 11 time used: 19  seconds  train loss: 0.8097118407191117 validation loss: 0.9276759408006621
epoch 12 time used: 19  seconds  train loss: 0.8094798275620636 validation loss: 0.920622928225579
epoch 13 time used: 21  seconds  train loss: 0.8083357270886515 validation loss: 0.9180112062995114
epoch 14 time used: 32  seconds  train loss: 0.8066021501594044 validation loss: 0.9057296158662483
epoch 15 time used: 44  seconds  train loss: 0.8063984657419185 validation loss: 0.9152346570693438
epoch 16 time used: 19  seconds  train loss: 0.8040538984715175 validation loss: 0.9160216937017678
epoch 17 time used: 19  seconds  train loss: 0.8032236345970784 validation loss: 0.9071457311881715
epoch 18 time used: 19  seconds  train loss: 0.8013255234124141 validation loss: 0.9062490916963833
epoch 19 time used: 19  seconds  train loss: 0.7991888242459738 validation loss: 0.8950100802070465
epoch 20 time used: 19  seconds  train loss: 0.7984091748892838 validation loss: 0.8971728522386124
epoch 21 time used: 19  seconds  train loss: 0.7961604977569743 validation loss: 0.9002914843867668
epoch 22 time used: 19  seconds  train loss: 0.7955789568583623 validation loss: 0.897900988509999
epoch 23 time used: 19  seconds  train loss: 0.793541677391546 validation loss: 0.8971153826855901
epoch 24 time used: 19  seconds  train loss: 0.7905369783363505 validation loss: 0.8898181117589201
epoch 25 time used: 19  seconds  train loss: 0.788343054810764 validation loss: 0.9219627653188374
epoch 26 time used: 19  seconds  train loss: 0.7859712984110858 validation loss: 0.8934015996420561
epoch 27 time used: 19  seconds  train loss: 0.7832314426325803 validation loss: 0.8994416176383175
epoch 28 time used: 19  seconds  train loss: 0.7808655196877665 validation loss: 0.879235119072359
epoch 29 time used: 19  seconds  train loss: 0.7774566937646011 validation loss: 0.8953335641035393
epoch 30 time used: 19  seconds  train loss: 0.7751419082135598 validation loss: 0.8998157731929228
epoch 31 time used: 19  seconds  train loss: 0.7738587361141763 validation loss: 0.8962892184210061
epoch 32 time used: 19  seconds  train loss: 0.772714430119201 validation loss: 0.8893952108734283
epoch 33 time used: 19  seconds  train loss: 0.7700221215508571 validation loss: 0.9019767600505506
epoch 34 time used: 19  seconds  train loss: 0.7682287454774674 validation loss: 0.9037962185209664
epoch 35 time used: 19  seconds  train loss: 0.7676619694039628 validation loss: 0.8999099784822606
epoch 36 time used: 19  seconds  train loss: 0.7660868933495892 validation loss: 0.8915820857185629
epoch 37 time used: 19  seconds  train loss: 0.7650369134430864 validation loss: 0.8818455694326713
Early stopping at epoch: 38
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.6676175121e-01, 0.7667617512
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 42.1622099940, 6.4932434110, 4.5651961023, 24.0310490131
Model Training Ended ... Tue May 31 00:32:42 2022
pred_SZTAXI_GraphWaveNet_2205310018 testing started Tue May 31 00:32:42 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:32:42 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.7407047769e-01, 0.8740704777
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 47.0690170065, 6.8606863364, 4.8896525799, 25.0305175781
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.4795186996, 6.7438504357, 4.7476152007, 24.6258929372
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.7845706989, 6.7664296862, 4.7742645860, 24.7308760881
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 45.9919244304, 6.7817346181, 4.7960818793, 24.8099908233
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.1834040838, 6.7958372614, 4.8163608793, 24.8564556241
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.3492030546, 6.8080249011, 4.8373915201, 24.8333334923
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 46.7176825241, 6.8350334691, 4.8660214175, 24.9927341938
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 47.1296232925, 6.8651018414, 4.8997908293, 25.0721305609
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 47.5393769814, 6.8948804907, 4.9298720064, 25.1719146967
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 47.9012013011, 6.9210693755, 4.9628456703, 25.1956254244
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 48.2258587193, 6.9444840499, 4.9864821843, 25.3041625023
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 48.6013715302, 6.9714683912, 5.0162399630, 25.3705710173
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 48.9244687619, 6.9946028309, 5.0428648222, 25.4026055336
Model Testing Ended ... Tue May 31 00:32:59 2022
