../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_6.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310033 training started Tue May 31 00:33:16 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:33:16 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8466464331105966 validation loss: 0.9544964026455856
epoch 1 time used: 19  seconds  train loss: 0.8324416214507471 validation loss: 0.9611195485983322
epoch 2 time used: 19  seconds  train loss: 0.8276703046531461 validation loss: 0.9278463279429953
epoch 3 time used: 19  seconds  train loss: 0.824170379601366 validation loss: 0.9216798807851118
epoch 4 time used: 19  seconds  train loss: 0.8199844161104173 validation loss: 0.9238715459458271
epoch 5 time used: 19  seconds  train loss: 0.8180652638078584 validation loss: 0.9370960866040852
epoch 6 time used: 19  seconds  train loss: 0.817149286928082 validation loss: 0.9273241897720602
epoch 7 time used: 19  seconds  train loss: 0.8149811800140067 validation loss: 0.9286071035399366
epoch 8 time used: 19  seconds  train loss: 0.8133886810047698 validation loss: 0.9163620694359736
epoch 9 time used: 19  seconds  train loss: 0.8123118081269189 validation loss: 0.9215081446799472
epoch 10 time used: 19  seconds  train loss: 0.8118800683686269 validation loss: 0.9160271983834641
epoch 11 time used: 19  seconds  train loss: 0.8090821925132068 validation loss: 0.9158706125335314
epoch 12 time used: 19  seconds  train loss: 0.8091129955662094 validation loss: 0.9172960905293327
epoch 13 time used: 19  seconds  train loss: 0.807296032078066 validation loss: 0.9134284693803361
epoch 14 time used: 19  seconds  train loss: 0.8060684802691594 validation loss: 0.9060567632243408
epoch 15 time used: 19  seconds  train loss: 0.8057714385294473 validation loss: 0.9109770664528235
epoch 16 time used: 19  seconds  train loss: 0.8036502212243603 validation loss: 0.9161028034651457
epoch 17 time used: 19  seconds  train loss: 0.8022348057494564 validation loss: 0.9068937933267053
epoch 18 time used: 19  seconds  train loss: 0.8011175480540074 validation loss: 0.9086639646867022
epoch 19 time used: 19  seconds  train loss: 0.7994372311391329 validation loss: 0.8986937293958901
epoch 20 time used: 19  seconds  train loss: 0.7983052766170474 validation loss: 0.8981515308517721
epoch 21 time used: 19  seconds  train loss: 0.7962839314303392 validation loss: 0.9058073115586048
epoch 22 time used: 19  seconds  train loss: 0.7954604880908136 validation loss: 0.9102482033606193
epoch 23 time used: 19  seconds  train loss: 0.7937353199949305 validation loss: 0.9086296015710973
epoch 24 time used: 19  seconds  train loss: 0.7910144736892298 validation loss: 0.8949599067370096
epoch 25 time used: 19  seconds  train loss: 0.7886996850858881 validation loss: 0.9280355919652911
epoch 26 time used: 19  seconds  train loss: 0.7872800455663147 validation loss: 0.8892069269175553
epoch 27 time used: 19  seconds  train loss: 0.7848273371564884 validation loss: 0.9047990886133108
epoch 28 time used: 19  seconds  train loss: 0.7824169136212866 validation loss: 0.8829814670097769
epoch 29 time used: 19  seconds  train loss: 0.779271629931747 validation loss: 0.8957472333860634
epoch 30 time used: 19  seconds  train loss: 0.7772650835693815 validation loss: 0.9067802266101932
epoch 31 time used: 19  seconds  train loss: 0.7752929150973411 validation loss: 0.8922146775236177
epoch 32 time used: 19  seconds  train loss: 0.7748397319109986 validation loss: 0.9182583271567502
epoch 33 time used: 19  seconds  train loss: 0.7719164786603339 validation loss: 0.8974966071731415
epoch 34 time used: 19  seconds  train loss: 0.7695570800925047 validation loss: 0.9093753449359343
epoch 35 time used: 19  seconds  train loss: 0.7692851690445651 validation loss: 0.9012659859301438
epoch 36 time used: 19  seconds  train loss: 0.7669049679469927 validation loss: 0.8972494519172023
epoch 37 time used: 19  seconds  train loss: 0.765928218917521 validation loss: 0.8812239869910093
epoch 38 time used: 19  seconds  train loss: 0.763890001885752 validation loss: 0.8837954458312609
epoch 39 time used: 19  seconds  train loss: 0.7636779808726792 validation loss: 0.8904731418955979
epoch 40 time used: 19  seconds  train loss: 0.7614776398006239 validation loss: 0.8896703147769567
epoch 41 time used: 19  seconds  train loss: 0.7604440677047285 validation loss: 0.8807681419363069
epoch 42 time used: 19  seconds  train loss: 0.7596474963095924 validation loss: 0.9069581417301994
epoch 43 time used: 19  seconds  train loss: 0.7596379793215952 validation loss: 0.8898710166636984
epoch 44 time used: 19  seconds  train loss: 0.7586579311792745 validation loss: 0.9015754917960855
epoch 45 time used: 19  seconds  train loss: 0.7567672784603168 validation loss: 0.8932825469259006
epoch 46 time used: 19  seconds  train loss: 0.7565197736915111 validation loss: 0.8817061301487595
epoch 47 time used: 19  seconds  train loss: 0.7565825996154741 validation loss: 0.8856777542859168
epoch 48 time used: 19  seconds  train loss: 0.7550102416346456 validation loss: 0.8807740484304096
epoch 49 time used: 19  seconds  train loss: 0.7541946095558861 validation loss: 0.8993371461161334
epoch 50 time used: 19  seconds  train loss: 0.7536659957165399 validation loss: 0.8876975401123958
Early stopping at epoch: 51
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5420126484e-01, 0.7542012648
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.5816425686, 6.4483829422, 4.5412096557, 24.0258842707
Model Training Ended ... Tue May 31 00:50:38 2022
pred_SZTAXI_GraphWaveNet_2205310033 testing started Tue May 31 00:50:38 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 00:50:38 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1573410948e-01, 0.8157341095
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9541107058, 6.6297896427, 4.6777356049, 23.9362627268
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.0592902109, 6.5619578032, 4.6029427014, 23.7110108137
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2845521302, 6.5790996443, 4.6242981988, 23.7439185381
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.4571648629, 6.5922048560, 4.6376865403, 23.8204151392
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6233208239, 6.6047952901, 4.6510559973, 23.8661646843
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7872388246, 6.6171926694, 4.6643227026, 23.8688468933
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9148535599, 6.6268283183, 4.6731018862, 23.9415645599
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0678481834, 6.6383618599, 4.6886564371, 23.9255309105
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1894849748, 6.6475172038, 4.6958833331, 23.9848226309
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3164160773, 6.6570576141, 4.7064450306, 24.0276262164
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4470555537, 6.6668624970, 4.7180587536, 24.0718781948
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5731000290, 6.6763088626, 4.7281658008, 24.0992322564
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7290032390, 6.6879745244, 4.7422098775, 24.1743534803
Model Testing Ended ... Tue May 31 00:50:43 2022
