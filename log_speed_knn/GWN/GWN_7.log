../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_7.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310050 training started Tue May 31 00:50:49 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 00:50:49 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.846361197838573 validation loss: 0.9519176987273184
epoch 1 time used: 19  seconds  train loss: 0.8319764932561904 validation loss: 0.9529933923512549
epoch 2 time used: 19  seconds  train loss: 0.8271619493557753 validation loss: 0.9240821766023019
epoch 3 time used: 19  seconds  train loss: 0.8235704305331365 validation loss: 0.9211573010653406
epoch 4 time used: 19  seconds  train loss: 0.8195453941567694 validation loss: 0.9173143408191737
epoch 5 time used: 19  seconds  train loss: 0.8175611155131464 validation loss: 0.9549517942898309
epoch 6 time used: 19  seconds  train loss: 0.8167438511319385 validation loss: 0.9281519962780511
epoch 7 time used: 19  seconds  train loss: 0.8145736845085665 validation loss: 0.9246541608625384
epoch 8 time used: 19  seconds  train loss: 0.8129919728378144 validation loss: 0.9142799795563541
epoch 9 time used: 19  seconds  train loss: 0.8119257044147801 validation loss: 0.9194353273258874
epoch 10 time used: 19  seconds  train loss: 0.811468989547252 validation loss: 0.9131525938783712
epoch 11 time used: 19  seconds  train loss: 0.8087809014625603 validation loss: 0.9170271727576185
epoch 12 time used: 19  seconds  train loss: 0.8088948535037414 validation loss: 0.9141463557286049
epoch 13 time used: 19  seconds  train loss: 0.8072735490873562 validation loss: 0.9118782462765328
epoch 14 time used: 19  seconds  train loss: 0.8063636487442603 validation loss: 0.9050504108566549
epoch 15 time used: 19  seconds  train loss: 0.8062581085039575 validation loss: 0.9130988055793801
epoch 16 time used: 19  seconds  train loss: 0.804570414433269 validation loss: 0.9113916733964759
epoch 17 time used: 19  seconds  train loss: 0.8033809320177157 validation loss: 0.908460461381656
epoch 18 time used: 19  seconds  train loss: 0.8026472570885974 validation loss: 0.9081887424881778
epoch 19 time used: 19  seconds  train loss: 0.8008480462037653 validation loss: 0.9003709222546857
epoch 20 time used: 19  seconds  train loss: 0.7997181908165238 validation loss: 0.9006370552143648
epoch 21 time used: 19  seconds  train loss: 0.7983392393945121 validation loss: 0.9027280478335139
epoch 22 time used: 19  seconds  train loss: 0.7977587773993209 validation loss: 0.9119211764477971
epoch 23 time used: 19  seconds  train loss: 0.7959970902243515 validation loss: 0.9178954861057338
epoch 24 time used: 19  seconds  train loss: 0.7938577741342113 validation loss: 0.8935603182114179
epoch 25 time used: 19  seconds  train loss: 0.7921451352229328 validation loss: 0.9313005117041555
epoch 26 time used: 19  seconds  train loss: 0.7905395714351496 validation loss: 0.8966048997433032
epoch 27 time used: 19  seconds  train loss: 0.7884783698179644 validation loss: 0.9128478744729834
epoch 28 time used: 19  seconds  train loss: 0.7865930486200206 validation loss: 0.8862138179997306
epoch 29 time used: 19  seconds  train loss: 0.78339653783299 validation loss: 0.8955913304689511
epoch 30 time used: 19  seconds  train loss: 0.7813557303307914 validation loss: 0.9062901613724172
epoch 31 time used: 19  seconds  train loss: 0.7795255964205919 validation loss: 0.890617326420931
epoch 32 time used: 19  seconds  train loss: 0.7778406635795854 validation loss: 0.9018484063409454
epoch 33 time used: 19  seconds  train loss: 0.7759342689602338 validation loss: 0.8933763329069413
epoch 34 time used: 19  seconds  train loss: 0.772934652748352 validation loss: 0.9039644459586832
epoch 35 time used: 19  seconds  train loss: 0.771871450785044 validation loss: 0.905870559203684
epoch 36 time used: 19  seconds  train loss: 0.7697203077937597 validation loss: 0.9110328730066024
epoch 37 time used: 19  seconds  train loss: 0.7682708849438902 validation loss: 0.886859823222184
epoch 38 time used: 19  seconds  train loss: 0.7659201694077482 validation loss: 0.8821515690034895
epoch 39 time used: 19  seconds  train loss: 0.7649831638736372 validation loss: 0.8830379885227526
epoch 40 time used: 19  seconds  train loss: 0.7629549281186773 validation loss: 0.8906373102866595
epoch 41 time used: 19  seconds  train loss: 0.7620095118859075 validation loss: 0.8829623015958872
epoch 42 time used: 19  seconds  train loss: 0.7600795875063662 validation loss: 0.9162496615998188
epoch 43 time used: 19  seconds  train loss: 0.7606894881762617 validation loss: 0.8965187084615527
epoch 44 time used: 19  seconds  train loss: 0.7593161445084541 validation loss: 0.8990040780299932
epoch 45 time used: 19  seconds  train loss: 0.7570329184722087 validation loss: 0.889987608983149
epoch 46 time used: 19  seconds  train loss: 0.7569430033818078 validation loss: 0.8799553495734486
epoch 47 time used: 19  seconds  train loss: 0.7568612380183778 validation loss: 0.8861288025011471
epoch 48 time used: 19  seconds  train loss: 0.7552352330593093 validation loss: 0.886468614511822
epoch 49 time used: 19  seconds  train loss: 0.7538836372017351 validation loss: 0.8979946582471553
epoch 50 time used: 19  seconds  train loss: 0.7534250030307309 validation loss: 0.8889264749057257
epoch 51 time used: 19  seconds  train loss: 0.7523478286534251 validation loss: 0.8994098756443801
epoch 52 time used: 19  seconds  train loss: 0.7519887750213211 validation loss: 0.8867621854763126
epoch 53 time used: 19  seconds  train loss: 0.7512445772016371 validation loss: 0.8823014091496444
epoch 54 time used: 19  seconds  train loss: 0.7507360185871422 validation loss: 0.9019428553865917
epoch 55 time used: 19  seconds  train loss: 0.7511605134559729 validation loss: 0.8837844335024629
Early stopping at epoch: 56
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.4661114604e-01, 0.7466111460
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.2106557798, 6.4195526152, 4.4948056604, 24.0997478366
Model Training Ended ... Tue May 31 01:09:53 2022
pred_SZTAXI_GraphWaveNet_2205310050 testing started Tue May 31 01:09:53 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:09:53 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1591280301e-01, 0.8159128030
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9649748760, 6.6306089370, 4.6626561261, 23.9903822541
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.1049179976, 6.5654335727, 4.5991438292, 23.7834617496
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.3427605095, 6.5835218925, 4.6166857131, 23.8613665104
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5036976128, 6.5957332885, 4.6292659837, 23.8880485296
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6244174989, 6.6048783107, 4.6366622064, 23.8984197378
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8016102421, 6.6182784954, 4.6477787877, 23.9595785737
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8966330722, 6.6254534239, 4.6564025289, 23.9110931754
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0260466722, 6.6352126320, 4.6674743521, 23.9353120327
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1982172982, 6.6481739822, 4.6790214416, 24.0259230137
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.3376792835, 6.6586544649, 4.6898418295, 24.1174325347
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4565702971, 6.6675760436, 4.6999748760, 24.1129010916
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5927538730, 6.6777806098, 4.7086114396, 24.1665408015
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6943941548, 6.6853866122, 4.7210105251, 24.2245286703
Model Testing Ended ... Tue May 31 01:09:58 2022
