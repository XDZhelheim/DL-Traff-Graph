../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_8.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310110 training started Tue May 31 01:10:03 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:10:03 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8459886165804748 validation loss: 0.9482390690798783
epoch 1 time used: 19  seconds  train loss: 0.8315176573789984 validation loss: 0.9561703756674013
epoch 2 time used: 19  seconds  train loss: 0.8267235930579825 validation loss: 0.9238005123328213
epoch 3 time used: 19  seconds  train loss: 0.8229381297933598 validation loss: 0.920474913582873
epoch 4 time used: 19  seconds  train loss: 0.8190276503223782 validation loss: 0.9168580957313082
epoch 5 time used: 19  seconds  train loss: 0.8170157013882274 validation loss: 0.9403807743271785
epoch 6 time used: 19  seconds  train loss: 0.8163546485717741 validation loss: 0.9251579526645034
epoch 7 time used: 19  seconds  train loss: 0.8142664721646315 validation loss: 0.9231832534519594
epoch 8 time used: 19  seconds  train loss: 0.812611508844248 validation loss: 0.9139526610943809
epoch 9 time used: 19  seconds  train loss: 0.8114954748669186 validation loss: 0.9171556056435428
epoch 10 time used: 19  seconds  train loss: 0.8109604495009182 validation loss: 0.9095491313222629
epoch 11 time used: 19  seconds  train loss: 0.8084307277355222 validation loss: 0.9158143297356752
epoch 12 time used: 19  seconds  train loss: 0.8083964861812836 validation loss: 0.9127490858533489
epoch 13 time used: 19  seconds  train loss: 0.806734025478363 validation loss: 0.9081192986289067
epoch 14 time used: 19  seconds  train loss: 0.8055685295658465 validation loss: 0.9036151135145728
epoch 15 time used: 19  seconds  train loss: 0.8054938235798398 validation loss: 0.9095595481976941
epoch 16 time used: 19  seconds  train loss: 0.8039636325361379 validation loss: 0.9118131117441168
epoch 17 time used: 19  seconds  train loss: 0.802366871328476 validation loss: 0.9044337106581352
epoch 18 time used: 19  seconds  train loss: 0.8016559926747937 validation loss: 0.9077720659882275
epoch 19 time used: 19  seconds  train loss: 0.7996703867891943 validation loss: 0.8998058942419973
epoch 20 time used: 19  seconds  train loss: 0.7988175430135063 validation loss: 0.9035038325323987
epoch 21 time used: 19  seconds  train loss: 0.7971438679891834 validation loss: 0.8957813266497939
epoch 22 time used: 19  seconds  train loss: 0.7963447837029208 validation loss: 0.8999115468850777
epoch 23 time used: 19  seconds  train loss: 0.7947228950253591 validation loss: 0.908961667053735
epoch 24 time used: 19  seconds  train loss: 0.7921777297219376 validation loss: 0.8848972032912334
epoch 25 time used: 19  seconds  train loss: 0.7905087977181458 validation loss: 0.9136235710993335
epoch 26 time used: 19  seconds  train loss: 0.7891051539486197 validation loss: 0.8918556917959185
epoch 27 time used: 19  seconds  train loss: 0.7871361262089497 validation loss: 0.9039806169063891
epoch 28 time used: 19  seconds  train loss: 0.7841935050097503 validation loss: 0.8832405900480735
epoch 29 time used: 19  seconds  train loss: 0.7816502317086731 validation loss: 0.8926787070967072
epoch 30 time used: 19  seconds  train loss: 0.779273506503017 validation loss: 0.8977088768090775
epoch 31 time used: 19  seconds  train loss: 0.7771682384003955 validation loss: 0.8898822511013468
epoch 32 time used: 19  seconds  train loss: 0.776684563665268 validation loss: 0.8911837499533126
epoch 33 time used: 19  seconds  train loss: 0.773258267137438 validation loss: 0.8881544251347062
epoch 34 time used: 19  seconds  train loss: 0.7708837732481922 validation loss: 0.8956305630764558
epoch 35 time used: 19  seconds  train loss: 0.7697117008152252 validation loss: 0.907576839722211
epoch 36 time used: 19  seconds  train loss: 0.767961575415192 validation loss: 0.8969095880119362
epoch 37 time used: 19  seconds  train loss: 0.7664945698734028 validation loss: 0.8818908861620509
epoch 38 time used: 19  seconds  train loss: 0.7644996841465935 validation loss: 0.8799417223503341
epoch 39 time used: 19  seconds  train loss: 0.7636255656672406 validation loss: 0.8874842254676629
epoch 40 time used: 19  seconds  train loss: 0.761252370107903 validation loss: 0.8901527784950104
epoch 41 time used: 19  seconds  train loss: 0.7602464435449874 validation loss: 0.8783625067763068
epoch 42 time used: 19  seconds  train loss: 0.7588276138176789 validation loss: 0.8970469105896072
epoch 43 time used: 19  seconds  train loss: 0.7593414155212609 validation loss: 0.8914925737760553
epoch 44 time used: 19  seconds  train loss: 0.7580124066021839 validation loss: 0.890679246750637
epoch 45 time used: 19  seconds  train loss: 0.7558604967204131 validation loss: 0.8847387830416361
epoch 46 time used: 19  seconds  train loss: 0.7559203140935722 validation loss: 0.8783635772875885
epoch 47 time used: 19  seconds  train loss: 0.7557564425264958 validation loss: 0.8809142839256211
epoch 48 time used: 19  seconds  train loss: 0.7550067542118165 validation loss: 0.8809834425129107
epoch 49 time used: 19  seconds  train loss: 0.7529587501482469 validation loss: 0.8880294958750407
epoch 50 time used: 19  seconds  train loss: 0.7523123495609289 validation loss: 0.8832806588998482
Early stopping at epoch: 51
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5343083165e-01, 0.7534308317
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.5164245746, 6.4433240315, 4.5290672454, 24.0230798721
Model Training Ended ... Tue May 31 01:27:26 2022
pred_SZTAXI_GraphWaveNet_2205310110 testing started Tue May 31 01:27:26 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:27:26 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1514501051e-01, 0.8151450105
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9226898907, 6.6274195499, 4.6791566716, 23.8366141915
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.0106082761, 6.5582473479, 4.6027612449, 23.6302331090
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.2420668199, 6.5758700428, 4.6264221475, 23.6576706171
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.4214858666, 6.5894981498, 4.6402091189, 23.7371429801
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.5912121257, 6.6023641316, 4.6539949827, 23.7769693136
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.7713257690, 6.6159901579, 4.6679335776, 23.7827286124
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9166648483, 6.6269649802, 4.6763720589, 23.8610938191
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0805090280, 6.6393154036, 4.6924755934, 23.8404259086
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1636433096, 6.6455732115, 4.6961437967, 23.8815262914
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2907052235, 6.6551262365, 4.7083860001, 23.9177212119
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4169359254, 6.6646032084, 4.7190898961, 23.9472776651
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5268260635, 6.6728424276, 4.7276552152, 23.9667147398
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6402954331, 6.6813393443, 4.7384364273, 24.0396946669
Model Testing Ended ... Tue May 31 01:27:31 2022
