../SZTAXI/SZTAXI-speed.pkl
../SZTAXI/adj_9.npy
data.shape (8064, 492)
pred_SZTAXI_GraphWaveNet_2205310127 training started Tue May 31 01:27:36 2022
TRAIN XS.shape YS,shape (6428, 1, 492, 12) (6428, 12, 492, 1)
Model Training Started ... Tue May 31 01:27:36 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 492, 13]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 492, 12]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 492, 12]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 492, 12]         --
|    |    └─nconv: 3-1                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-2                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-3                   [-1, 32, 492, 12]         --
|    |    └─nconv: 3-4                   [-1, 32, 492, 12]         --
|    |    └─linear: 3-5                  [-1, 32, 492, 12]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 492, 12]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 492, 10]         2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 492, 10]        8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 492, 10]         --
|    |    └─nconv: 3-6                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-7                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-8                   [-1, 32, 492, 10]         --
|    |    └─nconv: 3-9                   [-1, 32, 492, 10]         --
|    |    └─linear: 3-10                 [-1, 32, 492, 10]         5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 492, 10]         64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 492, 9]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 492, 9]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 492, 9]          --
|    |    └─nconv: 3-11                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-12                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-13                  [-1, 32, 492, 9]          --
|    |    └─nconv: 3-14                  [-1, 32, 492, 9]          --
|    |    └─linear: 3-15                 [-1, 32, 492, 9]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 492, 9]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 492, 7]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 492, 7]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 492, 7]          --
|    |    └─nconv: 3-16                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-17                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-18                  [-1, 32, 492, 7]          --
|    |    └─nconv: 3-19                  [-1, 32, 492, 7]          --
|    |    └─linear: 3-20                 [-1, 32, 492, 7]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 492, 7]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 492, 6]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 492, 6]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 492, 6]          --
|    |    └─nconv: 3-21                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-22                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-23                  [-1, 32, 492, 6]          --
|    |    └─nconv: 3-24                  [-1, 32, 492, 6]          --
|    |    └─linear: 3-25                 [-1, 32, 492, 6]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 492, 6]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 492, 4]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 492, 4]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 492, 4]          --
|    |    └─nconv: 3-26                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-27                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-28                  [-1, 32, 492, 4]          --
|    |    └─nconv: 3-29                  [-1, 32, 492, 4]          --
|    |    └─linear: 3-30                 [-1, 32, 492, 4]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 492, 4]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 492, 3]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 492, 3]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 492, 3]          --
|    |    └─nconv: 3-31                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-32                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-33                  [-1, 32, 492, 3]          --
|    |    └─nconv: 3-34                  [-1, 32, 492, 3]          --
|    |    └─linear: 3-35                 [-1, 32, 492, 3]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 492, 3]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 492, 1]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 492, 1]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 492, 1]          --
|    |    └─nconv: 3-36                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-37                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-38                  [-1, 32, 492, 1]          --
|    |    └─nconv: 3-39                  [-1, 32, 492, 1]          --
|    |    └─linear: 3-40                 [-1, 32, 492, 1]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 492, 1]          64
├─Conv2d: 1-2                            [-1, 512, 492, 1]         131,584
├─Conv2d: 1-3                            [-1, 12, 492, 1]          6,156
==========================================================================================
Total params: 280,396
Trainable params: 280,396
Non-trainable params: 0
Total mult-adds (M): 513.16
==========================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 78.48
Params size (MB): 1.07
Estimated Total Size (MB): 79.57
==========================================================================================
XS_torch.shape:   torch.Size([6428, 1, 492, 12])
YS_torch.shape:   torch.Size([6428, 12, 492, 1])
LOSS is : MSE
epoch 0 time used: 19  seconds  train loss: 0.8456906330365036 validation loss: 0.9484597408949439
epoch 1 time used: 19  seconds  train loss: 0.8313195114454538 validation loss: 0.9532690534544228
epoch 2 time used: 19  seconds  train loss: 0.8265752748269615 validation loss: 0.9274432700664843
epoch 3 time used: 19  seconds  train loss: 0.8227214246013256 validation loss: 0.9207145518331386
epoch 4 time used: 19  seconds  train loss: 0.8188523076167317 validation loss: 0.9139286036515117
epoch 5 time used: 19  seconds  train loss: 0.8166938081574474 validation loss: 0.9384007937279507
epoch 6 time used: 19  seconds  train loss: 0.8161948035824859 validation loss: 0.926542830407916
epoch 7 time used: 19  seconds  train loss: 0.8140478963363561 validation loss: 0.9231928548409571
epoch 8 time used: 19  seconds  train loss: 0.812349979687551 validation loss: 0.915761565984185
epoch 9 time used: 19  seconds  train loss: 0.8113933750779327 validation loss: 0.9197545632794129
epoch 10 time used: 19  seconds  train loss: 0.81074796580997 validation loss: 0.9096424490658205
epoch 11 time used: 19  seconds  train loss: 0.8083752217367397 validation loss: 0.919397806646812
epoch 12 time used: 19  seconds  train loss: 0.8080379243934815 validation loss: 0.914734291200021
epoch 13 time used: 19  seconds  train loss: 0.8066952298070764 validation loss: 0.9087464032481559
epoch 14 time used: 19  seconds  train loss: 0.8056212698412824 validation loss: 0.9069903881395635
epoch 15 time used: 19  seconds  train loss: 0.8056418681212544 validation loss: 0.9098341761536859
epoch 16 time used: 19  seconds  train loss: 0.8041183078611219 validation loss: 0.9141468156629534
epoch 17 time used: 19  seconds  train loss: 0.8025380595988604 validation loss: 0.9064523465004727
epoch 18 time used: 19  seconds  train loss: 0.8022594592649261 validation loss: 0.9054374837163669
epoch 19 time used: 19  seconds  train loss: 0.800291911636613 validation loss: 0.8987450733113644
epoch 20 time used: 19  seconds  train loss: 0.799653654078162 validation loss: 0.8990256827862109
epoch 21 time used: 19  seconds  train loss: 0.7982347912842654 validation loss: 0.8974425537669244
epoch 22 time used: 19  seconds  train loss: 0.7975186669979123 validation loss: 0.9072036746129468
epoch 23 time used: 19  seconds  train loss: 0.7962348330580493 validation loss: 0.9053315410566567
epoch 24 time used: 19  seconds  train loss: 0.7942159955057277 validation loss: 0.887642160280427
epoch 25 time used: 19  seconds  train loss: 0.7927126084079444 validation loss: 0.9170433170166775
epoch 26 time used: 19  seconds  train loss: 0.7916824952467407 validation loss: 0.8950819168517838
epoch 27 time used: 19  seconds  train loss: 0.7898966650535507 validation loss: 0.9011470832634921
epoch 28 time used: 19  seconds  train loss: 0.7878672617936711 validation loss: 0.8836362213637698
epoch 29 time used: 19  seconds  train loss: 0.7854225084418762 validation loss: 0.896866466275495
epoch 30 time used: 19  seconds  train loss: 0.7836795333099907 validation loss: 0.9051475317323979
epoch 31 time used: 19  seconds  train loss: 0.7812247657843708 validation loss: 0.8896032568827197
epoch 32 time used: 19  seconds  train loss: 0.7797368240899076 validation loss: 0.8927086366349785
epoch 33 time used: 19  seconds  train loss: 0.7773206294176419 validation loss: 0.8812991855156362
epoch 34 time used: 19  seconds  train loss: 0.7741331993940036 validation loss: 0.9038411568646407
epoch 35 time used: 19  seconds  train loss: 0.7736923877748623 validation loss: 0.9014296736290206
epoch 36 time used: 19  seconds  train loss: 0.7715311570153975 validation loss: 0.9138096995021573
epoch 37 time used: 19  seconds  train loss: 0.7698134664620987 validation loss: 0.8773667210370154
epoch 38 time used: 19  seconds  train loss: 0.7672625417220983 validation loss: 0.8859211660143155
epoch 39 time used: 19  seconds  train loss: 0.7664149075449784 validation loss: 0.8789585754645998
epoch 40 time used: 19  seconds  train loss: 0.7637689858039107 validation loss: 0.8849720263955605
epoch 41 time used: 19  seconds  train loss: 0.7625018292097414 validation loss: 0.8742661250764457
epoch 42 time used: 19  seconds  train loss: 0.7608696106148308 validation loss: 0.8967290547356677
epoch 43 time used: 19  seconds  train loss: 0.7611443559780907 validation loss: 0.8999268077499237
epoch 44 time used: 19  seconds  train loss: 0.7596986733832706 validation loss: 0.8946333969410379
epoch 45 time used: 19  seconds  train loss: 0.7578702163730203 validation loss: 0.8811813930966961
epoch 46 time used: 19  seconds  train loss: 0.7574727927807554 validation loss: 0.8783652171566712
epoch 47 time used: 19  seconds  train loss: 0.7571072577582314 validation loss: 0.8886222780047365
epoch 48 time used: 19  seconds  train loss: 0.755935687852618 validation loss: 0.8784928876369154
epoch 49 time used: 19  seconds  train loss: 0.7543600413572059 validation loss: 0.889445410439031
epoch 50 time used: 19  seconds  train loss: 0.7540121058990402 validation loss: 0.8778726689851106
Early stopping at epoch: 51
YS.shape, YS_pred.shape, (6428, 12, 492, 1) (6428, 12, 492, 1)
YS.shape, YS_pred.shape, (6428, 12, 492) (6428, 12, 492)
****************************************
GraphWaveNet, train, Torch MSE, 7.5181869423e-01, 0.7518186942
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 41.4327182140, 6.4368251657, 4.5167124015, 24.0660756826
Model Training Ended ... Tue May 31 01:45:02 2022
pred_SZTAXI_GraphWaveNet_2205310127 testing started Tue May 31 01:45:02 2022
TEST XS.shape, YS.shape (1602, 1, 492, 12) (1602, 12, 492, 1)
Model Testing Started ... Tue May 31 01:45:02 2022
TIMESTEP_IN, TIMESTEP_OUT 12 12
YS.shape, YS_pred.shape, (1602, 12, 492, 1) (1602, 12, 492, 1)
YS.shape, YS_pred.shape, (1602, 12, 492) (1602, 12, 492)
****************************************
GraphWaveNet, test, Torch MSE, 8.1691090147e-01, 0.8169109015
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.0112224069, 6.6340954475, 4.6821699925, 23.7818464637
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.0963278466, 6.5647793449, 4.6049166071, 23.5709950328
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.3295854475, 6.5825212075, 4.6280720781, 23.6068978906
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.4896116134, 6.5946653906, 4.6399628669, 23.6817106605
4 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.6618209063, 6.6077092026, 4.6556057826, 23.7332493067
5 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.8545714548, 6.6222784187, 4.6704893562, 23.7309858203
6 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 43.9737006270, 6.6312668946, 4.6762859234, 23.7965762615
7 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.1261807801, 6.6427540057, 4.6932628973, 23.7758740783
8 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.2402501273, 6.6513344621, 4.6991969432, 23.8259941339
9 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.4057201289, 6.6637617101, 4.7123849102, 23.8668411970
10 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.5205217123, 6.6723700221, 4.7240382733, 23.8899737597
11 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.6764099100, 6.6840414354, 4.7356429234, 23.9217221737
12 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 44.7599683285, 6.6902891065, 4.7461813485, 23.9813148975
Model Testing Ended ... Tue May 31 01:45:07 2022
